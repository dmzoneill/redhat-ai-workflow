# Skill: Cancel Pipeline
# Cancel stuck or failed Tekton pipelines

name: cancel_pipeline
description: |
  Cancel a running or stuck Tekton pipeline.

  Use when:
  - A pipeline is stuck and needs to be killed
  - You started a wrong build
  - Need to free up cluster resources
  - Want to retry with different parameters

  The skill will:
  1. List running pipelines
  2. Get pipeline status
  3. Cancel the specified pipeline
  4. Optionally delete the run
  5. Show how to retry

version: "1.0"

inputs:
  - name: run_name
    type: string
    required: false
    description: "PipelineRun name to cancel (lists running if not specified)"

  - name: namespace
    type: string
    required: false
    default: "aap-aa-tenant"
    description: "Konflux/Tekton namespace"

  - name: delete
    type: boolean
    required: false
    default: false
    description: "Delete the PipelineRun after cancelling"

  - name: list_only
    type: boolean
    required: false
    default: false
    description: "Just list running pipelines without cancelling"

steps:
  # ==================== KNOWLEDGE INTEGRATION ====================

  - name: get_pipeline_patterns
    description: "Get pipeline patterns and gotchas from knowledge base"
    tool: knowledge_query
    args:
      project: "automation-analytics-backend"
      persona: "devops"
      query: "gotchas"
    output: pipeline_knowledge_raw
    on_error: continue

  - name: parse_pipeline_knowledge
    description: "Parse pipeline knowledge for cancel context"
    compute: |
      knowledge_text = str(pipeline_knowledge_raw) if pipeline_knowledge_raw else ""

      gotchas = []

      # Extract gotchas related to pipelines/cancellation
      if knowledge_text:
          for line in knowledge_text.split("\n"):
              line_lower = line.lower()
              if any(kw in line_lower for kw in ["pipeline", "tekton", "konflux", "cancel", "stuck", "timeout"]):
                  gotchas.append(line.strip()[:150])

      result = {
          "has_knowledge": len(gotchas) > 0,
          "gotchas": gotchas[:5],
      }
    output: pipeline_knowledge
    on_error: continue

  # ==================== PROACTIVE ISSUE DETECTION ====================

  - name: check_konflux_known_issues
    description: "Check for known Konflux issues before starting"
    tool: check_known_issues
    args:
      tool_name: "tkn_pipelinerun_cancel"
      error_text: ""
    output: konflux_known_issues
    on_error: continue

  # ==================== LIST PIPELINES ====================

  - name: list_pipelineruns
    description: "List recent pipeline runs"
    tool: tkn_pipelinerun_list
    args:
      namespace: "{{ inputs.namespace }}"
      limit: 20
    output: pipelineruns_raw
    on_error: auto_heal  # Tekton/Konflux - may need kube_login

  - name: parse_pipelineruns
    description: "Parse pipeline runs"
    compute: |
      runs_text = str(pipelineruns_raw) if pipelineruns_raw else ""

      running = []
      failed = []
      all_runs = []

      for line in runs_text.split("\n"):
          if not line.strip() or "NAME" in line:
              continue

          parts = line.split()
          if len(parts) >= 2:
              name = parts[0]
              status = parts[1] if len(parts) > 1 else "unknown"

              run = {"name": name, "status": status, "line": line.strip()[:100]}
              all_runs.append(run)

              if "running" in status.lower():
                  running.append(run)
              elif "failed" in status.lower():
                  failed.append(run)

      result = {
          "running": running[:10],
          "running_count": len(running),
          "failed": failed[:10],
          "failed_count": len(failed),
          "all": all_runs[:20],
          "total": len(all_runs),
          "raw": runs_text[:800] if runs_text else "No pipelines",
      }
    output: pipeline_list

  - name: select_target
    description: "Select pipeline to cancel"
    compute: |
      if inputs.run_name:
          target = inputs.run_name
      elif pipeline_list.get("running_count", 0) == 1:
          target = pipeline_list["running"][0]["name"]
      else:
          target = None

      result = {
          "run_name": target,
          "needs_selection": target is None and pipeline_list.get("running_count", 0) > 1,
      }
    output: target_run

  # ==================== GET DETAILS ====================

  - name: describe_run
    description: "Get details of the target run"
    condition: "target_run.run_name and not inputs.list_only"
    tool: tkn_pipelinerun_describe
    args:
      run_name: "{{ target_run.run_name }}"
      namespace: "{{ inputs.namespace }}"
    output: run_details_raw
    on_error: auto_heal  # Tekton/Konflux - may need kube_login

  - name: get_taskruns
    description: "List task runs for this pipeline"
    condition: "target_run.run_name and not inputs.list_only"
    tool: tkn_taskrun_list
    args:
      namespace: "{{ inputs.namespace }}"
      limit: 20
    output: taskruns_raw
    on_error: auto_heal  # Tekton/Konflux - may need kube_login

  - name: parse_details
    description: "Parse run details"
    condition: "run_details_raw"
    compute: |
      details_text = str(run_details_raw) if run_details_raw else ""
      tasks_text = str(taskruns_raw) if 'taskruns_raw' in dir() and taskruns_raw else ""

      # Check current status
      status = "unknown"
      if "running" in details_text.lower():
          status = "running"
      elif "failed" in details_text.lower():
          status = "failed"
      elif "succeeded" in details_text.lower():
          status = "succeeded"
      elif "cancelled" in details_text.lower():
          status = "cancelled"

      # Count related task runs
      task_count = 0
      for line in tasks_text.split("\n"):
          if target_run.run_name in line:
              task_count += 1

      result = {
          "status": status,
          "can_cancel": status == "running",
          "task_count": task_count,
          "details": details_text[:600] if details_text else "",
      }
    output: run_status
    on_error: continue

  # ==================== CANCEL PIPELINE ====================

  - name: cancel_pipelinerun
    description: "Cancel the pipeline run"
    condition: "target_run.run_name and not inputs.list_only and run_status and run_status.can_cancel"
    tool: tkn_pipelinerun_cancel
    args:
      run_name: "{{ target_run.run_name }}"
      namespace: "{{ inputs.namespace }}"
    output: cancel_result
    on_error: auto_heal  # Tekton/Konflux - may need kube_login

  - name: parse_cancel
    description: "Parse cancel result"
    condition: "cancel_result"
    compute: |
      cancel_text = str(cancel_result) if cancel_result else ""

      success = "cancelled" in cancel_text.lower() or "error" not in cancel_text.lower()

      result = {
          "success": success,
          "message": cancel_text[:200] if cancel_text else "No response",
      }
    output: cancel_status
    on_error: continue

  # ==================== DELETE PIPELINE ====================

  - name: delete_pipelinerun
    description: "Delete the pipeline run"
    condition: "inputs.delete and target_run.run_name and cancel_status and cancel_status.success"
    tool: tkn_pipelinerun_delete
    args:
      run_name: "{{ target_run.run_name }}"
      namespace: "{{ inputs.namespace }}"
    output: delete_result
    on_error: auto_heal  # Tekton/Konflux - may need kube_login

  - name: parse_delete
    description: "Parse delete result"
    condition: "delete_result"
    compute: |
      delete_text = str(delete_result) if delete_result else ""

      success = "deleted" in delete_text.lower() or "error" not in delete_text.lower()

      result = {
          "success": success,
          "message": delete_text[:200] if delete_text else "No response",
      }
    output: delete_status
    on_error: continue

  # ==================== MEMORY ====================

  - name: log_cancel
    description: "Log cancel action"
    condition: "cancel_status and cancel_status.success"
    tool: memory_session_log
    args:
      action: "Cancelled pipeline {{ target_run.run_name }}"
      details: "Namespace: {{ inputs.namespace }}{% if inputs.delete %}, deleted{% endif %}"
    on_error: continue

  - name: track_pipeline_cancellations
    description: "Track pipeline cancellations for patterns"
    condition: "cancel_status and cancel_status.success"
    compute: |
      from datetime import datetime

      # Load patterns
      patterns = memory.read_memory("learned/patterns") or {}
      if "pipeline_cancellations" not in patterns:
          patterns["pipeline_cancellations"] = []

      # Record this cancellation
      cancel_record = {
          "run_name": target_run.run_name if target_run else "unknown",
          "namespace": inputs.namespace,
          "deleted": inputs.delete,
          "status_before": run_status.status if run_status else "unknown",
          "task_count": run_status.task_count if run_status else 0,
          "timestamp": datetime.now().isoformat(),
      }

      patterns["pipeline_cancellations"].append(cancel_record)

      # Keep last 100 cancellations
      patterns["pipeline_cancellations"] = patterns["pipeline_cancellations"][-100:]

      memory.write_memory("learned/patterns", patterns)
      result = "cancellation tracked"
    output: cancel_tracking_result
    on_error: continue

  - name: track_stuck_pipelines
    description: "Track pipelines that frequently get stuck"
    condition: "run_status and run_status.status == 'running'"
    compute: |
      from datetime import datetime

      # Load patterns
      patterns = memory.read_memory("learned/patterns") or {}
      if "stuck_pipelines" not in patterns:
          patterns["stuck_pipelines"] = {}

      # Extract pipeline name from run name (usually format: pipeline-name-xxxxx)
      run_name = target_run.run_name if target_run else ""
      pipeline_name = "-".join(run_name.split("-")[:-1]) if run_name else "unknown"

      if pipeline_name not in patterns["stuck_pipelines"]:
          patterns["stuck_pipelines"][pipeline_name] = {
              "count": 0,
              "first_stuck": datetime.now().isoformat(),
              "last_stuck": datetime.now().isoformat(),
          }

      patterns["stuck_pipelines"][pipeline_name]["count"] += 1
      patterns["stuck_pipelines"][pipeline_name]["last_stuck"] = datetime.now().isoformat()

      memory.write_memory("learned/patterns", patterns)
      result = "stuck pipeline tracked"
    output: stuck_tracking_result
    on_error: continue

  # ==================== SEMANTIC SEARCH ====================

  - name: search_pipeline_code
    description: "Search for pipeline-related code"
    condition: "target_run.run_name"
    tool: code_search
    args:
      query: "pipeline tekton {{ target_run.run_name.split('-')[0] if target_run.run_name else '' }}"
      project: "automation-analytics-backend"
      limit: 3
    output: pipeline_code_raw
    on_error: continue

  - name: parse_pipeline_code
    description: "Parse pipeline code search results"
    condition: "pipeline_code_raw"
    compute: |
      code_result = pipeline_code_raw if pipeline_code_raw else {}

      related_code = []
      if isinstance(code_result, dict) and code_result.get('results'):
          for r in code_result.get('results', [])[:3]:
              related_code.append({
                  'file': r.get('file_path', ''),
                  'score': r.get('score', 0),
              })

      result = {
          'code': related_code,
          'count': len(related_code),
      }
    output: pipeline_code_analysis
    on_error: continue

outputs:
  - name: report
    value: |
      ## üõë Cancel Pipeline

      **Namespace:** `{{ inputs.namespace }}`

      ---

      {% if inputs.list_only or not target_run.run_name %}
      ### üìã Pipeline Runs

      {% if pipeline_list.running_count > 0 %}
      **üîÑ Running ({{ pipeline_list.running_count }}):**
      {% for run in pipeline_list.running %}
      - `{{ run.name }}` - {{ run.status }}
      {% endfor %}
      {% else %}
      ‚úÖ No pipelines currently running.
      {% endif %}

      {% if pipeline_list.failed_count > 0 %}
      **‚ùå Failed ({{ pipeline_list.failed_count }}):**
      {% for run in pipeline_list.failed[:5] %}
      - `{{ run.name }}`
      {% endfor %}
      {% endif %}

      {% if target_run.needs_selection %}
      **Multiple running pipelines.** Specify which one:
      ```python
      skill_run("cancel_pipeline", '{"run_name": "PIPELINE_NAME"}')
      ```
      {% endif %}

      {% else %}
      ### Target: `{{ target_run.run_name }}`

      {% if run_status %}
      **Status:** {{ run_status.status }}
      **Tasks:** {{ run_status.task_count }}
      {% endif %}

      {% if not run_status.can_cancel %}
      ‚ö†Ô∏è Pipeline is not running (status: {{ run_status.status }}). Cannot cancel.

      {% elif cancel_status and cancel_status.success %}
      ‚úÖ **Pipeline Cancelled**

      {{ cancel_status.message }}

      {% if inputs.delete and delete_status %}
      {% if delete_status.success %}
      ‚úÖ PipelineRun deleted
      {% else %}
      ‚ö†Ô∏è Delete failed: {{ delete_status.message }}
      {% endif %}
      {% endif %}

      {% else %}
      ‚ùå **Cancel Failed**

      {{ cancel_status.message if cancel_status else "Unknown error" }}
      {% endif %}
      {% endif %}

      ---

      ### Commands

      **List running pipelines:**
      ```python
      tkn_pipelinerun_list(namespace='{{ inputs.namespace }}', limit=10)
      ```

      **Get logs:**
      ```python
      tkn_pipelinerun_logs(run_name='{{ target_run.run_name or "PIPELINE_NAME" }}', namespace='{{ inputs.namespace }}')
      ```

      **Retry (start new run):**
      ```python
      tkn_pipeline_start(pipeline_name='PIPELINE_NAME', namespace='{{ inputs.namespace }}')
      ```

  # ==================== LEARNING FROM FAILURES ====================

  - name: detect_cancel_failures
    description: "Detect failure patterns from pipeline cancellation"
    compute: |
      errors_detected = []

      # Check Tekton/Konflux failures
      list_text = str(pipelinerun_list_raw) if 'pipelinerun_list_raw' in dir() and pipelinerun_list_raw else ""
      cancel_text = str(cancel_result_raw) if 'cancel_result_raw' in dir() and cancel_result_raw else ""
      combined = list_text + cancel_text

      if "no route to host" in combined.lower():
          errors_detected.append({
              "tool": "tkn_pipelinerun_cancel",
              "pattern": "no route to host",
              "cause": "VPN not connected - Konflux cluster not reachable",
              "fix": "Run vpn_connect() and kube_login('konflux')"
          })
      if "unauthorized" in combined.lower() or "forbidden" in combined.lower():
          errors_detected.append({
              "tool": "tkn_pipelinerun_cancel",
              "pattern": "unauthorized",
              "cause": "Kubernetes auth expired for Konflux cluster",
              "fix": "Run kube_login('konflux')"
          })
      if "not found" in combined.lower() and "pipelinerun" in combined.lower():
          errors_detected.append({
              "tool": "tkn_pipelinerun_cancel",
              "pattern": "pipelinerun not found",
              "cause": "PipelineRun doesn't exist or already completed",
              "fix": "List running pipelines with tkn_pipelinerun_list()"
          })

      result = errors_detected
    output: cancel_errors_detected
    on_error: continue

  - name: learn_cancel_vpn_failure
    description: "Learn from VPN failures"
    condition: "cancel_errors_detected and any(e.get('pattern') == 'no route to host' for e in cancel_errors_detected)"
    tool: learn_tool_fix
    args:
      tool_name: "tkn_pipelinerun_cancel"
      error_pattern: "no route to host"
      root_cause: "VPN not connected - Konflux cluster not reachable"
      fix_description: "Run vpn_connect() and kube_login('konflux')"
    output: cancel_vpn_fix_learned
    on_error: continue

  - name: learn_cancel_auth_failure
    description: "Learn from auth failures"
    condition: "cancel_errors_detected and any(e.get('pattern') == 'unauthorized' for e in cancel_errors_detected)"
    tool: learn_tool_fix
    args:
      tool_name: "tkn_pipelinerun_cancel"
      error_pattern: "unauthorized"
      root_cause: "Kubernetes auth expired for Konflux cluster"
      fix_description: "Run kube_login('konflux')"
    output: cancel_auth_fix_learned
    on_error: continue

  - name: log_cancel_session
    description: "Log pipeline cancellation to session"
    tool: memory_session_log
    args:
      action: "Cancelled pipeline {{ target_run.run_name if target_run else 'unknown' }}"
      details: "Success: {{ cancel_status.success if cancel_status else 'unknown' }}"
    on_error: continue

  - name: context
    value:
      run_name: "{{ target_run.run_name }}"
      cancelled: "{{ cancel_status.success if cancel_status else false }}"
      deleted: "{{ delete_status.success if delete_status else false }}"
      running_count: "{{ pipeline_list.running_count }}"
