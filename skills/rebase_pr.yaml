# Skill: Rebase PR Branch
# Rebase a PR branch onto main, handling merge commits and conflicts

name: rebase_pr
description: |
  Rebase a PR branch onto main to clean up merge commits.

  If 'repo_path' is not provided, resolves from issue_key or repo_name via config.

  Steps:
  1. Check for merge commits on the PR
  2. Checkout the branch locally
  3. Pull latest from remote
  4. Rebase onto main
  5. If conflicts: guide user through resolution
  6. Force push rebased branch

  Handles merge conflicts by pausing and showing what needs to be fixed.

version: "1.2"

inputs:
  - name: mr_id
    type: integer
    required: false
    description: "GitLab MR ID - will find the branch"

  - name: issue_key
    type: string
    required: false
    description: "Jira issue key - will find the branch and resolve repo"

  - name: branch
    type: string
    required: false
    description: "Branch name directly (if known)"

  - name: repo_path
    type: string
    required: false
    default: ""
    description: "Path to repository - if not provided, resolved from issue_key or repo_name"

  - name: repo_name
    type: string
    required: false
    description: "Repository name from config (e.g., 'automation-analytics-backend')"

  - name: base_branch
    type: string
    required: false
    default: ""
    description: "Branch to rebase onto (default: repo's default_branch from config)"

  - name: force_push
    type: boolean
    required: false
    default: false
    description: "Auto force-push after successful rebase (asks if false)"

  - name: run_linting
    type: boolean
    required: false
    default: true
    description: "Run linting (black/flake8) before pushing (default: true)"

# No hardcoded constants - resolved dynamically

steps:

  - name: init_autoheal
    description: "Initialize failure tracking"
    compute: |
      result = {"git_failures": [], "attempts": 0}
    output: autoheal_state
    on_error: continue

  # ==================== MEMORY CONTEXT ====================

  - name: check_known_issues
    description: "Check for known rebase issues"
    compute: |
      # Check known issues for git rebase
      issues = memory.check_known_issues("git_rebase", "")

      result = {
          "has_known_issues": len(issues.get("matches", [])) > 0 if issues else False,
          "issues": issues.get("matches", [])[:3] if issues else [],
      }
    output: known_issues
    on_error: continue

  - name: load_rebase_history
    description: "Load previous rebase history for this branch"
    compute: |
      # Load learned patterns
      patterns = memory.read_memory("learned/patterns") or {}
      rebase_history = patterns.get("rebases", [])

      # Find history for similar branches
      issue_key = inputs.get("issue_key", "")
      mr_id = inputs.get("mr_id")

      relevant_rebases = []
      if issue_key:
          relevant_rebases = [r for r in rebase_history if issue_key in str(r.get("branch", ""))]
      elif mr_id:
          relevant_rebases = [r for r in rebase_history if str(mr_id) == str(r.get("mr_id", ""))]

      # Common conflict files
      conflict_files = {}
      for r in rebase_history:
          for cf in r.get("conflict_files", []):
              conflict_files[cf] = conflict_files.get(cf, 0) + 1

      result = {
          "previous_rebases": len(rebase_history),
          "for_this_branch": relevant_rebases[-5:],
          "common_conflict_files": sorted(conflict_files.keys(), key=lambda x: conflict_files[x], reverse=True)[:10],
      }
    output: rebase_history
    on_error: continue

  - name: get_coding_patterns
    description: "Get coding patterns from knowledge for conflict resolution"
    tool: knowledge_query
    args:
      project: "automation-analytics-backend"
      persona: "developer"
      section: "patterns.coding"
    output: coding_patterns_raw
    on_error: continue

  - name: parse_coding_patterns
    description: "Parse coding patterns"
    compute: |
      patterns_result = coding_patterns_raw if 'coding_patterns_raw' in dir() and coding_patterns_raw else {}

      coding_patterns = []
      if isinstance(patterns_result, dict) and patterns_result.get('found'):
          content = patterns_result.get('content', [])
          if isinstance(content, list):
              coding_patterns = content[:5]

      result = {
          'patterns': coding_patterns,
          'has_patterns': len(coding_patterns) > 0,
      }
    output: coding_patterns
    on_error: continue

  # ==================== RESOLVE REPOSITORY ====================

  - name: resolve_repo
    description: "Determine which repo and GitLab project to use"
    compute: |
      import os
      from scripts.common.config_loader import load_config

      repo_path = None
      gitlab_project = None
      default_branch = "main"

      # Load config using shared loader
      config = load_config()
      repos = config.get("repositories", {})

      # Explicit repo path
      if inputs.repo_path and inputs.repo_path != "" and inputs.repo_path != ".":
          repo_path = inputs.repo_path
          for name, cfg in repos.items():
              if cfg.get("path") == repo_path:
                  gitlab_project = cfg.get("gitlab")
                  default_branch = cfg.get("default_branch", "main")
                  break
      # Repo name from config
      elif inputs.repo_name and inputs.repo_name in repos:
          cfg = repos[inputs.repo_name]
          repo_path = cfg.get("path")
          gitlab_project = cfg.get("gitlab")
          default_branch = cfg.get("default_branch", "main")
      # Resolve from issue key
      elif inputs.issue_key:
          project_prefix = inputs.issue_key.split("-")[0].upper()
          for name, cfg in repos.items():
              if cfg.get("jira_project") == project_prefix:
                  repo_path = cfg.get("path")
                  gitlab_project = cfg.get("gitlab")
                  default_branch = cfg.get("default_branch", "main")
                  break
      # Fall back to cwd
      else:
          cwd = os.getcwd()
          if os.path.exists(os.path.join(cwd, ".git")):
              repo_path = cwd
              for name, cfg in repos.items():
                  if cfg.get("path") == cwd:
                      gitlab_project = cfg.get("gitlab")
                      default_branch = cfg.get("default_branch", "main")
                      break

      if not repo_path:
          raise ValueError("Repository not specified. Provide 'repo_path', 'repo_name', or 'issue_key'.")

      # Override default_branch if explicitly specified
      if inputs.base_branch:
          default_branch = inputs.base_branch

      result = {
          "path": repo_path,
          "gitlab_project": gitlab_project or "automation-analytics/automation-analytics-backend",
          "default_branch": default_branch,
      }
    output: resolved_repo

  # ==================== RESOLVE BRANCH NAME ====================

  - name: validate_input
    description: "Ensure we have a way to identify the branch"
    compute: |
      if not inputs.get('mr_id') and not inputs.get('issue_key') and not inputs.get('branch'):
        raise ValueError("Must provide one of: mr_id, issue_key, or branch")
      result = "OK"
    output: input_valid

  - name: get_branch_from_mr
    description: "Get branch name from MR"
    condition: "inputs.get('mr_id') and not inputs.get('branch')"
    tool: gitlab_mr_view
    args:
      project: "{{ resolved_repo.gitlab_project }}"
      mr_id: "{{ inputs.mr_id }}"
    output: mr_details
    on_error: auto_heal  # GitLab API - may need auth refresh

  - name: list_branches
    description: "List all branches for issue key lookup"
    condition: "inputs.get('issue_key') and not inputs.get('branch')"
    tool: git_branch_list
    args:
      repo: "{{ resolved_repo.path }}"
      all_branches: true
    output: branches_raw
    on_error: continue

  - name: extract_branch
    description: "Extract branch name from MR or issue key using shared parsers"
    compute: |
      from scripts.common.parsers import extract_branch_from_mr, parse_git_branches

      branch = inputs.get('branch')

      if not branch and mr_details:
        # Extract from MR details using shared parser
        branch = extract_branch_from_mr(mr_details)

      if not branch and inputs.get('issue_key'):
        # Find branch by issue key using shared parser
        matching = parse_git_branches(branches_raw or "", issue_key=inputs.issue_key)
        if matching:
          branch = matching[0]

      if not branch:
        raise ValueError("Could not determine branch name. Please provide 'branch' input directly.")

      result = branch
    output: target_branch

  # ==================== CHECK FOR MERGE COMMITS ====================

  - name: fetch_all
    description: "Fetch latest from all remotes"
    tool: git_fetch
    args:
      repo: "{{ resolved_repo.path }}"
      prune: true
    output: fetch_result
    on_error: auto_heal  # Git remote - may need auth/network

  - name: get_merge_commits
    description: "Get merge commits on the branch"
    tool: git_log
    args:
      repo: "{{ resolved_repo.path }}"
      range_spec: "origin/{{ resolved_repo.default_branch }}..origin/{{ target_branch }}"
      merges_only: true
      limit: 20
    output: merge_commits_raw
    on_error: continue

  - name: get_total_commits
    description: "Get total commit count"
    tool: git_log
    args:
      repo: "{{ resolved_repo.path }}"
      range_spec: "origin/{{ resolved_repo.default_branch }}..origin/{{ target_branch }}"
      count_only: true
    output: total_commits_raw
    on_error: continue

  - name: check_merge_commits
    description: "Parse merge commit info using shared parser"
    compute: |
      from scripts.common.parsers import parse_git_log

      # Parse merge commits using shared parser
      merge_output = str(merge_commits_raw) if merge_commits_raw else ""

      if "No commits found" not in merge_output and merge_output.strip():
        commits = parse_git_log(merge_output)
        merge_commits = [c.get('sha', '') or c.get('message', '')[:10] for c in commits]
      else:
        merge_commits = []

      # Parse total count
      total_str = str(total_commits_raw).strip() if total_commits_raw else "0"
      try:
        total_commits = int(total_str)
      except:
        total_commits = 0

      result = {
        'has_merge_commits': len(merge_commits) > 0,
        'merge_count': len(merge_commits),
        'total_commits': total_commits,
        'merge_commits': merge_commits[:5]
      }
    output: merge_check

  # ==================== CHECKOUT AND PREPARE (using MCP tools) ====================

  - name: check_status
    description: "Check for uncommitted changes"
    tool: git_status
    args:
      repo: "{{ resolved_repo.path }}"
    output: git_status_raw
    on_error: continue

  - name: stash_changes
    description: "Stash any local changes"
    condition: "git_status_raw and ('Changes not staged' in str(git_status_raw) or 'Changes to be committed' in str(git_status_raw))"
    tool: git_stash
    args:
      repo: "{{ resolved_repo.path }}"
      action: "push"
      message: "rebase_pr: auto-stash before rebase"
    output: stash_result
    on_error: continue

  - name: checkout_branch
    description: "Checkout the target branch"
    tool: git_checkout
    args:
      repo: "{{ resolved_repo.path }}"
      target: "{{ target_branch }}"
    output: checkout_result
    on_error: continue

  - name: checkout_fallback
    description: "Fallback: force checkout from remote if local failed"
    condition: "checkout_result and 'error' in str(checkout_result).lower()"
    tool: git_checkout
    args:
      repo: "{{ resolved_repo.path }}"
      target: "{{ target_branch }}"
      force_create: true
      start_point: "origin/{{ target_branch }}"
    output: checkout_fallback_result
    on_error: continue

  - name: pull_latest
    description: "Pull latest from remote"
    tool: git_pull
    args:
      repo: "{{ resolved_repo.path }}"
    output: pull_result_raw
    on_error: auto_heal  # Git remote - may need auth/network

  - name: sync_with_remote
    description: "Reset to remote if pull failed"
    condition: "pull_result_raw and 'error' in str(pull_result_raw).lower()"
    tool: git_reset
    args:
      repo: "{{ resolved_repo.path }}"
      target: "origin/{{ target_branch }}"
      mode: "hard"
    output: reset_result
    on_error: continue

  - name: sync_status
    description: "Record sync status"
    compute: |
      if 'reset_result' in dir() and reset_result:
        result = f"Reset to remote: {reset_result}"
      elif 'pull_result_raw' in dir():
        result = f"Pulled: {pull_result_raw}"
      else:
        result = "Branch synced"
    output: pull_result

  # ==================== PERFORM REBASE ====================

  - name: update_base
    description: "Fetch base branch from remote"
    tool: git_fetch
    args:
      repo: "{{ resolved_repo.path }}"
      remote: "origin"
      branch: "{{ resolved_repo.default_branch }}"
    output: base_updated

  - name: start_rebase
    description: "Start the rebase onto base branch"
    tool: git_rebase
    args:
      repo: "{{ resolved_repo.path }}"
      onto: "origin/{{ resolved_repo.default_branch }}"
    output: rebase_raw
    on_error: continue

  - name: parse_rebase_result
    description: "Parse rebase output into structured result using shared parser"
    compute: |
      from scripts.common.parsers import extract_conflict_files

      rebase_output = str(rebase_raw) if rebase_raw else ""

      if "Successfully rebased" in rebase_output or "‚úÖ" in rebase_output:
        rebase_status = {
          'success': True,
          'conflicts': False,
          'message': 'Rebase completed successfully!'
        }
      elif "conflict" in rebase_output.lower() or "‚ö†Ô∏è" in rebase_output:
        # Extract conflict files using shared parser
        conflict_files = extract_conflict_files(rebase_output)
        rebase_status = {
          'success': False,
          'conflicts': True,
          'conflict_files': conflict_files,
          'message': f'Rebase paused - {len(conflict_files)} file(s) have conflicts'
        }
      else:
        rebase_status = {
          'success': False,
          'conflicts': False,
          'message': f'Rebase failed: {rebase_output[:200]}'
        }

      result = rebase_status
    output: rebase_result

  # ==================== HANDLE CONFLICTS (AUTO-RESOLVE IF POSSIBLE) ====================

  - name: search_conflict_context
    description: "Find similar code patterns to help resolve conflicts"
    condition: "rebase_result.get('conflicts') and rebase_result.get('conflict_files')"
    tool: code_search
    args:
      query: "{{ rebase_result.conflict_files[0] if rebase_result.conflict_files else 'conflict resolution' }}"
      project: "automation-analytics-backend"
      limit: 3
      min_score: 0.5
    output: conflict_context_raw
    on_error: continue

  - name: parse_conflict_context
    description: "Parse conflict context search results"
    condition: "conflict_context_raw"
    compute: |
      context_result = conflict_context_raw if conflict_context_raw else {}

      similar_code = []
      if isinstance(context_result, dict) and context_result.get('results'):
          for r in context_result.get('results', [])[:3]:
              similar_code.append({
                  'file': r.get('file_path', ''),
                  'score': r.get('score', 0),
                  'preview': r.get('code_chunk', '')[:150] if r.get('code_chunk') else '',
              })

      result = {
          'similar_code': similar_code,
          'has_context': len(similar_code) > 0,
      }
    output: conflict_context
    on_error: continue

  - name: analyze_and_resolve_conflicts
    description: "Analyze conflicts and auto-resolve obvious ones"
    condition: "rebase_result.get('conflicts')"
    compute: |
      import os
      from scripts.common.parsers import parse_conflict_markers, find_full_conflict_marker

      conflict_files = rebase_result.get('conflict_files', [])
      repo = resolved_repo["path"]

      auto_resolved = []
      needs_human = []

      for filepath in conflict_files:
        full_path = os.path.join(repo, filepath)

        try:
          with open(full_path, 'r') as f:
            content = f.read()

          # Find all conflict blocks using shared parser
          conflict_blocks = parse_conflict_markers(content)
          conflicts = [(c['ours'], c['theirs']) for c in conflict_blocks]

          if not conflicts:
            # No conflicts found, might be resolved already
            auto_resolved.append({'file': filepath, 'action': 'no_conflicts_found'})
            continue

          can_auto_resolve = True
          resolution_strategy = None

          for ours, theirs in conflicts:
            ours_stripped = ours.strip()
            theirs_stripped = theirs.strip()

            # Case 1: Identical (shouldn't happen but handle it)
            if ours_stripped == theirs_stripped:
              resolution_strategy = 'identical'
              continue

            # Case 2: Ours is empty - accept theirs (new addition)
            if not ours_stripped and theirs_stripped:
              resolution_strategy = 'accept_theirs'
              continue

            # Case 3: Theirs is empty - keep ours (they deleted, we modified)
            if ours_stripped and not theirs_stripped:
              resolution_strategy = 'accept_ours'
              continue

            # Case 4: Simple whitespace/formatting difference
            if ours_stripped.replace(' ', '').replace('\t', '') == theirs_stripped.replace(' ', '').replace('\t', ''):
              resolution_strategy = 'whitespace_only'
              continue

            # Case 5: One side just adds lines (non-overlapping)
            ours_lines = set(ours_stripped.split('\n'))
            theirs_lines = set(theirs_stripped.split('\n'))
            if ours_lines.issubset(theirs_lines) or theirs_lines.issubset(ours_lines):
              resolution_strategy = 'subset_merge'
              continue

            # Complex conflict - needs human
            can_auto_resolve = False
            break

          if can_auto_resolve and resolution_strategy:
            # Apply auto-resolution
            new_content = content

            for ours, theirs in conflicts:
              # Find and get the full marker including commit ref using shared parser
              full_marker = find_full_conflict_marker(content, ours, theirs)

              if full_marker:

                if resolution_strategy in ['accept_theirs', 'subset_merge']:
                  # Keep theirs
                  new_content = new_content.replace(full_marker, theirs)
                elif resolution_strategy == 'accept_ours':
                  # Keep ours
                  new_content = new_content.replace(full_marker, ours)
                elif resolution_strategy in ['identical', 'whitespace_only']:
                  # Keep theirs (more recent)
                  new_content = new_content.replace(full_marker, theirs)

            # Write resolved file
            with open(full_path, 'w') as f:
              f.write(new_content)

            # Track file for staging (will be staged in next step)
            auto_resolved.append({
              'file': filepath,
              'action': f'auto_resolved ({resolution_strategy})',
              'strategy': resolution_strategy
            })
          else:
            # Count conflicts for human
            conflict_count = len(conflicts)
            needs_human.append({
              'file': filepath,
              'conflicts': conflict_count,
              'reason': 'Complex changes on both sides'
            })

        except Exception as e:
          needs_human.append({
            'file': filepath,
            'conflicts': '?',
            'reason': f'Error reading file: {str(e)[:50]}'
          })

      result = {
        'auto_resolved': auto_resolved,
        'needs_human': needs_human,
        'all_resolved': len(needs_human) == 0
      }
    output: conflict_resolution

  # Stage all auto-resolved files
  - name: stage_resolved_files
    description: "Stage auto-resolved conflict files"
    condition: "conflict_resolution and conflict_resolution.get('auto_resolved')"
    tool: git_add
    args:
      repo: "{{ resolved_repo.path }}"
      files: "{{ ' '.join([f['file'] for f in conflict_resolution.auto_resolved]) }}"
    output: stage_result
    on_error: continue

  # Continue the rebase
  - name: continue_rebase_if_resolved
    description: "Continue rebase if all conflicts auto-resolved"
    condition: "conflict_resolution and conflict_resolution.get('all_resolved')"
    tool: git_rebase
    args:
      repo: "{{ resolved_repo.path }}"
      continue_rebase: true
    output: continue_raw
    on_error: continue

  # Check for new conflicts
  - name: check_new_conflicts
    description: "Check if new conflicts emerged after continue"
    condition: "continue_raw and 'conflict' in str(continue_raw).lower()"
    tool: git_status
    args:
      repo: "{{ resolved_repo.path }}"
    output: new_status_raw
    on_error: continue

  # Parse continue result
  - name: parse_continue_result
    description: "Parse the rebase continue result"
    condition: "conflict_resolution and conflict_resolution.get('all_resolved')"
    compute: |
      continue_text = str(continue_raw) if 'continue_raw' in dir() and continue_raw else ""
      new_status = str(new_status_raw) if 'new_status_raw' in dir() and new_status_raw else ""

      if 'success' in continue_text.lower() or ('conflict' not in continue_text.lower() and 'error' not in continue_text.lower()):
        continue_status = {
          'success': True,
          'message': 'Rebase continued successfully after auto-resolving conflicts'
        }
      else:
        # Check for new conflicts
        new_conflicts = [l[3:] for l in new_status.split('\n') if 'both modified' in l.lower() or l.startswith('UU')]

        if new_conflicts:
          continue_status = {
            'success': False,
            'message': f'More conflicts emerged: {len(new_conflicts)} files',
            'new_conflicts': new_conflicts
          }
        else:
          continue_status = {
            'success': False,
            'message': f'Rebase continue failed: {continue_text[:100]}'
          }

      result = continue_status
    output: continue_result

  - name: update_rebase_result
    description: "Update rebase result after auto-resolution"
    condition: "continue_result"
    compute: |
      if continue_result.get('success'):
        # Rebase is now complete
        result = {
          'success': True,
          'conflicts': False,
          'auto_resolved': True,
          'message': 'Rebase completed (conflicts auto-resolved)'
        }
      else:
        result = rebase_result  # Keep original status
    output: final_rebase_result

  # ==================== RUN LINTING (before push) ====================

  - name: run_flake8
    description: "Run flake8 linting on changed files"
    condition: "(rebase_result.get('success') or (final_rebase_result and final_rebase_result.get('success'))) and inputs.get('run_linting', True)"
    tool: lint_python
    args:
      repo: "{{ resolved_repo.path }}"
      tool: "flake8"
      fix: false
    output: flake8_result
    on_error: continue

  - name: run_black_check
    description: "Run black formatting check on changed files"
    condition: "(rebase_result.get('success') or (final_rebase_result and final_rebase_result.get('success'))) and inputs.get('run_linting', True)"
    tool: lint_python
    args:
      repo: "{{ resolved_repo.path }}"
      tool: "black"
      fix: false
    output: black_result
    on_error: continue

  - name: check_lint_results
    description: "Check if linting passed"
    condition: "(rebase_result.get('success') or (final_rebase_result and final_rebase_result.get('success'))) and inputs.get('run_linting', True)"
    compute: |
      flake8_output = str(flake8_result) if 'flake8_result' in dir() and flake8_result else ""
      black_output = str(black_result) if 'black_result' in dir() and black_result else ""

      flake8_passed = not flake8_output or 'error' not in flake8_output.lower() or '0 errors' in flake8_output.lower() or flake8_output.strip() == ""
      black_passed = not black_output or 'would reformat' not in black_output.lower() or 'All done' in black_output

      # Extract actual errors for reporting
      flake8_errors = []
      if flake8_output and not flake8_passed:
        for line in flake8_output.split('\n'):
          if ':' in line and ('F' in line or 'E' in line or 'W' in line):
            flake8_errors.append(line.strip())

      black_errors = []
      if black_output and not black_passed:
        for line in black_output.split('\n'):
          if 'would reformat' in line.lower():
            black_errors.append(line.strip())

      result = {
        'passed': flake8_passed and black_passed,
        'flake8_passed': flake8_passed,
        'black_passed': black_passed,
        'flake8_errors': flake8_errors[:10],  # Limit to first 10
        'black_errors': black_errors[:10],
      }
    output: lint_check

  # ==================== FORCE PUSH (if successful) ====================

  - name: check_branch_protection
    description: "Dry-run to check if force push is allowed"
    condition: "(rebase_result.get('success') or (final_rebase_result and final_rebase_result.get('success'))) and inputs.force_push"
    tool: git_push
    args:
      repo: "{{ resolved_repo.path }}"
      branch: "{{ target_branch }}"
      force: true
      dry_run: true
    output: dry_run_result
    on_error: auto_heal  # Git remote - may need auth/network

  - name: analyze_protection
    description: "Check dry-run result for protection issues"
    condition: "(rebase_result.get('success') or (final_rebase_result and final_rebase_result.get('success'))) and inputs.force_push"
    compute: |
      output_text = str(dry_run_result).lower() if 'dry_run_result' in dir() else ""

      if 'protected branch' in output_text:
        protection_check = {'allowed': False, 'reason': f"Branch '{target_branch}' is protected. Cannot force push."}
      elif 'permission denied' in output_text or '403' in output_text:
        protection_check = {'allowed': False, 'reason': "Permission denied - you may not have push access."}
      elif 'remote rejected' in output_text:
        protection_check = {'allowed': False, 'reason': "Remote rejected push - check branch rules."}
      elif 'error' in output_text or 'failed' in output_text:
        protection_check = {'allowed': False, 'reason': output_text[:200]}
      else:
        protection_check = {'allowed': True, 'reason': 'OK'}

      result = protection_check
    output: protection_check

  - name: force_push
    description: "Force push rebased branch"
    condition: >
      (rebase_result.get('success') or (final_rebase_result and final_rebase_result.get('success')))
      and inputs.force_push
      and (not protection_check or protection_check.get('allowed', True))
      and (not lint_check or lint_check.get('passed', True))
    tool: git_push
    args:
      repo: "{{ resolved_repo.path }}"
      branch: "{{ target_branch }}"
      force: true
    output: push_result

  # ==================== BUILD SUMMARY ====================

  - name: build_summary
    description: "Build result summary"
    compute: |
      lines = ["## üîÑ Rebase PR Summary", ""]
      lines.append(f"**Branch:** `{target_branch}`")
      lines.append(f"**Base:** `{resolved_repo['default_branch']}`")
      lines.append(f"**Repository:** `{resolved_repo['path']}`")
      lines.append("")

      # Merge commits info
      if merge_check.get('has_merge_commits'):
        lines.append(f"### ‚ö†Ô∏è Merge Commits Found: {merge_check['merge_count']}")
        for mc in merge_check.get('merge_commits', [])[:3]:
          lines.append(f"- `{mc}`")
        lines.append("")

      # Use final_rebase_result if available (after auto-resolution)
      effective_result = final_rebase_result if final_rebase_result else rebase_result

      # Show auto-resolution results
      if conflict_resolution:
        auto_resolved = conflict_resolution.get('auto_resolved', [])
        needs_human = conflict_resolution.get('needs_human', [])

        if auto_resolved:
          lines.append(f"### ü§ñ Auto-Resolved: {len(auto_resolved)} file(s)")
          for ar in auto_resolved:
            lines.append(f"- ‚úÖ `{ar['file']}` ({ar.get('strategy', 'resolved')})")
          lines.append("")

        if needs_human:
          lines.append(f"### üôã Needs Your Help: {len(needs_human)} file(s)")
          for nh in needs_human:
            lines.append(f"- ‚ö†Ô∏è `{nh['file']}` ({nh['conflicts']} conflict(s)) - {nh.get('reason', '')}")
          lines.append("")

      # Lint results
      if lint_check:
        if lint_check.get('passed'):
          lines.append("### ‚úÖ Linting Passed")
          lines.append("")
        else:
          lines.append("### ‚ùå Linting Failed")
          if not lint_check.get('flake8_passed') and lint_check.get('flake8_errors'):
            lines.append("**flake8 errors:**")
            for err in lint_check['flake8_errors'][:5]:
              lines.append(f"- `{err}`")
          if not lint_check.get('black_passed') and lint_check.get('black_errors'):
            lines.append("**black formatting issues:**")
            for err in lint_check['black_errors'][:5]:
              lines.append(f"- `{err}`")
          lines.append("")
          lines.append("‚ö†Ô∏è **Push blocked until lint errors are fixed.**")
          lines.append("")

      # Final rebase result
      if effective_result.get('success'):
        lines.append("### ‚úÖ Rebase Successful!")
        if effective_result.get('auto_resolved'):
          lines.append("*Conflicts were automatically resolved*")
        lines.append("")
        if lint_check and not lint_check.get('passed'):
          lines.append("‚ö†Ô∏è Fix lint errors before pushing.")
        elif push_result:
          lines.append(f"‚úÖ {push_result}")
        else:
          lines.append("Branch is rebased locally. Ready to force push.")
      elif effective_result.get('conflicts') and conflict_resolution and conflict_resolution.get('needs_human'):
        lines.append("### ‚ö†Ô∏è Manual Resolution Required")
        lines.append("")
        lines.append("Some conflicts couldn't be auto-resolved. Please fix the files above.")
      elif effective_result.get('conflicts'):
        lines.append("### ‚ö†Ô∏è Merge Conflicts Detected")
        lines.append("")
        lines.append("Conflicts need manual resolution.")
      else:
        lines.append("### ‚ùå Rebase Failed")
        lines.append(effective_result.get('message', 'Unknown error'))

      result = '\n'.join(lines)
    output: summary

  # Emit rebase hooks
  - name: emit_rebase_hook
    description: "Notify author about rebase result"
    compute: |
      # emit_event is available from skill engine safe_globals
      effective_result = final_rebase_result if final_rebase_result else rebase_result

      if emit_event:
          if effective_result.get('success'):
              emit_event("rebase_completed", {
                  "mr_id": str(inputs.get('mr_id', '')),
                  "branch": target_branch,
                  "base_branch": resolved_repo.get("default_branch", "main"),
                  "author": "",  # self - no DM needed
              })
              result = "rebase_completed hook sent"
          elif effective_result.get('conflicts') and conflict_resolution and conflict_resolution.get('needs_human'):
              emit_event("rebase_conflict", {
                  "mr_id": str(inputs.get('mr_id', '')),
                  "branch": target_branch,
                  "author": "",  # self - no DM needed
              })
              result = "rebase_conflict hook sent"
          else:
              result = "no hook needed"
      else:
          result = "hook skipped: emit_event not available"
    output: rebase_hook_result
    on_error: continue

  # ==================== MEMORY INTEGRATION ====================

  - name: log_rebase
    description: "Log rebase to session"
    compute: |
      effective_result = final_rebase_result if final_rebase_result else rebase_result
      success = effective_result.get('success', False) if effective_result else False
      conflicts = effective_result.get('conflicts', False) if effective_result else False

      result = {
          "success": success,
          "conflicts": conflicts,
          "mr_id": inputs.get('mr_id', ''),
          "branch": target_branch if target_branch else "unknown",
      }
    output: rebase_log_context

  - name: session_log_rebase
    description: "Log rebase to session"
    tool: memory_session_log
    args:
      action: "Rebased {{ 'MR !' + rebase_log_context.mr_id|string if rebase_log_context.mr_id else rebase_log_context.branch }}"
      details: "{{ 'Success' if rebase_log_context.success else ('Conflicts' if rebase_log_context.conflicts else 'Failed') }}"
    on_error: continue

  - name: learn_rebase_pattern
    description: "Learn from this rebase for future reference"
    compute: |
      from datetime import datetime

      # Load patterns
      patterns = memory.read_memory("learned/patterns") or {}
      if "rebases" not in patterns:
          patterns["rebases"] = []

      effective_result = final_rebase_result if 'final_rebase_result' in dir() and final_rebase_result else rebase_result

      # Record this rebase
      rebase_record = {
          "branch": target_branch if target_branch else "unknown",
          "mr_id": inputs.get("mr_id"),
          "issue_key": inputs.get("issue_key"),
          "base_branch": resolved_repo.get("default_branch", "main") if resolved_repo else "main",
          "had_merge_commits": merge_check.get("has_merge_commits", False) if merge_check else False,
          "merge_count": merge_check.get("merge_count", 0) if merge_check else 0,
          "success": effective_result.get("success", False) if effective_result else False,
          "had_conflicts": effective_result.get("conflicts", False) if effective_result else False,
          "auto_resolved": conflict_resolution.get("all_resolved", False) if conflict_resolution else False,
          "conflict_files": [nh.get("file") for nh in (conflict_resolution.get("needs_human", []) if conflict_resolution else [])],
          "lint_passed": lint_check.get("passed", True) if lint_check else True,
          "pushed": bool(push_result) if 'push_result' in dir() else False,
          "timestamp": datetime.now().isoformat(),
      }

      patterns["rebases"].append(rebase_record)

      # Keep last 200 rebase records
      patterns["rebases"] = patterns["rebases"][-200:]

      memory.write_memory("learned/patterns", patterns)
      result = "rebase pattern learned"
    output: pattern_learn_result
    on_error: continue

  - name: track_conflict_prone_files
    description: "Track files that frequently have conflicts during rebases"
    condition: "conflict_resolution and conflict_resolution.get('needs_human')"
    compute: |
      from datetime import datetime

      # Load patterns
      patterns = memory.read_memory("learned/patterns") or {}
      if "conflict_prone_files" not in patterns:
          patterns["conflict_prone_files"] = []

      # Track each conflicting file
      for nh in (conflict_resolution.get("needs_human", []) or []):
          filepath = nh.get("file")
          if not filepath:
              continue

          existing = [f for f in patterns["conflict_prone_files"] if f.get("file") == filepath]

          if existing:
              existing[0]["conflict_count"] = existing[0].get("conflict_count", 1) + 1
              existing[0]["last_conflict"] = datetime.now().isoformat()
          else:
              patterns["conflict_prone_files"].append({
                  "file": filepath,
                  "conflict_count": 1,
                  "first_conflict": datetime.now().isoformat(),
                  "last_conflict": datetime.now().isoformat(),
              })

      # Keep top 100 conflict-prone files
      patterns["conflict_prone_files"] = sorted(
          patterns["conflict_prone_files"],
          key=lambda x: x.get("conflict_count", 0),
          reverse=True
      )[:100]

      memory.write_memory("learned/patterns", patterns)
      result = "conflict-prone files tracked"
    output: conflict_tracking_result
    on_error: continue

  - name: update_mr_state
    description: "Update MR state in memory after rebase"
    condition: "inputs.get('mr_id')"
    compute: |
      from datetime import datetime

      # Update current work state
      current_work = memory.read_memory("state/current_work") or {}
      if "open_mrs" not in current_work:
          current_work["open_mrs"] = []

      effective_result = final_rebase_result if 'final_rebase_result' in dir() and final_rebase_result else rebase_result

      # Find and update this MR
      for mr in current_work["open_mrs"]:
          if mr.get("id") == inputs.get("mr_id"):
              mr["last_rebase"] = datetime.now().isoformat()
              mr["rebase_success"] = effective_result.get("success", False) if effective_result else False
              mr["pushed"] = bool(push_result) if 'push_result' in dir() else False
              break

      memory.write_memory("state/current_work", current_work)
      result = "MR state updated"
    output: mr_state_result
    on_error: continue

  # ==================== LEARNING FROM FAILURES ====================

  - name: detect_rebase_failures
    description: "Detect failure patterns from rebase operations"
    compute: |
      errors_detected = []

      # Check git failures
      rebase_text = str(rebase_raw) if 'rebase_raw' in dir() and rebase_raw else ""
      fetch_text = str(fetch_result) if 'fetch_result' in dir() and fetch_result else ""
      combined = rebase_text + fetch_text

      if "conflict" in combined.lower():
          errors_detected.append({
              "tool": "git_rebase",
              "pattern": "conflict",
              "cause": "Rebase resulted in merge conflicts",
              "fix": "Resolve conflicts manually, then git add and git rebase --continue"
          })
      if "permission denied" in combined.lower():
          errors_detected.append({
              "tool": "git_fetch",
              "pattern": "permission denied",
              "cause": "SSH key not loaded or git credentials expired",
              "fix": "Run ssh-add or check git credentials"
          })

      # Check GitLab failures
      mr_text = str(mr_details) if 'mr_details' in dir() and mr_details else ""
      if "no such host" in mr_text.lower():
          errors_detected.append({
              "tool": "gitlab_mr_view",
              "pattern": "no such host",
              "cause": "VPN not connected - internal GitLab not reachable",
              "fix": "Run vpn_connect() to connect to Red Hat VPN"
          })

      result = errors_detected
    output: rebase_errors_detected
    on_error: continue

  - name: learn_rebase_conflict_failure
    description: "Learn from rebase conflict failures"
    condition: "rebase_errors_detected and any(e.get('pattern') == 'conflict' for e in rebase_errors_detected)"
    tool: learn_tool_fix
    args:
      tool_name: "git_rebase"
      error_pattern: "conflict"
      root_cause: "Rebase resulted in merge conflicts"
      fix_description: "Resolve conflicts manually, then git add and git rebase --continue"
    output: rebase_conflict_fix_learned
    on_error: continue

  - name: learn_rebase_vpn_failure
    description: "Learn from GitLab VPN failures"
    condition: "rebase_errors_detected and any(e.get('pattern') == 'no such host' for e in rebase_errors_detected)"
    tool: learn_tool_fix
    args:
      tool_name: "gitlab_mr_view"
      error_pattern: "no such host"
      root_cause: "VPN not connected - internal GitLab not reachable"
      fix_description: "Run vpn_connect() to connect to Red Hat VPN"
    output: rebase_vpn_fix_learned
    on_error: continue

# ==================== OUTPUT ====================

outputs:
  - name: summary
    value: |
      {{ summary }}

      ---

      {% if conflict_resolution and conflict_resolution.get('needs_human') %}
      ## üõ†Ô∏è Resolve Remaining Conflicts

      I auto-resolved what I could, but some conflicts need your judgment:

      {% if conflict_context and conflict_context.has_context %}
      ### üîç Similar Code for Reference

      These files have similar patterns that may help resolve conflicts:

      {% for code in conflict_context.similar_code[:3] %}
      - `{{ code.file }}` ({{ "%.0f"|format(code.score * 100) }}% similar)
      {% endfor %}
      {% endif %}

      {% if coding_patterns and coding_patterns.has_patterns %}
      ### üìã Coding Patterns to Follow

      {% for pattern in coding_patterns.patterns[:3] %}
      - {{ pattern }}
      {% endfor %}
      {% endif %}

      **Step 1:** Open each file marked with ‚ö†Ô∏è above and resolve the conflicts
      Look for markers like:
      ```
      <<<<<<< HEAD
      your changes
      =======
      incoming changes
      >>>>>>> commit
      ```

      **Step 2:** After resolving each file, stage it:
      ```bash
      git add <filename>
      ```

      **Step 3:** Continue the rebase:
      ```bash
      git rebase --continue
      ```

      **Step 4:** If more conflicts, repeat steps 1-3

      **Step 5:** When complete, force push:
      ```bash
      git push --force-with-lease origin {{ target_branch }}
      ```

      **To abort:** `git rebase --abort`

      ---

      When you're done, tell me and I can verify and push.

      {% elif lint_check and not lint_check.get('passed') %}
      ## ‚ùå Lint Errors Must Be Fixed

      The rebase succeeded but there are lint errors that must be fixed before pushing.

      **Fix the errors above, then:**
      1. Stage your fixes: `git add -u`
      2. Amend the commit: `git commit --amend --no-edit`
      3. Run the skill again or push manually:
         ```bash
         git push --force-with-lease origin {{ target_branch }}
         ```

      {% elif (final_rebase_result and final_rebase_result.get('success') and not push_result) or (rebase_result.get('success') and not push_result) %}
      ## üöÄ Ready to Push

      {% if conflict_resolution and conflict_resolution.get('auto_resolved') %}
      All conflicts were auto-resolved! ü§ñ
      {% endif %}

      The rebase completed successfully! Would you like me to force push?

      Say **"yes, push it"** or run:
      ```
      skill_run("rebase_pr", '{"branch": "{{ target_branch }}", "force_push": true}')
      ```

      Or manually:
      ```bash
      git push --force-with-lease origin {{ target_branch }}
      ```

      {% elif push_result %}
      ## ‚úÖ Complete!

      {% if conflict_resolution and conflict_resolution.get('auto_resolved') %}
      Conflicts were auto-resolved and the branch has been pushed! ü§ñ
      {% else %}
      The branch has been rebased and pushed.
      {% endif %}

      The MR should now show a clean history.

      {% elif rebase_result.get('conflicts') and not conflict_resolution %}
      ## üõ†Ô∏è Resolve Conflicts

      **Step 1:** Open each conflicted file and resolve the conflicts
      **Step 2:** `git add <filename>`
      **Step 3:** `git rebase --continue`
      **Step 4:** Repeat if more conflicts
      **Step 5:** `git push --force-with-lease origin {{ target_branch }}`

      {% else %}
      ## ‚ùå Action Required

      Please check the error above and try again.
      {% endif %}

  - name: context
    value:
      branch: "{{ target_branch }}"
      rebase_success: "{{ rebase_result.get('success', False) }}"
      has_conflicts: "{{ rebase_result.get('conflicts', False) }}"
      pushed: "{{ push_result is defined }}"
