# Skill: Release AA Backend to Production
# Promotes automation-analytics-backend from stage to production via app-interface

name: release_aa_backend_prod
description: |
  Release Automation Analytics backend to production.
  This skill guides you through the promotion process from stage to production
  by updating the commit SHA in app-interface and creating a PR for approval.

  Resolves paths and Quay images from config.json.
version: "1.2"

inputs:
  - name: commit_sha
    type: string
    required: true
    description: "Full SHA1 commit to release (must exist in automation-analytics-backend repo and have image in Quay)"

  - name: release_date
    type: string
    required: false
    default: "{{ today }}"
    description: "Release date for Jira title (YYYY-MM-DD format, defaults to today)"

  - name: include_billing
    type: boolean
    required: false
    default: false
    description: "Also promote the billing component to production"

# No hardcoded constants - resolved dynamically from config.json

steps:

  - name: init_autoheal
    description: "Initialize failure tracking"
    compute: |
      result = {"release_failures": []}
    output: autoheal_state
    on_error: continue

  # ==================== KNOWLEDGE INTEGRATION ====================

  - name: check_release_known_issues
    description: "Check for known release/deployment issues"
    compute: |
      # Check known issues for release operations
      release_issues = memory.check_known_issues("release", "") or {}
      quay_issues = memory.check_known_issues("quay", "") or {}
      appinterface_issues = memory.check_known_issues("app-interface", "") or {}
      deploy_issues = memory.check_known_issues("deploy", "") or {}

      all_issues = []
      for issues in [release_issues, quay_issues, appinterface_issues, deploy_issues]:
          if issues and issues.get("matches"):
              all_issues.extend(issues.get("matches", [])[:2])

      result = {
          "has_known_issues": len(all_issues) > 0,
          "issues": all_issues[:5],
      }
    output: release_known_issues
    on_error: continue

  - name: get_release_gotchas
    description: "Get release-related gotchas from knowledge"
    tool: knowledge_query
    args:
      project: "automation-analytics-backend"
      persona: "release"
      section: "gotchas"
    output: release_gotchas_raw
    on_error: continue

  - name: parse_release_gotchas
    description: "Parse release-related gotchas"
    compute: |
      gotchas_result = release_gotchas_raw if 'release_gotchas_raw' in dir() and release_gotchas_raw else {}

      release_gotchas = []
      if isinstance(gotchas_result, dict) and gotchas_result.get('found'):
          content = gotchas_result.get('content', [])
          if isinstance(content, list):
              # Filter for release-related gotchas
              for g in content:
                  g_str = str(g).lower()
                  if any(kw in g_str for kw in ['release', 'prod', 'deploy', 'sha', 'quay', 'app-interface', 'promote']):
                      release_gotchas.append(g)

      result = {
          'gotchas': release_gotchas[:5],
          'has_gotchas': len(release_gotchas) > 0,
      }
    output: prod_release_gotchas
    on_error: continue

  # ==================== LOAD CONFIG ====================

  - name: load_config
    description: "Load release configuration from config.json"
    compute: |
      import os
      from scripts.common.config_loader import load_config

      config = load_config()
      repos = config.get("repositories", {})
      ai_config = config.get("app_interface", {})
      quay_config = config.get("quay", {})
      ns_config = config.get("namespaces", {}).get("production", {})
      paths_cfg = config.get("paths", {})

      # Get repo paths
      backend_cfg = repos.get("automation-analytics-backend", {})
      ai_cfg = repos.get("app-interface", {})

      # Use workspace_roots as fallback
      workspace_roots = paths_cfg.get("workspace_roots", [])
      default_backend = ""
      default_ai = ""
      for root in workspace_roots:
          if os.path.exists(os.path.join(os.path.expanduser(root), "automation-analytics-backend")):
              default_backend = os.path.join(os.path.expanduser(root), "automation-analytics-backend")
          if os.path.exists(os.path.join(os.path.expanduser(root), "app-interface")):
              default_ai = os.path.join(os.path.expanduser(root), "app-interface")

      result = {
          "backend_repo": backend_cfg.get("path", default_backend),
          "appinterface_repo": ai_cfg.get("path") or ai_config.get("path", default_ai),
          "deploy_file": ai_config.get("deploy_file", "data/services/insights/tower-analytics/cicd/deploy-clowder.yml"),
          "quay_image": f"quay.io/redhat-services-prod/{quay_config.get('repositories', {}).get('automation-analytics', 'aap-aa-tenant/aap-aa-main/automation-analytics-backend-main')}",
          "quay_repository": quay_config.get("repositories", {}).get("automation-analytics", "aap-aa-tenant/aap-aa-main/automation-analytics-backend-main"),
          "namespace_main": ns_config.get("main", "tower-analytics-prod"),
          "namespace_billing": ns_config.get("billing", "tower-analytics-prod-billing"),
          "prod_namespace_pattern": "tower-analytics-prod.yml",
          "billing_namespace_pattern": "tower-analytics-prod-billing.yml",
      }
    output: cfg
  # ==================== VERIFICATION ====================

  # Step 1: Verify commit exists in backend repo
  - name: verify_commit_exists
    description: "Verify the commit SHA exists in automation-analytics-backend"
    tool: git_log
    args:
      repo: "{{ cfg.backend_repo }}"
      limit: 1
    validate:
      - command: "git cat-file -t {{ inputs.commit_sha }}"
        cwd: "{{ cfg.backend_repo }}"
        expect_success: true
        error_message: "Commit {{ inputs.commit_sha }} not found in automation-analytics-backend. Did you fetch latest?"
    output: commit_info

  # Step 2: Verify image exists in Quay
  - name: verify_quay_image
    description: "Verify the container image exists in Quay.io"
    tool: quay_get_tag
    args:
      repository: "aap-aa-tenant/aap-aa-main/automation-analytics-backend-main"
      tag: "{{ inputs.commit_sha }}"
      namespace: "redhat-services-prod"
    validate:
      expect_success: true
      error_message: "Image not found in Quay for SHA {{ inputs.commit_sha }}. Build may not have completed."
    output: quay_image
    on_error: auto_heal  # Quay API - may need auth

  # ==================== GET CURRENT STATE ====================

  # Step 3: Get current production SHA from deploy file
  - name: get_current_prod_sha
    description: "Read current production SHA from app-interface using shared parser"
    compute: |
      from scripts.common.parsers import parse_deploy_clowder_ref

      deploy_path = f"{cfg["appinterface_repo"]}/{cfg["deploy_file"]}"
      with open(deploy_path, 'r') as f:
        content = f.read()

      # Use shared parser to extract ref
      current_sha = parse_deploy_clowder_ref(content, "tower-analytics-prod")

      if not current_sha:
        raise Exception("Could not find production ref in deploy-clowder.yml")

      return current_sha
    output: current_prod_sha

  # Step 4: Get commit log for changelog (using MCP tool)
  - name: get_changelog_log
    description: "Get list of commits being released"
    tool: git_log
    args:
      repo: "{{ cfg.backend_repo }}"
      range: "{{ current_prod_sha }}..{{ inputs.commit_sha }}"
      oneline: true
    output: changelog_raw
    on_error: continue

  - name: format_changelog
    description: "Format changelog output"
    compute: |
      # parsers is available from skill engine safe_globals
      commits_str = str(changelog_raw) if changelog_raw else ""

      if not commits_str.strip() or "error" in commits_str.lower():
        result = "No new commits (same SHA as current production)"
      else:
        commits = parsers.parse_git_log(commits_str) if parsers else []
        commit_count = len(commits)
        result = f"üì¶ {commit_count} commits to release:\n\n{commits_str.strip()}"
    output: changelog

  # ==================== CREATE JIRA ISSUE ====================

  # Step 5: Create release Jira issue
  - name: create_jira_issue
    description: "Create Jira story for tracking this release"
    tool: jira_create_issue
    args:
      issue_type: "story"
      summary: "{{ inputs.release_date }} Analytics HCC Service Release"
    output: jira_issue
    on_error: auto_heal  # Jira API - may need auth refresh

  # ==================== PREPARE APP-INTERFACE ====================

  # Step 6: Ensure app-interface is clean and up to date
  - name: check_appinterface_status
    description: "Check app-interface repo status"
    tool: git_status
    args:
      repo: "{{ cfg.appinterface_repo }}"
    output: appinterface_status

  - name: validate_clean_repo
    description: "Ensure no uncommitted changes"
    validate:
      condition: "'Working tree clean' in appinterface_status or not appinterface_status"
      error_message: "app-interface has uncommitted changes. Please commit or stash them first."

  # Step 7: Checkout master and pull latest
  - name: checkout_master
    description: "Switch to master branch"
    tool: git_checkout
    args:
      repo: "{{ cfg.appinterface_repo }}"
      target: "master"

  - name: fetch_upstream
    description: "Fetch latest from upstream"
    tool: git_fetch
    args:
      repo: "{{ cfg.appinterface_repo }}"
      remote: "upstream"
    on_error: auto_heal  # Git remote - may need auth/network

  - name: rebase_upstream
    description: "Rebase on upstream master"
    tool: git_rebase
    args:
      repo: "{{ cfg.appinterface_repo }}"
      onto: "upstream/master"
    output: pull_result
    on_error: continue

  # Step 8: Get existing branches (using MCP tool)
  - name: list_existing_branches
    description: "Check for existing release branches"
    tool: git_branch_list
    args:
      repo: "{{ cfg.appinterface_repo }}"
      pattern: "aa-release-{{ inputs.release_date }}"
    output: existing_branches_raw
    on_error: continue

  - name: create_branch_name
    description: "Determine branch name (handle existing versions)"
    compute: |
      from scripts.common.parsers import parse_git_branches, get_next_version

      base_name = f"aa-release-{inputs.release_date}"

      # Parse existing branches
      existing = parse_git_branches(str(existing_branches_raw) if existing_branches_raw else "")
      matching = [b for b in existing if base_name in b]

      if not matching:
          branch_name = base_name
          version = 1
      else:
          # Use shared function to get next version
          version = get_next_version(matching, base_name)
          branch_name = f"{base_name}-v{version}"

      result = {"name": branch_name, "version": version, "existing": len(matching)}
    output: branch_info

  - name: create_release_branch
    description: "Create branch for this release"
    tool: git_checkout
    args:
      repo: "{{ cfg.appinterface_repo }}"
      target: "{{ branch_info.name }}"
      force_create: true
    output: branch_result

  - name: set_branch_name
    compute: |
      result = branch_info["name"]
    output: branch_name

  # ==================== UPDATE DEPLOY FILE ====================

  # Step 9: Update production ref in deploy-clowder.yml
  - name: update_prod_ref
    description: "Update production namespace ref to new SHA using shared parser"
    compute: |
      from scripts.common.parsers import update_deploy_clowder_ref

      deploy_path = f"{cfg["appinterface_repo"]}/{cfg["deploy_file"]}"

      with open(deploy_path, 'r') as f:
        content = f.read()

      # Use shared function to update ref
      new_content, success = update_deploy_clowder_ref(content, inputs.commit_sha, "tower-analytics-prod")

      if not success:
        raise Exception("Could not find production ref pattern in deploy-clowder.yml")

      with open(deploy_path, 'w') as f:
        f.write(new_content)

      return f"Updated tower-analytics-prod ref: {current_prod_sha[:12]} ‚Üí {inputs.commit_sha[:12]}"
    output: prod_update_result

  # Step 10: Optionally update billing ref
  - name: update_billing_ref
    description: "Update billing production namespace ref (if requested) using shared parser"
    condition: "{{ inputs.include_billing }}"
    compute: |
      from scripts.common.parsers import update_deploy_clowder_ref

      deploy_path = f"{cfg["appinterface_repo"]}/{cfg["deploy_file"]}"

      with open(deploy_path, 'r') as f:
        content = f.read()

      # Use shared function to update billing ref
      new_content, success = update_deploy_clowder_ref(content, inputs.commit_sha, "tower-analytics-prod-billing")

      if not success:
        raise Exception("Could not find billing production ref pattern")

      with open(deploy_path, 'w') as f:
        f.write(new_content)

      return f"Updated tower-analytics-prod-billing ref to {inputs.commit_sha[:12]}"
    output: billing_update_result

  # ==================== COMMIT AND PUSH ====================

  # Step 11: Stage and commit changes
  - name: stage_changes
    description: "Stage the deploy file changes"
    tool: git_add
    args:
      repo: "{{ cfg.appinterface_repo }}"
      files: "{{ cfg.deploy_file }}"

  - name: build_commit_message
    description: "Build commit message following commit lint rules"
    compute: |
      # Commit format: {issue_key} - {type}({scope}): {description}
      # For releases without a specific Jira issue, use the release Jira if available
      issue_key = jira_issue.get('key', '') if jira_issue else ''

      description = f"release {inputs.commit_sha[:12]} to production"
      if inputs.include_billing:
        description += " (including billing)"

      # The git_commit tool will format this properly with issue_key and commit_type
      result = {
        "description": description,
        "issue_key": issue_key,
      }
    output: commit_message

  - name: commit_changes
    description: "Commit the release changes following commit lint rules"
    tool: git_commit
    args:
      repo: "{{ cfg.appinterface_repo }}"
      message: "{{ commit_message.description }}"
      issue_key: "{{ commit_message.issue_key }}"
      commit_type: "chore"
      scope: "release"

  # Step 12: Push branch to origin
  - name: push_branch
    description: "Push release branch to origin"
    tool: git_push
    args:
      repo: "{{ cfg.appinterface_repo }}"
      branch: "{{ branch_name }}"
      set_upstream: true
    output: push_result

  # Step 13: Build MR title following commit format
  - name: build_mr_title
    description: "Build MR title using config.json commit format"
    compute: |
      from scripts.common.config_loader import format_commit_message

      issue_key = jira_issue.get('key', '') if jira_issue else ''
      description = f"release {inputs.commit_sha[:12]} to production"

      if issue_key:
        # Use the centralized formatter
        title = format_commit_message(
          description=description,
          issue_key=issue_key,
          commit_type="chore",
          scope="release",
        )
      else:
        # Fallback if no Jira issue - still follow format pattern
        title = f"chore(release): tower-analytics {description}"

      result = title
    output: mr_title

  # Step 14: Create merge request
  - name: create_mr
    description: "Create merge request for team approval"
    tool: gitlab_mr_create
    args:
      project: "app-interface"  # Adjust if different
      title: "{{ mr_title }}"
      description: |
        ## Release: {{ inputs.release_date }} Analytics HCC Service

        **Commit SHA:** `{{ inputs.commit_sha }}`
        **Jira:** {{ jira_issue.key if jira_issue else 'N/A' }}

        ### Changes Included
        {{ changelog }}

        ### Components Updated
        - [x] tower-analytics-prod (main)
        {% if inputs.include_billing %}- [x] tower-analytics-prod-billing{% endif %}

        ### Quay Image
        `{{ cfg.quay_image }}:{{ inputs.commit_sha }}`

        ### Checklist
        - [ ] Verified image exists in Quay
        - [ ] Reviewed changelog
        - [ ] Stage has been validated
        - [ ] Ready for production deployment
      target_branch: "master"
      source_branch: "{{ branch_name }}"
      draft: false
    output: mr_result
    on_error: auto_heal  # GitLab API - may need auth refresh

  # ==================== UPDATE JIRA ====================

  # Step 14: Add MR link to Jira issue
  - name: update_jira_with_mr
    description: "Add MR link to Jira issue"
    condition: "{{ jira_issue }}"
    tool: jira_add_comment
    args:
      issue_key: "{{ jira_issue.key }}"
      comment: |
        App-Interface MR created: {{ mr_result.web_url }}

        Releasing commit: {{ inputs.commit_sha }}
        {{ changelog }}
    on_error: auto_heal  # Jira API - may need auth refresh

  # Step 15: Emit release started hook
  - name: emit_release_started_hook
    description: "Notify team channel about release"
    condition: "mr_result"
    compute: |
      # emit_event is available from skill engine safe_globals
      if emit_event:
          # Emit release started
          emit_event("release_started", {
              "sha": inputs.commit_sha[:12],
              "environment": "production",
          })

          # Also emit release MR ready
          emit_event("release_mr_ready", {
              "mr_url": mr_result.get('web_url', ''),
              "sha": inputs.commit_sha[:12],
          })
          result = "hooks sent"
      else:
          result = "hooks skipped: emit_event not available"
    output: release_hook_result
    on_error: continue

  # ==================== SEMANTIC SEARCH ====================

  - name: search_release_code
    description: "Search for code related to this production release"
    tool: code_search
    args:
      query: "production release {{ inputs.commit_sha[:12] }} automation-analytics-backend deploy"
      project: "automation-analytics-backend"
      limit: 3
    output: release_code_raw
    on_error: continue

  - name: parse_release_code
    description: "Parse release code search results"
    condition: "release_code_raw"
    compute: |
      code_result = release_code_raw if release_code_raw else {}

      related_code = []
      if isinstance(code_result, dict) and code_result.get('found'):
          for item in code_result.get('content', []):
              related_code.append(item.get('path', '') + ":" + str(item.get('line_number', '')))

      result = {
          "has_code": len(related_code) > 0,
          "code_snippets": related_code[:5],
      }
    output: release_code_search
    on_error: continue

  # ==================== MEMORY INTEGRATION ====================

  - name: log_release
    description: "Log release to session and track deployment"
    compute: |
      # Use shared memory helpers
      memory.append_to_list(
          "state/environments",
          "recent_deployments",
          {
              "version": inputs.release_date,
              "sha": inputs.commit_sha[:12],
              "environment": "production",
              "deployed_at": memory.get_timestamp(),
              "mr_url": mr_result.get("web_url", "") if mr_result else "",
              "jira_key": jira_issue.get("key", "") if jira_issue else "",
          }
      )
      # Trim to last 10 deployments
      data = memory.read_memory("state/environments")
      if len(data.get("recent_deployments", [])) > 10:
          data["recent_deployments"] = data["recent_deployments"][:10]
          memory.write_memory("state/environments", data)
      result = "deployment tracked"
    output: memory_update_result
    on_error: continue

  - name: session_log_release
    description: "Log release to session"
    tool: memory_session_log
    args:
      action: "Prepared production release {{ inputs.release_date }}"
      details: "SHA: {{ inputs.commit_sha[:12] }}, Jira: {{ jira_issue.key if jira_issue else 'N/A' }}"
    on_error: continue

  - name: track_production_releases
    description: "Track production releases for patterns"
    compute: |
      from datetime import datetime

      # Load patterns
      patterns = memory.read_memory("learned/patterns") or {}
      if "production_releases" not in patterns:
          patterns["production_releases"] = []

      # Record this release
      release_record = {
          "release_date": inputs.release_date,
          "commit_sha": inputs.commit_sha[:40],
          "previous_sha": current_prod_sha[:40] if current_prod_sha else None,
          "include_billing": inputs.include_billing,
          "jira_key": jira_issue.key if jira_issue else None,
          "mr_created": bool(mr_result) if 'mr_result' in dir() else False,
          "timestamp": datetime.now().isoformat(),
      }

      patterns["production_releases"].append(release_record)

      # Keep last 100 releases
      patterns["production_releases"] = patterns["production_releases"][-100:]

      memory.write_memory("learned/patterns", patterns)
      result = "release tracked"
    output: release_tracking_result
    on_error: continue

  - name: update_release_state
    description: "Update release state in memory"
    compute: |
      from datetime import datetime

      # Update release state
      state_data = memory.read_memory("state/releases") or {}
      if "production" not in state_data:
          state_data["production"] = {}

      state_data["production"]["last_release"] = {
          "date": inputs.release_date,
          "sha": inputs.commit_sha[:12],
          "previous_sha": current_prod_sha[:12] if current_prod_sha else None,
          "jira_key": jira_issue.key if jira_issue else None,
          "mr_url": mr_result.get("web_url", "") if mr_result else None,
          "timestamp": datetime.now().isoformat(),
      }

      # Track release frequency
      if "release_count" not in state_data["production"]:
          state_data["production"]["release_count"] = 0
      state_data["production"]["release_count"] += 1

      memory.write_memory("state/releases", state_data)
      result = "release state updated"
    output: release_state_result
    on_error: continue

  # ==================== LEARNING FROM FAILURES ====================

  - name: detect_release_failures
    description: "Detect failure patterns from release operations"
    compute: |
      errors_detected = []

      # Check Quay failures
      quay_text = str(quay_image) if 'quay_image' in dir() and quay_image else ""
      if "not found" in quay_text.lower() or "manifest unknown" in quay_text.lower():
          errors_detected.append({
              "tool": "quay_check_image_exists",
              "pattern": "image not found",
              "cause": "Image not built yet - Konflux build may not have completed",
              "fix": "Wait for Konflux build to complete, check with konflux_list_builds()"
          })

      # Check GitLab MR failures
      mr_text = str(mr_result) if 'mr_result' in dir() and mr_result else ""
      if "no such host" in mr_text.lower():
          errors_detected.append({
              "tool": "gitlab_mr_create",
              "pattern": "no such host",
              "cause": "VPN not connected - internal GitLab not reachable",
              "fix": "Run vpn_connect() to connect to Red Hat VPN"
          })

      # Check Jira failures
      jira_text = str(jira_issue) if 'jira_issue' in dir() and jira_issue else ""
      if "unauthorized" in jira_text.lower():
          errors_detected.append({
              "tool": "jira_create_issue",
              "pattern": "unauthorized",
              "cause": "Jira authentication failed or token expired",
              "fix": "Check Jira credentials in config.json"
          })

      result = errors_detected
    output: release_errors_detected
    on_error: continue

  - name: learn_release_image_failure
    description: "Learn from image not found failures"
    condition: "release_errors_detected and any(e.get('pattern') == 'image not found' for e in release_errors_detected)"
    tool: learn_tool_fix
    args:
      tool_name: "quay_check_image_exists"
      error_pattern: "image not found"
      root_cause: "Image not built yet - Konflux build may not have completed"
      fix_description: "Wait for Konflux build to complete, check with konflux_list_builds()"
    output: release_image_fix_learned
    on_error: continue

  - name: learn_release_vpn_failure
    description: "Learn from GitLab VPN failures"
    condition: "release_errors_detected and any(e.get('pattern') == 'no such host' for e in release_errors_detected)"
    tool: learn_tool_fix
    args:
      tool_name: "gitlab_mr_create"
      error_pattern: "no such host"
      root_cause: "VPN not connected - internal GitLab not reachable"
      fix_description: "Run vpn_connect() to connect to Red Hat VPN"
    output: release_vpn_fix_learned
    on_error: continue

# ==================== OUTPUT ====================

outputs:
  - name: summary
    value: |
      ## ‚úÖ Production Release Prepared

      **Release Date:** {{ inputs.release_date }}
      **Commit SHA:** `{{ inputs.commit_sha }}`

      ### Jira Issue
      {{ jira_issue.key if jira_issue else '‚ö†Ô∏è Jira issue not created' }}

      ### Merge Request
      {{ mr_result.web_url if mr_result else '‚ö†Ô∏è MR not created' }}

      ### Changes Included
      {{ changelog }}

      ### Components
      - ‚úÖ tower-analytics-prod (main)
      {% if inputs.include_billing %}- ‚úÖ tower-analytics-prod-billing{% else %}- ‚è≠Ô∏è tower-analytics-prod-billing (skipped){% endif %}

      ---

      ### Next Steps
      1. üëÄ Review the MR: {{ mr_result.web_url if mr_result else 'N/A' }}
      2. ‚úÖ Get team approval
      3. üöÄ Merge to trigger deployment
      4. üìä Monitor deployment in ArgoCD/App-Interface
      5. ‚úÖ Verify pods are healthy in `tower-analytics-prod`

      ### Monitoring Commands
      ```
      kubectl_get_pods(namespace='tower-analytics-prod', environment='production')
      prometheus_query(query='up{namespace="tower-analytics-prod"}', environment='production')
      ```

      ### Rollback (if needed)
      If issues arise, create a new release with the previous SHA:
      ```
      skill_run("release_aa_backend_prod", '{"commit_sha": "{{ current_prod_sha }}"}')
      ```

      {% if prod_release_gotchas and prod_release_gotchas.has_gotchas %}
      ---

      ### ‚ö†Ô∏è Release Gotchas

      {% for gotcha in prod_release_gotchas.gotchas[:3] %}
      - {{ gotcha }}
      {% endfor %}
      {% endif %}

      {% if release_known_issues and release_known_issues.has_known_issues %}
      ---

      ### üí° Known Issues

      {% for issue in release_known_issues.issues[:3] %}
      - {{ issue.pattern if issue.pattern else issue }}
      {% endfor %}
      {% endif %}

  - name: context
    value:
      jira_key: "{{ jira_issue.key if jira_issue else null }}"
      mr_url: "{{ mr_result.web_url if mr_result else null }}"
      branch: "{{ branch_name }}"
      old_sha: "{{ current_prod_sha }}"
      new_sha: "{{ inputs.commit_sha }}"
      include_billing: "{{ inputs.include_billing }}"
