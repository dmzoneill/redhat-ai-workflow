# Skill: Test MR in Ephemeral Environment
# Deploy PR/MR image to ephemeral namespace and run pytest validation
#
# IMPORTANT: This skill uses MCP tools (aa-bonfire, aa-quay). DO NOT run raw bonfire commands.
# The skill handles: kubeconfig, component names, image tags, and bonfire syntax automatically.

name: test_mr_ephemeral
description: |
  Deploy an MR's image to an ephemeral namespace for testing.
  
  ## How It Works
  1. Gets commit SHA from MR (via GitLab MCP)
  2. Checks if Konflux has built the image (via Quay MCP) - STOPS if not ready
  3. Reserves ephemeral namespace (via bonfire MCP)
  4. Deploys using full SHA image tag (via bonfire_deploy_aa)
  5. Runs pytest against ephemeral DB (optional)
  
  ## Prerequisites
  - Konflux must have built the image (check quay.io/redhat-user-workloads/aap-aa-tenant)
  - User must be logged into ephemeral cluster (run `kube e` once)
  
  ## NEVER Do These Things
  - DO NOT copy kubeconfig files (cp ~/.kube/config.e ~/.kube/config)
  - DO NOT run raw `bonfire deploy` without --set-image-tag with FULL SHA
  - DO NOT use short SHA (8 chars like 8d23cab) - images are tagged with FULL 40-char SHA
  - DO NOT truncate the SHA - Quay only has images tagged with full 40-char commit SHA
  
  ## Why Full SHA Matters
  Konflux tags images with the FULL 40-char git commit SHA, not short form.
  - WRONG: quay.io/.../image:8d23cab (manifest unknown!)
  - RIGHT: quay.io/.../image:8d23cab1234567890abcdef1234567890abcdef12
  
  ## Key Config Values (from config.json)
  - App: tower-analytics
  - Component: tower-analytics-clowdapp (main) or tower-analytics-billing-clowdapp (billing)
  - Image base: quay.io/redhat-user-workloads/aap-aa-tenant/aap-aa-main/automation-analytics-backend-main
  
  ## ITS Deploy Pattern (what bonfire needs)
  - template_ref: Full 40-char git commit SHA
  - IMAGE: quay.io/.../image@sha256 (base + @sha256 suffix)
  - IMAGE_TAG: 64-char sha256 digest from Quay (NOT the git SHA!)
  
  The skill automatically extracts the sha256 digest from Quay after checking the image exists.
  
  ## STOP Conditions
  - If image not in Quay: STOP, tell user to wait for Konflux build
  - If namespace reservation fails: STOP, check cluster login
  
  DO NOT fall back to raw bonfire commands - always use the MCP tools.
version: "1.3"

inputs:
  - name: mr_id
    type: integer
    required: false
    description: "GitLab MR ID (will find the image from Konflux)"
  
  - name: commit_sha
    type: string
    required: false
    description: "Specific commit SHA to test (alternative to mr_id)"
  
  - name: duration
    type: string
    required: false
    default: "2h"
    description: "How long to reserve namespace (e.g., 1h, 2h, 4h)"
  
  - name: run_tests
    type: boolean
    required: false
    default: true
    description: "Run pytest against ephemeral environment"
  
  - name: billing
    type: boolean
    required: false
    default: null
    description: |
      Which ClowdApp to deploy:
      - null (default): AUTO-DETECT from Jira issue and commit diff
      - false: Force tower-analytics-clowdapp (main app)
      - true: Force tower-analytics-billing-clowdapp (billing features)
      
      Auto-detection checks:
      1. Jira issue key in commit ‚Üí search for "billing" in issue
      2. Commit modifies aap_billing_controller/ files
      3. Commit modifies test/processor/aap_billing_controller/ files

  - name: cleanup_on_failure
    type: boolean
    required: false
    default: true
    description: "Release namespace if deployment/tests fail"

  - name: cleanup_on_success
    type: boolean
    required: false
    default: false
    description: "Release namespace after successful tests (default: keep for manual testing)"

# No hardcoded constants - resolved from config.json

steps:
  # ==================== LOAD CONFIG ====================

  - name: load_config
    description: "Load Konflux, Quay, and GitLab configuration"
    compute: |
      import json
      from pathlib import Path

      config_paths = [
          Path.cwd() / "config.json",
          Path.home() / "src/redhat-ai-workflow/config.json",
      ]
      config = {}
      for p in config_paths:
          if p.exists():
              with open(p) as f:
                  config = json.load(f)
              break

      repos = config.get("repositories", {})
      quay_config = config.get("quay", {})
      bonfire_config = config.get("bonfire", {})

      # Get automation-analytics-backend config
      aa_config = repos.get("automation-analytics-backend", {})

      result = {
          "gitlab_project": aa_config.get("gitlab", "automation-analytics/automation-analytics-backend"),
          "konflux_namespace": aa_config.get("konflux_namespace", "aap-aa-tenant"),
          "quay_pr_repo": quay_config.get("repositories", {}).get("automation-analytics", "aap-aa-tenant/aap-aa-main/automation-analytics-backend-main"),
          "quay_pr_namespace": quay_config.get("default_namespace", "redhat-user-workloads"),
          "quay_release_namespace": "redhat-services-prod",
          "ephemeral_kubeconfig": bonfire_config.get("kubeconfig", str(Path.home() / ".kube/config.e")),
      }
    output: cfg

  # ==================== PRE-FLIGHT CHECKS ====================

  # Step 0: Check required tools
  - name: check_tools
    description: "Verify bonfire and kubectl are available"
    compute: |
      import shutil

      required = ["bonfire", "kubectl", "oc"]
      missing = []
      available = []

      for tool in required:
          if shutil.which(tool):
              available.append(tool)
          else:
              missing.append(tool)

      # bonfire is required, kubectl/oc need at least one
      if "bonfire" in missing:
          raise ValueError(
              "bonfire not installed. Install with: pip install crc-bonfire"
          )

      if "kubectl" in missing and "oc" in missing:
          raise ValueError(
              "kubectl or oc not installed. Install OpenShift CLI."
          )

      result = {"available": available, "missing": missing}
    output: tools_check

  # ==================== GET COMMIT SHA ====================

  # Step 1: Get MR info from GitLab (if mr_id provided)
  - name: get_mr_info
    description: "Get MR details from GitLab including short SHA"
    condition: "{{ inputs.mr_id and not inputs.commit_sha }}"
    tool: gitlab_mr_view
    args:
      project: "{{ cfg.gitlab.backend_project }}"
      mr_id: "{{ inputs.mr_id }}"
    output: mr_view_raw
    on_error: continue

  - name: parse_mr_info
    description: "Extract SHA and branch from MR info"
    condition: "{{ inputs.mr_id and not inputs.commit_sha }}"
    compute: |
      import json
      import re
      
      mr_text = str(mr_view_raw) if mr_view_raw else ""
      short_sha = None
      source_branch = None
      
      # Try to parse as JSON first
      try:
        mr_data = json.loads(mr_text)
        short_sha = mr_data.get("sha", "")
        source_branch = mr_data.get("source_branch", "")
      except:
        # Parse from markdown output
        sha_match = re.search(r'SHA[:\s]+`?([a-f0-9]{7,40})`?', mr_text, re.IGNORECASE)
        branch_match = re.search(r'Source[:\s]+`?([^`\s]+)`?', mr_text, re.IGNORECASE)
        if sha_match:
          short_sha = sha_match.group(1)
        if branch_match:
          source_branch = branch_match.group(1)
      
      if not short_sha:
        raise ValueError(f"Could not get SHA for MR {inputs.mr_id}")
      
      result = {"short_sha": short_sha, "branch": source_branch}
    output: mr_parsed

  # Step 1b: Expand short SHA to full 40-char using git_rev_parse
  - name: expand_sha
    description: "Expand short SHA to full 40-char SHA"
    condition: "{{ mr_parsed and mr_parsed.short_sha }}"
    tool: git_rev_parse
    args:
      repo: "{{ cfg.repositories.backend.path }}"
      ref: "{{ mr_parsed.short_sha }}"
    output: full_sha_raw
    on_error: continue

  - name: build_mr_info
    description: "Build mr_info from expanded SHA"
    condition: "{{ mr_parsed }}"
    compute: |
      sha_output = str(full_sha_raw) if full_sha_raw else ""
      
      # Extract SHA (it's the output directly, or in error message)
      sha = sha_output.strip()
      if sha.startswith("‚ùå"):
        raise ValueError(f"Could not expand SHA: {sha}")
      
      if len(sha) != 40:
        raise ValueError(f"Expected 40-char SHA, got: {sha}")
      
      result = {"sha": sha, "branch": mr_parsed.get("branch", "")}
    output: mr_info

  # Step 2: Determine final commit SHA
  - name: resolve_commit
    compute: |
      if inputs.commit_sha:
        sha = inputs.commit_sha
      elif mr_info and mr_info.get('sha'):
        sha = mr_info['sha']
      else:
        sha = None
      result = sha
    output: commit_sha

  # Step 3: Validate we have a commit
  - name: validate_commit
    compute: |
      if not commit_sha:
        raise Exception("Could not determine commit SHA. Provide either mr_id or commit_sha.")
      result = f"Using commit: {commit_sha[:12]}"
    output: commit_status

  # ==================== AUTO-DETECT CLOWDAPP ====================
  # Determine if we should deploy billing or main ClowdApp
  
  # Step 3a: Get commit message using git_show
  - name: get_commit_message
    description: "Get commit message for Jira key extraction"
    tool: git_show
    args:
      repo: "{{ resolved_repo.path }}"
      commit: "{{ commit_sha }}"
      format: "%s%n%b"
    output: commit_message_raw
    on_error: continue

  # Step 3b: Parse commit info
  - name: parse_commit_info
    description: "Extract Jira key and billing keywords from commit"
    compute: |
      import re
      
      commit_message = str(commit_message_raw).strip() if 'commit_message_raw' in dir() and commit_message_raw else ""
      
      # Remove error prefix if present
      if commit_message.startswith("‚ùå"):
        commit_message = ""
      
      # Extract Jira issue key (AAP-XXXXX pattern)
      jira_match = re.search(r'(AAP-\d+)', commit_message, re.IGNORECASE)
      jira_key = jira_match.group(1).upper() if jira_match else None
      
      # Check for billing keywords in commit message itself
      billing_keywords = ['billing', 'subscription', 'vcpu', 'host_count', 'infra_usage']
      commit_has_billing = any(kw in commit_message.lower() for kw in billing_keywords)
      
      result = {
        "message": commit_message[:200],
        "jira_key": jira_key,
        "commit_mentions_billing": commit_has_billing
      }
    output: commit_info
  
  # Step 3b: Check Jira issue for billing indicators
  - name: check_jira_billing
    description: "Look for billing indicators in Jira issue"
    condition: "{{ commit_info.get('jira_key') }}"
    tool: jira_get_issue
    args:
      issue_key: "{{ commit_info.jira_key }}"
    output: jira_issue
    on_error: continue
  
  # Step 3c: Analyze Jira issue for billing signals
  - name: analyze_jira_billing
    description: "Check if Jira issue mentions billing"
    compute: |
      jira_text = str(jira_issue).lower() if jira_issue else ""
      
      billing_signals = [
        'billing',
        'subscription watch',
        'subscription-watch',
        'vcpu',
        'host count',
        'metering',
        'rhsm',
        'red hat subscription',
        'aap-billing',
        'billing-controller',
        'billing controller',
        'billing exporter',
        'swatch',
      ]
      
      found_signals = [s for s in billing_signals if s in jira_text]
      
      result = {
        "is_billing": len(found_signals) > 0,
        "signals": found_signals[:5],  # Top 5 matches
        "jira_checked": bool(jira_issue)
      }
    output: jira_billing_check
  
  # Step 3d: Get files changed in commit
  - name: get_changed_files
    description: "Get list of files changed in this commit"
    tool: git_diff_tree
    args:
      repo: "{{ resolved_repo.path }}"
      commit: "{{ commit_sha }}"
      name_only: true
    output: changed_files_raw
    on_error: continue

  # Step 3e: Check for billing file changes
  - name: check_billing_files
    description: "Check if commit modifies billing-related files"
    compute: |
      changed_files_text = str(changed_files_raw) if 'changed_files_raw' in dir() and changed_files_raw else ""
      
      # Skip if error
      if changed_files_text.startswith("‚ùå"):
        changed_files = []
      else:
        changed_files = [f.strip() for f in changed_files_text.strip().split('\n') if f.strip()]
      
      # Billing-related paths
      billing_paths = [
        'tower_analytics_report/processor/aap_billing_controller',
        'test/processor/aap_billing_controller',
        'aap_billing',
        'billing',
        'subscription_watch',
      ]
      
      billing_files = []
      for f in changed_files:
        for bp in billing_paths:
          if bp in f.lower():
            billing_files.append(f)
            break
      
      result = {
        "total_files_changed": len(changed_files),
        "billing_files_changed": billing_files,
        "has_billing_changes": len(billing_files) > 0
      }
    output: diff_billing_check
  
  # Step 3e: Determine final ClowdApp selection
  - name: determine_clowdapp
    description: "Decide whether to deploy billing or main ClowdApp"
    compute: |
      # If user explicitly specified, use that
      if inputs.billing is not None:
        use_billing = inputs.billing
        reason = "User explicitly specified"
      else:
        # Auto-detect based on signals
        signals = []
        
        # Signal 1: Commit message mentions billing
        if commit_info.get('commit_mentions_billing'):
          signals.append("commit_message")
        
        # Signal 2: Jira issue mentions billing
        if jira_billing_check.get('is_billing'):
          signals.append(f"jira_issue({', '.join(jira_billing_check.get('signals', [])[:2])})")
        
        # Signal 3: Commit changes billing files
        if diff_billing_check.get('has_billing_changes'):
          signals.append(f"files({len(diff_billing_check.get('billing_files_changed', []))} billing files)")
        
        use_billing = len(signals) > 0
        reason = f"Auto-detected: {', '.join(signals)}" if signals else "No billing signals found, using main"
      
      # Select ClowdApp
      if use_billing:
        clowdapp = "tower-analytics-billing-clowdapp"
        template = "clowderapp-billing.yaml"
      else:
        clowdapp = "tower-analytics-clowdapp"
        template = "clowderapp.yaml"
      
      result = {
        "use_billing": use_billing,
        "clowdapp": clowdapp,
        "template": template,
        "reason": reason,
        "jira_key": commit_info.get('jira_key'),
        "billing_files": diff_billing_check.get('billing_files_changed', [])[:5]
      }
    output: clowdapp_selection

  # ==================== CHECK IMAGE EXISTS ====================

  # Step 4: Check if image exists in PR repo (redhat-user-workloads)
  - name: check_quay_image
    description: "Verify the image was built and pushed to Quay (PR repo)"
    tool: quay_get_tag
    args:
      repository: "{{ cfg.quay_pr_repo }}"
      tag: "{{ commit_sha }}"
      namespace: "{{ cfg.quay_pr_namespace }}"
    output: quay_result
    on_error: continue

  # Step 5: If image not found, check Konflux build status
  - name: check_konflux_build
    description: "Check Konflux build status for this commit"
    condition: "{{ not quay_result or 'not found' in str(quay_result).lower() }}"
    tool: konflux_list_builds
    args:
      namespace: "{{ cfg.konflux_namespace }}"
      limit: 10
    output: konflux_builds

  # Step 6: Validate image availability and extract sha256 digest
  - name: validate_image
    compute: |
      import re
      
      quay_output = str(quay_result) if quay_result else ""
      
      if quay_output and 'not found' not in quay_output.lower():
        # Extract the sha256 digest from Manifest Digest line
        # Format: **Manifest Digest:** `sha256:abc123...`
        digest_match = re.search(r'sha256:([a-f0-9]{64})', quay_output)
        if digest_match:
          sha256_digest = digest_match.group(1)  # Just the 64-char hex part
          result = {
            "available": True, 
            "status": "Image ready in Quay",
            "sha256_digest": sha256_digest
          }
        else:
          result = {"available": False, "status": "Could not extract sha256 digest from Quay response"}
      else:
        result = {"available": False, "status": "Image not found - build may be in progress"}
    output: image_status

  # Step 6b: HARD STOP if image not available
  # DO NOT proceed to namespace reservation or deployment if image doesn't exist
  - name: check_image_ready
    description: "STOP if image not built yet"
    compute: |
      if not image_status.get("available", False):
        # Return early with clear message - do NOT try to deploy
        result = {
          "error": True,
          "message": f"STOP: Image for commit {commit_sha[:12] if commit_sha else 'unknown'} not found in Quay.",
          "action": "Wait for Konflux to build the image, then retry.",
          "check_command": f"quay_get_tag(repository='automation-analytics-backend-main', tag='{commit_sha}', namespace='aap-aa-tenant')"
        }
      else:
        result = {"error": False, "message": "Image available, proceeding with deployment"}
    output: image_check

  # ==================== RESERVE NAMESPACE ====================
  # Only proceed if image is available (image_check.error == False)

  # Step 7: Reserve ephemeral namespace
  - name: reserve_namespace
    description: "Reserve an ephemeral namespace"
    condition: "{{ image_status.get('available', False) and not image_check.get('error', True) }}"
    tool: bonfire_namespace_reserve
    args:
      duration: "{{ inputs.duration }}"
      pool: "default"
      timeout: 600
      force: true
    output: namespace_result

  # Step 8: Extract namespace name
  - name: get_namespace_name
    condition: "{{ image_status.get('available', False) and not image_check.get('error', True) }}"
    compute: |
      import re
      
      ns_output = str(namespace_result)
      match = re.search(r'(ephemeral-[a-z0-9]+)', ns_output.lower())
      if match:
        result = match.group(1)
      else:
        result = None
    output: namespace_name

  # ==================== DEPLOY ====================

  # Step 9: Deploy to ephemeral
  # Uses ITS pattern: template_ref = git SHA, image_tag = sha256 digest
  # ClowdApp is auto-detected from Jira/commit or explicitly specified
  - name: deploy_app
    description: "Deploy AA to ephemeral namespace using {{ clowdapp_selection.clowdapp }}"
    condition: "{{ namespace_name and image_status.get('sha256_digest') }}"
    tool: bonfire_deploy_aa
    args:
      namespace: "{{ namespace_name }}"
      template_ref: "{{ commit_sha }}"
      image_tag: "{{ image_status.sha256_digest }}"
      billing: "{{ clowdapp_selection.use_billing }}"
      timeout: 900
    output: deploy_result

  # Step 10: Wait for pods to be ready
  - name: wait_for_ready
    description: "Wait for deployment to be ready"
    condition: "{{ namespace_name and deploy_result }}"
    tool: bonfire_namespace_wait
    args:
      namespace: "{{ namespace_name }}"
      timeout: 300
    output: wait_result
    on_error: continue

  # ==================== GET DB CREDENTIALS ====================

  # Step 11: Get postgres connection info from automation-analytics-db secret
  # Using individual tool calls for each secret key
  
  - name: get_db_host
    description: "Get DB host from secret"
    condition: "{{ namespace_name and inputs.run_tests }}"
    tool: kubectl_get_secret_value
    args:
      secret_name: "automation-analytics-db"
      key: "db.host"
      namespace: "{{ namespace_name }}"
      environment: "ephemeral"
      decode: true
    output: db_host_raw
    on_error: continue

  - name: get_db_port
    description: "Get DB port from secret"
    condition: "{{ namespace_name and inputs.run_tests }}"
    tool: kubectl_get_secret_value
    args:
      secret_name: "automation-analytics-db"
      key: "db.port"
      namespace: "{{ namespace_name }}"
      environment: "ephemeral"
      decode: true
    output: db_port_raw
    on_error: continue

  - name: get_db_user
    description: "Get DB user from secret"
    condition: "{{ namespace_name and inputs.run_tests }}"
    tool: kubectl_get_secret_value
    args:
      secret_name: "automation-analytics-db"
      key: "db.user"
      namespace: "{{ namespace_name }}"
      environment: "ephemeral"
      decode: true
    output: db_user_raw
    on_error: continue

  - name: get_db_password
    description: "Get DB password from secret"
    condition: "{{ namespace_name and inputs.run_tests }}"
    tool: kubectl_get_secret_value
    args:
      secret_name: "automation-analytics-db"
      key: "db.password"
      namespace: "{{ namespace_name }}"
      environment: "ephemeral"
      decode: true
    output: db_password_raw
    on_error: continue

  - name: get_db_name
    description: "Get DB name from secret"
    condition: "{{ namespace_name and inputs.run_tests }}"
    tool: kubectl_get_secret_value
    args:
      secret_name: "automation-analytics-db"
      key: "db.name"
      namespace: "{{ namespace_name }}"
      environment: "ephemeral"
      decode: true
    output: db_name_raw
    on_error: continue

  - name: build_db_credentials
    description: "Build DB credentials object from secret values"
    condition: "{{ namespace_name and inputs.run_tests }}"
    compute: |
      def clean_value(raw, default=""):
        if not raw or str(raw).startswith("‚ùå"):
          return default
        return str(raw).strip()
      
      db_host = clean_value(db_host_raw if 'db_host_raw' in dir() else None)
      db_port = clean_value(db_port_raw if 'db_port_raw' in dir() else None, "5432")
      db_user = clean_value(db_user_raw if 'db_user_raw' in dir() else None)
      db_password = clean_value(db_password_raw if 'db_password_raw' in dir() else None)
      db_name = clean_value(db_name_raw if 'db_name_raw' in dir() else None)
      
      ns = namespace_name
      
      result = {
        "host": db_host or f"automation-analytics-db.{ns}.svc",
        "port": db_port,
        "user": db_user or "postgres",
        "password": db_password or "",
        "database": db_name or "tower-analytics",
        "found": bool(db_host and db_user and db_password),
        "connection_string": f"postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}" if all([db_user, db_password, db_host, db_name]) else None
      }
    output: db_creds

  # Step 12: Check pod status
  - name: check_pods
    description: "Get pod status in namespace"
    condition: "{{ namespace_name }}"
    tool: kubectl_get_pods
    args:
      namespace: "{{ namespace_name }}"
      environment: "ephemeral"
    output: pod_status
    on_error: continue

  # Step 13: Get FastAPI pod name
  # Using kubectl_get_pods tool and then parsing for fastapi pattern
  - name: get_all_pods
    description: "Get all pods in namespace"
    condition: "{{ namespace_name and inputs.run_tests }}"
    tool: kubectl_get_pods
    args:
      namespace: "{{ namespace_name }}"
      environment: "ephemeral"
    output: all_pods_raw
    on_error: continue

  - name: find_fastapi_pod
    description: "Find the FastAPI pod from pod listing"
    condition: "{{ namespace_name and inputs.run_tests and all_pods_raw }}"
    compute: |
      pods_text = str(all_pods_raw) if 'all_pods_raw' in dir() else ""
      
      fastapi_pod = None
      for line in pods_text.split('\n'):
        # Skip header and empty lines
        if not line.strip() or 'NAME' in line:
          continue
        
        parts = line.split()
        if len(parts) >= 3:
          pod_name = parts[0]
          status = parts[2] if len(parts) > 2 else ""
          
          # Find fastapi pod that's Running
          if 'fastapi' in pod_name.lower() and 'Running' in status:
            fastapi_pod = pod_name
            break
      
      result = fastapi_pod
    output: fastapi_pod

  # ==================== RUN TESTS ====================

  # Step 14: Run smoke tests (not full suite - that takes 90 min!)
  # LEARNINGS:
  # - LOG_LEVEL env var causes conflicts (some code expects int, some string) - UNSET it
  # - DATABASE_PREFIX is required by test helpers
  # - Full test suite takes ~90 minutes - only run smoke tests inline
  # - Test directories: test/test_*.py, test/v1/, test/processor/ (no test/restapi/)
  # Step 14a: Create test script locally
  - name: create_test_script
    description: "Create smoke test script with DB credentials"
    condition: "{{ fastapi_pod and db_creds }}"
    compute: |
      import os
      import textwrap
      
      db = db_creds
      ns = namespace_name
      
      # Extract credentials
      db_host = db.get('host', f'automation-analytics-db.{ns}.svc')
      db_port = db.get('port', '5432')
      db_user = db.get('user', 'postgres')
      db_password = db.get('password', '')
      db_name = db.get('database', 'tower-analytics')
      
      # Build DATABASE_PREFIX (required by test helpers)
      database_prefix = f"postgresql://{db_user}:{db_password}@{db_host}:{db_port}"
      database_url = f"{database_prefix}/{db_name}"
      
      # Create smoke test script
      test_script = textwrap.dedent(f"""
          #!/bin/bash
          
          # Database connection from automation-analytics-db secret
          export POSTGRESQL_USER="{db_user}"
          export POSTGRESQL_PASSWORD="{db_password}"
          export POSTGRESQL_HOST="{db_host}"
          export POSTGRESQL_PORT="{db_port}"
          export POSTGRESQL_DATABASE="{db_name}"
          
          # SQLAlchemy-style URLs (required by app and tests)
          export DATABASE_URL="{database_url}"
          export DATABASE_PREFIX="{database_prefix}"
          
          # App settings
          export SECRET_KEY="test-secret-key-12345"
          
          # CRITICAL: Unset LOG_LEVEL - app has conflicting code
          unset LOG_LEVEL
          
          cd /opt/app-root/src
          
          echo "=== Smoke Tests (full suite = 90min, run separately) ==="
          echo "DB: {db_host}:{db_port}/{db_name}"
          echo ""
          
          # Run quick smoke tests only
          pytest test/test_hello.py test/test_db.py test/test_configurator.py test/test_liveness_check.py -v --tb=short 2>&1
          
          echo ""
          echo "=== Smoke tests complete ==="
      """).strip()
      
      # Write script to temp file
      script_path = "/tmp/ephemeral_smoke_test.sh"
      with open(script_path, 'w') as f:
        f.write(test_script)
      os.chmod(script_path, 0o755)
      
      result = script_path
    output: test_script_path

  # Step 14b: Copy test script to pod
  - name: copy_test_script
    description: "Copy smoke test script to FastAPI pod"
    condition: "{{ fastapi_pod and test_script_path }}"
    tool: kubectl_cp
    args:
      source: "{{ test_script_path }}"
      destination: "{{ fastapi_pod }}:/tmp/smoke_test.sh"
      namespace: "{{ namespace_name }}"
      environment: "ephemeral"
      container: "automation-analytics-api-fastapi-v2"
      to_pod: true
    output: copy_result
    on_error: continue

  # Step 14c: Execute smoke tests
  - name: run_smoke_tests
    description: "Execute smoke tests in FastAPI pod"
    condition: "{{ fastapi_pod and copy_result }}"
    tool: kubectl_exec
    args:
      pod_name: "{{ fastapi_pod }}"
      command: "bash /tmp/smoke_test.sh"
      namespace: "{{ namespace_name }}"
      environment: "ephemeral"
      container: "automation-analytics-api-fastapi-v2"
      timeout: 120
    output: test_exec_result
    on_error: continue

  # Step 14d: Parse test results
  - name: parse_test_results
    description: "Parse smoke test output"
    compute: |
      output = str(test_exec_result) if 'test_exec_result' in dir() and test_exec_result else ""
      
      if len(output) > 3000:
        output = output[-3000:]
      
      # Check for pytest success indicators
      passed = "passed" in output.lower() and "failed" not in output.lower()
      
      result = {
        "passed": passed,
        "output": output,
        "smoke_only": True,
        "full_suite_time": "~90 minutes"
      }
    output: test_result

  # ==================== CLEANUP ====================

  # Step 14: Cleanup on failure
  - name: cleanup_on_failure
    description: "Release namespace if deployment or tests failed"
    condition: "namespace_name and inputs.cleanup_on_failure and ((deploy_result and 'fail' in str(deploy_result).lower()) or (test_result and not test_result.get('passed')))"
    tool: bonfire_namespace_release
    args:
      namespace: "{{ namespace_name }}"
    output: cleanup_failure_result
    on_error: continue

  # Step 15: Cleanup on success (if requested)
  - name: cleanup_on_success
    description: "Release namespace after successful tests"
    condition: "namespace_name and inputs.cleanup_on_success and test_result and test_result.get('passed')"
    tool: bonfire_namespace_release
    args:
      namespace: "{{ namespace_name }}"
    output: cleanup_success_result
    on_error: continue

  # Step 16: Determine final cleanup status
  - name: cleanup_status
    description: "Report cleanup status"
    compute: |
      if cleanup_failure_result:
        result = {"cleaned_up": True, "reason": "failure"}
      elif cleanup_success_result:
        result = {"cleaned_up": True, "reason": "success"}
      else:
        result = {"cleaned_up": False, "reason": "kept"}
    output: cleanup_info

  # Step 17: Emit ephemeral hooks
  - name: emit_ephemeral_hooks
    description: "Notify about ephemeral environment status"
    compute: |
      import asyncio
      import sys
      from pathlib import Path
      sys.path.insert(0, str(Path.home() / "src/redhat-ai-workflow"))
      
      try:
          from scripts.skill_hooks import emit_event
          
          # Emit ready notification when deployed
          if namespace_name and deploy_result and 'fail' not in str(deploy_result).lower():
              asyncio.run(emit_event("ephemeral_ready", {
                  "namespace": namespace_name,
                  "mr_id": str(inputs.get('mr_id', '')),
                  "author": "",  # self
              }))
              result = "ephemeral_ready hook sent"
          
          # Emit test failure notification
          if test_result and not test_result.get('passed'):
              asyncio.run(emit_event("ephemeral_tests_failed", {
                  "mr_id": str(inputs.get('mr_id', '')),
                  "namespace": namespace_name or "",
                  "author": "",  # self
              }))
              result = "ephemeral_tests_failed hook sent"
          else:
              result = "no failure hook needed"
      except Exception as e:
          result = f"hook skipped: {e}"
    output: ephemeral_hook_result
    on_error: continue

outputs:
  - name: summary
    value: |
      ## üß™ Ephemeral Test Environment
      
      {% if image_check and image_check.get('error') %}
      ### üõë STOPPED: Image Not Ready
      
      **Commit:** `{{ commit_sha[:12] if commit_sha else 'unknown' }}`
      **Message:** {{ image_check.message }}
      
      **Action Required:** {{ image_check.action }}
      
      #### Check Image Status
      ```python
      # Via MCP tool:
      {{ image_check.check_command }}
      
      # Or check Quay directly:
      # https://quay.io/repository/redhat-user-workloads/aap-aa-tenant/aap-aa-main/automation-analytics-backend-main?tag={{ commit_sha }}
      ```
      
      #### Check Konflux Build
      ```python
      konflux_list_builds(namespace='{{ cfg.konflux_namespace }}')
      ```
      
      **DO NOT** try to deploy manually - wait for the image to be built first.
      
      {% elif not image_status.available %}
      ### ‚ùå Image Not Available
      
      **Commit:** `{{ commit_sha[:12] if commit_sha else 'unknown' }}`
      **Status:** {{ image_status.status }}
      
      The image hasn't been built yet. Check Konflux:
      ```
      konflux_list_builds(namespace='{{ cfg.konflux_namespace }}')
      ```
      
      **Quay (PR images):** `quay.io/{{ cfg.quay_pr_namespace }}/{{ cfg.quay_pr_repo }}`
      
      {% else %}
      **Commit:** `{{ commit_sha[:12] }}`
      **Namespace:** `{{ namespace_name }}`
      **Duration:** {{ inputs.duration }}
      
      ### ClowdApp Selection
      **Component:** `{{ clowdapp_selection.clowdapp }}`
      **Reason:** {{ clowdapp_selection.reason }}
      {% if clowdapp_selection.jira_key %}**Jira:** [{{ clowdapp_selection.jira_key }}](https://issues.redhat.com/browse/{{ clowdapp_selection.jira_key }}){% endif %}
      {% if clowdapp_selection.billing_files %}
      **Billing files changed:**
      {% for f in clowdapp_selection.billing_files %}
      - `{{ f }}`
      {% endfor %}
      {% endif %}
      
      ### Deployment Status
      {% if deploy_result and '‚úÖ' in str(deploy_result) %}
      ‚úÖ Deployed successfully
      {% else %}
      ‚ö†Ô∏è Check deployment status below
      {% endif %}
      
      ### Pod Status
      ```
      {{ pod_status[:600] if pod_status else 'Checking...' }}
      ```
      
      {% if db_creds %}
      ### Database Connection
      - **Host:** `{{ db_creds.host }}`
      - **Port:** `{{ db_creds.port }}`
      - **Database:** `{{ db_creds.database }}`
      - **User:** `{{ db_creds.user }}`
      - **Credentials found:** {{ '‚úÖ' if db_creds.found else '‚ö†Ô∏è Using defaults' }}
      
      {% if db_creds.found %}
      **Connection String:**
      ```
      {{ db_creds.connection_string }}
      ```
      {% endif %}
      {% endif %}
      
      {% if inputs.run_tests and test_result %}
      ### üß™ Test Results
      {% if test_result.passed %}
      ‚úÖ **Tests passed**
      {% else %}
      ‚ùå **Tests failed**
      {% endif %}
      
      ```
      {{ test_result.output[:1000] }}
      ```
      {% endif %}
      
      ---
      
      ### Useful Commands
      
      **Check pods:**
      ```
      kubectl_get_pods(namespace='{{ namespace_name }}', environment='ephemeral')
      ```
      
      **Get logs:**
      ```
      kubectl_logs(pod_name='{{ fastapi_pod }}', namespace='{{ namespace_name }}', environment='ephemeral')
      ```
      
      **Extend time:**
      ```
      bonfire_namespace_extend(namespace='{{ namespace_name }}', duration='1h')
      ```
      
      **Release when done:**
      ```
      bonfire_namespace_release(namespace='{{ namespace_name }}')
      ```
      {% endif %}
  
  - name: context
    value:
      commit_sha: "{{ commit_sha }}"
      namespace: "{{ namespace_name }}"
      image_available: "{{ image_status.available }}"
      deployed: "{{ deploy_result is not none }}"
      tests_passed: "{{ test_result.passed if test_result else 'not run' }}"
      fastapi_pod: "{{ fastapi_pod }}"
      db_host: "{{ db_creds.host if db_creds else none }}"
