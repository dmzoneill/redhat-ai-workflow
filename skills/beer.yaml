# Skill: End of Day Wrap-Up
# Your daily wrap-up assistant - wind down and prepare for tomorrow

name: beer
description: |
  End of day wrap-up - review what you accomplished and prep for tomorrow.

  This skill gathers and summarizes:
  - ‚úÖ Wins: Commits pushed, PRs merged, issues closed
  - üìä Stats: Lines changed, files touched
  - üîÑ WIP: Uncommitted changes, draft PRs
  - ‚è∞ Tomorrow: Early meetings, deadlines
  - üßπ Cleanup: Stale branches, expiring ephemeral envs
  - üìù Standup: Auto-generated standup notes
  - üéØ Follow-ups: PRs needing attention tomorrow

version: "1.0"

inputs:
  - name: generate_standup
    type: boolean
    required: false
    default: true
    description: "Generate standup notes for tomorrow"

  - name: cleanup_prompts
    type: boolean
    required: false
    default: true
    description: "Show cleanup reminders (branches, ephemeral)"

  - name: slack_format
    type: boolean
    required: false
    default: false
    description: "Use Slack link format"

steps:
  # ==================== SEMANTIC SEARCH ====================

  - name: search_eod_code
    description: "Search for code related to end of day activities"
    tool: code_search
    args:
      query: "end of day wrap-up commits PRs standup"
      project: "automation-analytics-backend"
      limit: 3
    output: eod_code_raw
    on_error: continue

  - name: parse_eod_code
    description: "Parse EOD code search results"
    condition: "eod_code_raw"
    compute: |
      code_result = eod_code_raw if eod_code_raw else {}

      related_code = []
      if isinstance(code_result, dict) and code_result.get('found'):
          for item in code_result.get('content', []):
              related_code.append(item.get('path', '') + ":" + str(item.get('line_number', '')))

      result = {
          "has_code": len(related_code) > 0,
          "code_snippets": related_code[:5],
      }
    output: eod_code_search
    on_error: continue

  # ==================== KNOWLEDGE INTEGRATION ====================

  - name: get_project_patterns
    description: "Get project patterns and learnings from knowledge base"
    tool: knowledge_query
    args:
      project: "automation-analytics-backend"
      persona: "developer"
      query: "gotchas"
    output: project_knowledge_raw
    on_error: continue

  - name: parse_project_knowledge
    description: "Parse project knowledge for wrap-up context"
    compute: |
      knowledge_text = str(project_knowledge_raw) if project_knowledge_raw else ""

      gotchas = []
      patterns = []

      # Extract gotchas and patterns for summary
      if knowledge_text:
          for line in knowledge_text.split("\n"):
              line_lower = line.lower()
              if any(kw in line_lower for kw in ["gotcha", "watch out", "note", "important", "remember"]):
                  gotchas.append(line.strip()[:150])
              if any(kw in line_lower for kw in ["pattern", "convention", "best practice", "workflow"]):
                  patterns.append(line.strip()[:150])

      result = {
          "has_knowledge": len(gotchas) > 0 or len(patterns) > 0,
          "gotchas": gotchas[:5],
          "patterns": patterns[:3],
      }
    output: project_knowledge
    on_error: continue

  # ==================== PROACTIVE ISSUE DETECTION ====================

  - name: check_gitlab_known_issues
    description: "Check for known GitLab issues before starting"
    tool: check_known_issues
    args:
      tool_name: "gitlab_mr_list"
      error_text: ""
    output: gitlab_known_issues
    on_error: continue

  - name: check_calendar_known_issues
    description: "Check for known Google Calendar issues before starting"
    tool: check_known_issues
    args:
      tool_name: "google_calendar_events"
      error_text: ""
    output: calendar_known_issues
    on_error: continue

  # ==================== CONFIGURATION ====================

  - name: load_config
    description: "Load configuration using shared loader"
    compute: |
      from datetime import datetime, timedelta
      from zoneinfo import ZoneInfo
      from scripts.common.config_loader import load_config, get_timezone

      config = load_config()
      tz = ZoneInfo(get_timezone())
      now = datetime.now(tz)
      tomorrow = now + timedelta(days=1)

      # Determine greeting based on time
      hour = now.hour
      if hour < 17:
        greeting = "Wrapping up early"
        emoji = "‚òÄÔ∏è"
      elif hour < 20:
        greeting = "Cheers"
        emoji = "üç∫"
      else:
        greeting = "Burning the midnight oil"
        emoji = "üåô"

      result = {
        "config": config,
        "now": now.isoformat(),
        "today": now.strftime("%Y-%m-%d"),
        "tomorrow": tomorrow.strftime("%Y-%m-%d"),
        "day_name": now.strftime("%A"),
        "tomorrow_name": tomorrow.strftime("%A"),
        "time": now.strftime("%H:%M"),
        "greeting": greeting,
        "emoji": emoji,
      }
    output: ctx

  # ==================== MEMORY CONTEXT ====================

  - name: load_current_work
    description: "Load current work state from memory"
    compute: |
      from pathlib import Path
      import yaml

      memory_file = Path.home() / "src/redhat-ai-workflow/memory/state/current_work.yaml"
      current_work = {"active_issues": [], "open_mrs": [], "follow_ups": []}

      if memory_file.exists():
          try:
              with open(memory_file) as f:
                  data = yaml.safe_load(f) or {}
              current_work["active_issues"] = data.get("active_issues", [])
              current_work["open_mrs"] = data.get("open_mrs", [])
              current_work["follow_ups"] = data.get("follow_ups", [])
          except Exception:
              pass

      result = current_work
    output: memory_work

  # ==================== TODAY'S COMMITS ====================

  - name: get_todays_commits
    description: "Get commits you pushed today"
    tool: git_log
    args:
      repo: "automation-analytics-backend"
      author: "{{ ctx.config.user.username }}"
      since: "{{ ctx.today }}"
      limit: 20
    output: todays_commits_raw
    on_error: continue

  - name: parse_todays_commits
    description: "Parse today's commits"
    compute: |
      import re

      commits = []
      raw = str(todays_commits_raw) if todays_commits_raw else ""

      for line in raw.split('\n'):
        match = re.search(r'`([a-f0-9]{7,})\s+(.+?)`', line)
        if match:
          commits.append({
            "sha": match.group(1)[:7],
            "message": match.group(2)[:60]
          })

      # Calculate stats
      result = {
        "commits": commits,
        "count": len(commits)
      }
    output: todays_work
    on_error: continue

  # ==================== UNCOMMITTED CHANGES ====================

  - name: check_uncommitted
    description: "Check for uncommitted work"
    compute: |
      # Will be populated by subsequent tool calls
      result = []
    output: uncommitted_init

  - name: check_backend_status
    description: "Check backend repo for uncommitted changes"
    tool: git_status
    args:
      repo: "automation-analytics-backend"
    output: backend_status_raw
    on_error: continue

  - name: check_workflow_status
    description: "Check workflow repo for uncommitted changes"
    tool: git_status
    args:
      repo: "redhat-ai-workflow"
    output: workflow_status_raw
    on_error: continue

  - name: parse_uncommitted
    description: "Parse uncommitted changes from both repos"
    compute: |
      uncommitted = []

      for repo_name, status_raw in [
        ("automation-analytics-backend", backend_status_raw if 'backend_status_raw' in dir() else None),
        ("redhat-ai-workflow", workflow_status_raw if 'workflow_status_raw' in dir() else None),
      ]:
        if not status_raw:
          continue
        status_text = str(status_raw)
        # Look for modified/added/deleted files in the output
        if "modified:" in status_text or "new file:" in status_text or "deleted:" in status_text:
          # Count changes
          lines = [l.strip() for l in status_text.split('\n') if 'modified:' in l or 'new file:' in l or 'deleted:' in l]
          if lines:
            uncommitted.append({
              "repo": repo_name,
              "files": len(lines),
              "changes": lines[:5]
            })

      result = uncommitted
    output: uncommitted_changes

  # ==================== TODAY'S MERGED PRs ====================

  - name: get_merged_today
    description: "Get PRs merged today"
    tool: gitlab_mr_list
    args:
      project: "automation-analytics/automation-analytics-backend"
      state: "merged"
    output: merged_mrs_raw
    on_error: auto_heal  # GitLab API - may need auth refresh

  - name: parse_merged_today
    description: "Filter for today's merges"
    compute: |
      from scripts.common.parsers import parse_mr_list

      merged_today = parse_mr_list(merged_mrs_raw) if merged_mrs_raw else []
      result = merged_today[:5]  # Top 5 recent merges
    output: merged_today
    on_error: continue

  # ==================== MY OPEN PRs STATUS ====================

  - name: get_my_prs
    description: "Get my open PRs"
    tool: gitlab_mr_list
    args:
      project: "automation-analytics/automation-analytics-backend"
      author: "@me"
    output: my_prs_raw
    on_error: auto_heal  # GitLab API - may need auth refresh

  - name: parse_my_prs
    description: "Parse my open PRs using shared parser"
    compute: |
      from scripts.common.parsers import parse_mr_list

      prs = parse_mr_list(my_prs_raw) if my_prs_raw else []

      # Enrich with draft status
      raw = str(my_prs_raw) if my_prs_raw else ""
      for pr in prs:
        pr_id = str(pr.get('id', ''))
        for line in raw.split('\n'):
          if f"!{pr_id}" in line:
            pr['draft'] = 'draft' in line.lower()
            break

      result = prs
    output: my_prs
    on_error: continue

  # ==================== TOMORROW'S CALENDAR ====================

  - name: get_tomorrows_calendar
    description: "Fetch tomorrow's calendar events"
    compute: |
      from pathlib import Path
      from datetime import datetime, timedelta
      from zoneinfo import ZoneInfo
      import os

      # Read config_dir from config.json, fallback to default
      gc_config = ctx.get('config', {}).get('google_calendar', {})
      config_dir = gc_config.get('config_dir', '~/.config/google_calendar')
      CONFIG_DIR = Path(os.path.expanduser(config_dir))
      TOKEN_FILE = CONFIG_DIR / "token.json"
      TIMEZONE = "Europe/Dublin"
      tz = ZoneInfo(TIMEZONE)

      events_tomorrow = []

      if TOKEN_FILE.exists():
        try:
          from google.oauth2.credentials import Credentials
          from googleapiclient.discovery import build

          creds = Credentials.from_authorized_user_file(str(TOKEN_FILE))
          service = build('calendar', 'v3', credentials=creds)

          # Get tomorrow's events
          tomorrow = datetime.now(tz) + timedelta(days=1)
          start = tomorrow.replace(hour=0, minute=0, second=0).isoformat()
          end = tomorrow.replace(hour=23, minute=59, second=59).isoformat()

          events = service.events().list(
            calendarId='primary',
            timeMin=start,
            timeMax=end,
            singleEvents=True,
            orderBy='startTime'
          ).execute().get('items', [])

          for event in events[:10]:
            start_time = event['start'].get('dateTime', event['start'].get('date', ''))
            if 'T' in start_time:
              time_str = start_time[11:16]
            else:
              time_str = 'All day'

            events_tomorrow.append({
              "time": time_str,
              "title": event.get('summary', 'No title')[:40],
              "meet_link": event.get('hangoutLink', ''),
              "early": time_str < '10:00' if time_str != 'All day' else False
            })
        except Exception as e:
          events_tomorrow = [{"error": str(e)}]

      result = events_tomorrow
    output: tomorrow_calendar
    on_error: continue

  # ==================== EPHEMERAL CLEANUP ====================

  - name: check_ephemeral
    description: "Check ephemeral namespaces for cleanup"
    tool: bonfire_namespace_list
    args:
      mine: true
    output: ephemeral_raw
    on_error: auto_heal  # Ephemeral cluster - may need kube_login

  - name: parse_ephemeral
    description: "Parse ephemeral namespaces"
    compute: |
      from scripts.common.parsers import parse_namespaces

      result = parse_namespaces(ephemeral_raw) if ephemeral_raw else []
    output: ephemeral_namespaces
    on_error: continue

  # ==================== STALE BRANCHES ====================

  - name: get_merged_branches
    description: "Get branches merged into main"
    tool: git_branch_list
    args:
      repo: "automation-analytics-backend"
      merged: "main"
    output: merged_branches_raw
    on_error: continue

  - name: parse_stale_branches
    description: "Extract stale branches (merged but not main/master)"
    compute: |
      stale_branches = []
      raw = str(merged_branches_raw) if 'merged_branches_raw' in dir() and merged_branches_raw else ""

      for line in raw.split('\n'):
        # Parse branch name from output
        if '`' in line:
          # Format: ‚Üí `branch-name` or   `branch-name`
          import re
          match = re.search(r'`([^`]+)`', line)
          if match:
            branch = match.group(1)
            if branch and branch not in ['main', 'master', 'HEAD']:
              stale_branches.append(branch)

      result = stale_branches[:5]  # Top 5
    output: stale_branches

  # ==================== GENERATE STANDUP ====================

  - name: generate_standup_notes
    description: "Generate standup notes for tomorrow"
    condition: "inputs.get('generate_standup', True)"
    compute: |
      from scripts.common.parsers import linkify_jira_keys, linkify_mr_ids
      is_slack = inputs.get('slack_format', True)
      lines = []

      # Yesterday (what I did today)
      lines.append("**Yesterday:**")
      if todays_work and todays_work.get('commits'):
        for c in todays_work['commits'][:3]:
          msg = linkify_jira_keys(c['message'], slack_format=is_slack)
          lines.append(f"- {msg}")
      else:
        lines.append("- (no commits today)")

      # Today (what I'll work on)
      lines.append("")
      lines.append("**Today:**")
      if my_prs:
        for pr in my_prs[:2]:
          if not pr.get('draft'):
            title = linkify_jira_keys(pr['title'], slack_format=is_slack)
            mr_id = linkify_mr_ids(f"!{pr['id']}", slack_format=is_slack)
            lines.append(f"- Continue {mr_id}: {title}")
            break
      else:
        lines.append("- (check Jira board)")

      # Blockers
      lines.append("")
      lines.append("**Blockers:**")
      lines.append("- None")

      result = '\n'.join(lines)
    output: standup_notes
    on_error: continue

  # ==================== WEEKLY STATS ====================

  - name: get_weekly_commits
    description: "Get commits from the past week"
    tool: git_log
    args:
      repo: "automation-analytics-backend"
      since: "1 week ago"
      author: "{{ ctx.config.user.username }}"
      limit: 100
      oneline: true
    output: weekly_commits_raw
    on_error: continue

  - name: get_weekly_numstat
    description: "Get line change stats for the week"
    tool: git_log
    args:
      repo: "automation-analytics-backend"
      since: "1 week ago"
      author: "{{ ctx.config.user.username }}"
      limit: 100
      numstat: true
    output: weekly_numstat_raw
    on_error: continue

  - name: parse_weekly_stats
    description: "Parse weekly activity stats"
    compute: |
      stats = {
        "commits_this_week": 0,
        "lines_added": 0,
        "lines_removed": 0,
      }

      # Count commits
      commits_raw = str(weekly_commits_raw) if 'weekly_commits_raw' in dir() and weekly_commits_raw else ""
      if commits_raw:
        # Count lines that look like commits (short SHA followed by message)
        import re
        commit_lines = [l for l in commits_raw.split('\n') if re.match(r'^[a-f0-9]{7,}', l.strip())]
        stats["commits_this_week"] = len(commit_lines)

      # Parse numstat
      numstat_raw = str(weekly_numstat_raw) if 'weekly_numstat_raw' in dir() and weekly_numstat_raw else ""
      for line in numstat_raw.split('\n'):
        parts = line.split('\t')
        if len(parts) >= 2:
          try:
            added = parts[0].strip()
            removed = parts[1].strip()
            if added.isdigit():
              stats["lines_added"] += int(added)
            if removed.isdigit():
              stats["lines_removed"] += int(removed)
          except:
            pass

      result = stats
    output: weekly_stats

  # ==================== FORMAT BRIEFING ====================

  - name: format_briefing
    description: "Create the end of day wrap-up"
    compute: |
      import re

      lines = []

      # Get user's first name from config
      full_name = ctx.get('config', {}).get('user', {}).get('full_name', 'there')
      first_name = full_name.split()[0] if full_name else 'there'

      # Base URL for GitLab MRs
      gitlab_mr_base = "https://gitlab.cee.redhat.com/automation-analytics/automation-analytics-backend/-/merge_requests"

      # Import shared linkify functions
      from scripts.common.parsers import linkify_jira_keys, linkify_mr_ids

      is_slack = inputs.get('slack_format', True)

      def build_link(url, text):
          if is_slack:
              return f"<{url}|{text}>"
          return f"[{text}]({url})"

      # Header
      lines.append(f"# {ctx['emoji']} {ctx['greeting']}, {first_name}!")
      lines.append("")
      lines.append(f"**{ctx['day_name']}, {ctx['today']}** | {ctx['time']} Irish time")
      lines.append("")
      lines.append("---")
      lines.append("")

      # Today's Wins
      lines.append("## ‚úÖ Today's Wins")
      if todays_work and todays_work.get('count', 0) > 0:
        lines.append(f"**{todays_work['count']}** commits pushed:")
        for c in todays_work.get('commits', [])[:5]:
          msg = linkify_jira_keys(c['message'], slack_format=is_slack)
          lines.append(f"- `{c['sha']}` {msg}")
      else:
        lines.append("- No commits today (and that's okay! üéÑ)")
      lines.append("")

      # Today's Merges
      if merged_today:
        lines.append("## üöÄ Merged Today")
        for mr in merged_today:
          title = linkify_jira_keys(mr['title'], slack_format=is_slack)
          url = f"{gitlab_mr_base}/{mr['id']}"
          lines.append(f"- {build_link(url, '!' + str(mr['id']))} - {title}")
        lines.append("")

      # Weekly Stats
      lines.append("## üìä This Week's Stats")
      if weekly_stats:
        lines.append(f"- **{weekly_stats.get('commits_this_week', 0)}** commits")
        lines.append(f"- **+{weekly_stats.get('lines_added', 0)}** / **-{weekly_stats.get('lines_removed', 0)}** lines")
      else:
        lines.append("- Stats unavailable")
      lines.append("")

      # Uncommitted Work
      if uncommitted_changes:
        lines.append("## üîÑ Uncommitted Work")
        lines.append("‚ö†Ô∏è Don't forget to commit or stash:")
        for uc in uncommitted_changes:
          lines.append(f"- **{uc['repo']}**: {uc['files']} changed files")
        lines.append("")

      # Open PRs
      lines.append("## üîÄ Your Open PRs")
      if my_prs:
        drafts = [p for p in my_prs if p.get('draft')]
        active = [p for p in my_prs if not p.get('draft')]
        lines.append(f"**{len(active)}** active, **{len(drafts)}** draft")
        for pr in active[:3]:
          title_with_links = linkify_jira_keys(pr.get('title', ''), slack_format=is_slack)
          url = f"{gitlab_mr_base}/{pr['id']}"
          lines.append(f"- {build_link(url, '!' + str(pr['id']))} - {title_with_links}")
      else:
        lines.append("- No open PRs")
      lines.append("")

      # Tomorrow's Calendar
      lines.append("## ‚è∞ Tomorrow's Schedule")
      if tomorrow_calendar and not any('error' in e for e in tomorrow_calendar):
        early_meetings = [e for e in tomorrow_calendar if e.get('early')]
        if early_meetings:
          lines.append("**‚ö†Ô∏è Early meetings:**")
          for e in early_meetings:
            lines.append(f"- **{e['time']}** {e['title']} üìπ")

        for e in tomorrow_calendar[:5]:
          if not e.get('early'):
            meet = "üìπ" if e.get('meet_link') else ""
            lines.append(f"- {e['time']} - {e['title']} {meet}")

        if not tomorrow_calendar:
          lines.append("- No meetings tomorrow! üéâ")
      else:
        lines.append("- Calendar not accessible")
      lines.append("")

      # Cleanup Reminders
      if inputs.get('cleanup_prompts', True):
        cleanup_items = []

        if ephemeral_namespaces:
          for ns in ephemeral_namespaces:
            cleanup_items.append(f"üß™ Release `{ns['name']}`? (expires {ns['expires']})")

        if stale_branches:
          for br in stale_branches[:3]:
            cleanup_items.append(f"üåø Delete merged branch `{br}`?")

        if cleanup_items:
          lines.append("## üßπ Cleanup Reminders")
          for item in cleanup_items:
            lines.append(f"- {item}")
          lines.append("")

      # Follow-ups from Memory
      follow_ups = memory_work.get('follow_ups', []) if memory_work else []
      if follow_ups:
        lines.append("## üìå Follow-ups (from memory)")
        for fu in follow_ups[:5]:
          task = fu.get('task', 'Unknown task')
          priority = fu.get('priority', 'normal')
          due = fu.get('due', '')
          emoji = "üî¥" if priority == "high" else "üü°" if priority == "medium" else "‚ö™"
          due_str = f" (due: {due})" if due else ""
          lines.append(f"- {emoji} {task}{due_str}")
        lines.append("")

      # Standup Notes
      if standup_notes:
        lines.append("## üìù Tomorrow's Standup (ready to paste)")
        lines.append("```")
        lines.append(standup_notes)
        lines.append("```")
        lines.append("")

      # Sign off
      lines.append("---")
      lines.append("")

      # Fun sign-off based on day
      day = ctx['day_name']
      if day == 'Friday':
        lines.append("üçª **Happy Friday!** Have a great weekend!")
      elif day == 'Thursday':
        lines.append("üç∫ Almost there! One more day to Friday.")
      else:
        lines.append("üç∫ Have a good evening!")

      result = '\n'.join(lines)
    output: briefing

  # ==================== MEMORY UPDATES ====================

  - name: log_beer_session
    description: "Log end of day wrap-up to session"
    tool: memory_session_log
    args:
      action: "End of day wrap-up (beer)"
      details: "Commits: {{ todays_work.count if todays_work else 0 }}, PRs: {{ my_prs | length if my_prs else 0 }}"
    on_error: continue

  - name: update_work_state
    description: "Sync memory with actual work state at end of day"
    compute: |
      from datetime import datetime

      # Update current work with fresh data
      current_work = memory.read_memory("state/current_work") or {}

      # Save today's summary
      if "daily_summaries" not in current_work:
          current_work["daily_summaries"] = []

      current_work["daily_summaries"].append({
          "date": ctx.get("today", datetime.now().strftime("%Y-%m-%d")),
          "commits": todays_work.get("count", 0) if todays_work else 0,
          "open_prs": len(my_prs) if my_prs else 0,
          "merged_today": len(merged_today) if merged_today else 0,
          "uncommitted_repos": len(uncommitted_changes) if uncommitted_changes else 0,
      })

      # Keep last 30 days
      current_work["daily_summaries"] = current_work["daily_summaries"][-30:]

      current_work["last_beer"] = datetime.now().isoformat()

      memory.write_memory("state/current_work", current_work)
      result = "work state synced for EOD"
    output: work_sync_result
    on_error: continue

  - name: learn_daily_patterns
    description: "Learn from daily activity patterns"
    compute: |
      from datetime import datetime

      # Load patterns
      patterns = memory.read_memory("learned/patterns") or {}
      if "daily_patterns" not in patterns:
          patterns["daily_patterns"] = []

      # Record today's pattern
      day_record = {
          "date": ctx.get("today", datetime.now().strftime("%Y-%m-%d")),
          "day_of_week": ctx.get("day_name", datetime.now().strftime("%A")),
          "commits": todays_work.get("count", 0) if todays_work else 0,
          "weekly_commits": weekly_stats.get("commits_this_week", 0) if weekly_stats else 0,
          "lines_added": weekly_stats.get("lines_added", 0) if weekly_stats else 0,
          "lines_removed": weekly_stats.get("lines_removed", 0) if weekly_stats else 0,
          "stale_branches": len(stale_branches) if stale_branches else 0,
          "ephemeral_envs": len(ephemeral_namespaces) if ephemeral_namespaces else 0,
      }

      patterns["daily_patterns"].append(day_record)

      # Keep last 90 days
      patterns["daily_patterns"] = patterns["daily_patterns"][-90:]

      memory.write_memory("learned/patterns", patterns)
      result = "daily patterns learned"
    output: pattern_learn_result
    on_error: continue

  - name: save_standup_for_tomorrow
    description: "Save standup notes for tomorrow morning"
    condition: "standup_notes"
    compute: |
      from datetime import datetime, timedelta

      # Save standup for tomorrow's coffee
      shared = memory.read_memory("state/shared_context") or {}

      tomorrow = (datetime.now() + timedelta(days=1)).strftime("%Y-%m-%d")
      shared["prepared_standup"] = {
          "date": tomorrow,
          "notes": standup_notes,
          "generated_at": datetime.now().isoformat(),
      }

      memory.write_memory("state/shared_context", shared)
      result = "standup notes saved for tomorrow"
    output: standup_save_result
    on_error: continue

  # ==================== LEARNING FROM FAILURES ====================

  - name: detect_beer_failures
    description: "Detect failure patterns from EOD data gathering"
    compute: |
      errors_detected = []

      # Check git failures
      git_text = str(todays_commits_raw) if 'todays_commits_raw' in dir() and todays_commits_raw else ""
      if "permission denied" in git_text.lower():
          errors_detected.append({
              "tool": "git_log",
              "pattern": "permission denied",
              "cause": "Git repository access denied",
              "fix": "Check repository permissions and SSH keys"
          })

      # Check GitLab failures
      gitlab_text = str(my_prs_raw) if 'my_prs_raw' in dir() and my_prs_raw else ""
      if "no such host" in gitlab_text.lower():
          errors_detected.append({
              "tool": "gitlab_mr_list",
              "pattern": "no such host",
              "cause": "VPN not connected - internal GitLab not reachable",
              "fix": "Run vpn_connect() to connect to Red Hat VPN"
          })

      # Check calendar failures
      calendar_text = str(tomorrow_calendar_raw) if 'tomorrow_calendar_raw' in dir() and tomorrow_calendar_raw else ""
      if "oauth" in calendar_text.lower() or "token" in calendar_text.lower():
          errors_detected.append({
              "tool": "google_calendar_events",
              "pattern": "oauth token",
              "cause": "Google OAuth token expired or not configured",
              "fix": "Run setup-gmail to refresh OAuth tokens"
          })

      # Check bonfire failures
      bonfire_text = str(ephemeral_namespaces_raw) if 'ephemeral_namespaces_raw' in dir() and ephemeral_namespaces_raw else ""
      if "no route to host" in bonfire_text.lower():
          errors_detected.append({
              "tool": "bonfire_namespace_list",
              "pattern": "no route to host",
              "cause": "VPN not connected - ephemeral cluster not reachable",
              "fix": "Run vpn_connect() and kube_login('ephemeral')"
          })

      result = errors_detected
    output: beer_errors_detected
    on_error: continue

  - name: learn_beer_vpn_failure
    description: "Learn from GitLab VPN failures"
    condition: "beer_errors_detected and any(e.get('pattern') == 'no such host' for e in beer_errors_detected)"
    tool: learn_tool_fix
    args:
      tool_name: "gitlab_mr_list"
      error_pattern: "no such host"
      root_cause: "VPN not connected - internal GitLab not reachable"
      fix_description: "Run vpn_connect() to connect to Red Hat VPN"
    output: beer_vpn_fix_learned
    on_error: continue

  - name: learn_beer_calendar_failure
    description: "Learn from Google Calendar OAuth failures"
    condition: "beer_errors_detected and any(e.get('pattern') == 'oauth token' for e in beer_errors_detected)"
    tool: learn_tool_fix
    args:
      tool_name: "google_calendar_events"
      error_pattern: "oauth token"
      root_cause: "Google OAuth token expired or not configured"
      fix_description: "Run setup-gmail to refresh OAuth tokens"
    output: beer_calendar_fix_learned
    on_error: continue

  - name: learn_beer_bonfire_failure
    description: "Learn from bonfire VPN failures"
    condition: "beer_errors_detected and any(e.get('pattern') == 'no route to host' for e in beer_errors_detected)"
    tool: learn_tool_fix
    args:
      tool_name: "bonfire_namespace_list"
      error_pattern: "no route to host"
      root_cause: "VPN not connected - ephemeral cluster not reachable"
      fix_description: "Run vpn_connect() and kube_login('ephemeral')"
    output: beer_bonfire_fix_learned
    on_error: continue

  - name: log_beer_session
    description: "Log EOD wrap-up to session"
    tool: memory_session_log
    args:
      action: "EOD wrap-up completed"
      details: "{{ todays_work.count if todays_work else 0 }} commits, {{ my_prs | length if my_prs else 0 }} open PRs"
    on_error: continue

outputs:
  - name: summary
    value: "{{ briefing }}"

  - name: context
    value:
      commits_today: "{{ todays_work.count if todays_work else 0 }}"
      uncommitted_repos: "{{ uncommitted_changes | length if uncommitted_changes else 0 }}"
      open_prs: "{{ my_prs | length if my_prs else 0 }}"
      meetings_tomorrow: "{{ tomorrow_calendar | length if tomorrow_calendar else 0 }}"
      ephemeral_to_clean: "{{ ephemeral_namespaces | length if ephemeral_namespaces else 0 }}"
      stale_branches: "{{ stale_branches | length if stale_branches else 0 }}"
