# Skill: Weekly Summary
# Generate a summary of work from session logs

name: weekly_summary
description: |
  Generate a summary of work from session logs.

  Aggregates session logs from the past week (or specified period)
  and provides a summary of:
  - Issues worked on
  - MRs created/reviewed
  - Deployments and debugging sessions
  - Patterns learned

  Useful for weekly reports or sprint reviews.

version: "1.1"

inputs:
  - name: days
    type: integer
    required: false
    default: 7
    description: "Number of days to look back (default: 7)"

  - name: format
    type: string
    required: false
    default: "markdown"
    description: "Output format: 'markdown' or 'slack'"

  - name: repo
    type: string
    required: false
    default: "automation-analytics-backend"
    description: "Repository to get commit history from"

steps:

  - name: init_autoheal
    description: "Initialize failure tracking"
    compute: |
      result = {"failures": []}
    output: autoheal_state
    on_error: continue

  # ==================== GATHER DATA FROM MULTIPLE SOURCES ====================

  - name: get_recent_commits
    description: "Get commits from the past week"
    tool: git_log
    args:
      repo: "{{ inputs.repo }}"
      since: "{{ inputs.days }} days ago"
      author: ""
    output: commits_raw
    on_error: continue

  - name: get_my_jira_issues
    description: "Get my recently updated Jira issues"
    tool: jira_my_issues
    args:
      max_results: 20
    output: jira_issues_raw
    on_error: continue

  - name: get_my_mrs
    description: "Get my recent merge requests"
    tool: gitlab_mr_list
    args:
      project: "automation-analytics/automation-analytics-backend"
      state: "all"
      per_page: 10
    output: mrs_raw
    on_error: continue

  - name: get_recent_releases
    description: "Get recent Konflux releases"
    tool: konflux_list_releases
    args:
      namespace: "aap-aa-tenant"
      limit: 5
    output: releases_raw
    on_error: continue

  - name: get_recent_images
    description: "Get recent image tags from Quay"
    tool: quay_list_aa_tags
    args:
      limit: 10
    output: quay_tags_raw
    on_error: continue

  - name: search_slack_discussions
    description: "Search Slack for relevant team discussions"
    tool: slack_search_messages
    args:
      query: "in:team-automation-analytics after:{{ inputs.days }}d"
      limit: 20
    output: slack_discussions_raw
    on_error: continue

  - name: parse_slack_discussions
    description: "Parse Slack discussions"
    compute: |
      slack_text = str(slack_discussions_raw) if 'slack_discussions_raw' in dir() and slack_discussions_raw else ""

      discussions = []
      for line in slack_text.split("\n")[:20]:
          if line.strip():
              discussions.append(line.strip()[:100])

      # Look for important topics
      important = []
      keywords = ["deploy", "release", "bug", "urgent", "hotfix", "incident", "outage"]
      for msg in discussions:
          if any(kw in msg.lower() for kw in keywords):
              important.append(msg)

      result = {
          "total": len(discussions),
          "discussions": discussions[:10],
          "important": important[:5],
          "has_slack": len(discussions) > 0,
      }
    output: slack_activity
    on_error: continue

  # ==================== READ SESSION LOGS ====================

  - name: get_session_logs
    description: "Read session logs from memory directory"
    compute: |
      from pathlib import Path
      from datetime import datetime, timedelta
      import yaml

      days = inputs.get("days", 7)
      cutoff = datetime.now() - timedelta(days=days)

      logs_dir = Path.home() / "src/redhat-ai-workflow/memory/logs"
      session_entries = []

      if logs_dir.exists():
          for log_file in sorted(logs_dir.glob("*.yaml"), reverse=True):
              try:
                  # Parse date from filename (e.g., 2024-01-15.yaml)
                  date_str = log_file.stem
                  log_date = datetime.strptime(date_str, "%Y-%m-%d")

                  if log_date >= cutoff:
                      with open(log_file) as f:
                          data = yaml.safe_load(f) or {}

                      for entry in data.get("entries", []):
                          entry["date"] = date_str
                          session_entries.append(entry)
              except (ValueError, yaml.YAMLError) as e:
                  continue

      result = {
          "entries": session_entries,
          "count": len(session_entries),
          "days_covered": days,
      }
    output: logs

  - name: load_current_work
    description: "Load current work state"
    tool: memory_read
    args:
      key: "state/current_work"
    output: current_work_raw
    on_error: continue

  - name: parse_external_data
    description: "Parse data from git, jira, gitlab, konflux"
    compute: |
      # Parse commits
      commits_text = str(commits_raw) if commits_raw else ""
      commit_count = commits_text.count("\n") if commits_text else 0

      # Parse Jira issues
      jira_text = str(jira_issues_raw) if jira_issues_raw else ""
      import re
      jira_keys = re.findall(r'AAP-\d+', jira_text)
      unique_jira = list(set(jira_keys))[:10]

      # Parse MRs
      mrs_text = str(mrs_raw) if mrs_raw else ""
      mr_ids = re.findall(r'!(\d+)', mrs_text)
      unique_mrs = list(set(mr_ids))[:10]

      # Parse releases
      releases_text = str(releases_raw) if releases_raw else ""
      release_count = releases_text.lower().count("release") if releases_text else 0

      # Parse Quay tags
      quay_text = str(quay_tags_raw) if quay_tags_raw else ""
      tag_count = len(re.findall(r'[a-f0-9]{40}', quay_text))

      result = {
          "commit_count": commit_count,
          "jira_issues": unique_jira,
          "gitlab_mrs": unique_mrs,
          "release_count": release_count,
          "image_count": tag_count,
          "commits_sample": commits_text[:500] if commits_text else "",
      }
    output: external_data

  - name: analyze_logs
    description: "Analyze session logs for summary"
    compute: |
      import re
      from collections import defaultdict
      import yaml

      entries = logs.get("entries", [])

      # Categories to track
      issues_worked = set()
      mrs_created = set()
      mrs_reviewed = set()
      deployments = []
      debug_sessions = []
      patterns_learned = []
      notifications_sent = []
      other_actions = []

      for entry in entries:
          action = entry.get("action", "")
          details = entry.get("details", "")
          date = entry.get("date", "")

          # Extract Jira issues
          jira_matches = re.findall(r"AAP-\d+", action + " " + details)
          issues_worked.update(jira_matches)

          # Extract MR IDs
          mr_matches = re.findall(r"!(\d+)", action)
          for mr_id in mr_matches:
              if "Created MR" in action or "create" in action.lower():
                  mrs_created.add(mr_id)
              elif "Reviewed" in action or "review" in action.lower():
                  mrs_reviewed.add(mr_id)

          # Categorize actions
          action_lower = action.lower()
          if "deployed" in action_lower or "ephemeral" in action_lower:
              deployments.append({"date": date, "action": action})
          elif "debug" in action_lower or "investigated" in action_lower:
              debug_sessions.append({"date": date, "action": action})
          elif "learned pattern" in action_lower:
              patterns_learned.append({"date": date, "action": action})
          elif "notified" in action_lower:
              notifications_sent.append({"date": date, "action": action})
          elif "Started work" in action or "Closed issue" in action:
              pass  # Already captured via issues_worked
          else:
              other_actions.append({"date": date, "action": action})

      # Parse current work for active items
      current_work = {}
      if current_work_raw and isinstance(current_work_raw, str):
          try:
              current_work = yaml.safe_load(current_work_raw) or {}
          except:
              pass

      result = {
          "issues_worked": list(issues_worked),
          "mrs_created": list(mrs_created),
          "mrs_reviewed": list(mrs_reviewed),
          "deployments": deployments[:10],
          "debug_sessions": debug_sessions[:10],
          "patterns_learned": patterns_learned,
          "notifications": notifications_sent[:10],
          "other": other_actions[:20],
          "active_issues": current_work.get("active_issues", []),
          "open_mrs": current_work.get("open_mrs", []),
          "total_entries": logs.get("count", 0),
      }
    output: analysis

  - name: format_summary
    description: "Format summary for output"
    compute: |
      lines = []
      fmt = inputs.get("format", "markdown")
      is_slack = fmt == "slack"

      if is_slack:
          lines.append("*ğŸ“Š Weekly Summary*\n")
      else:
          lines.append("# ğŸ“Š Weekly Summary\n")
          lines.append(f"*{analysis['total_entries']} session entries over {logs['days_covered']} days*\n")

      # Issues worked
      if analysis["issues_worked"]:
          if is_slack:
              lines.append(f"*Issues Worked:* {len(analysis['issues_worked'])}")
              lines.append(", ".join(analysis["issues_worked"][:10]))
          else:
              lines.append("## ğŸ« Issues Worked")
              for issue in analysis["issues_worked"][:10]:
                  lines.append(f"- [{issue}](https://issues.redhat.com/browse/{issue})")
          lines.append("")

      # MRs
      if analysis["mrs_created"] or analysis["mrs_reviewed"]:
          if is_slack:
              lines.append(f"*MRs:* {len(analysis['mrs_created'])} created, {len(analysis['mrs_reviewed'])} reviewed")
          else:
              lines.append("## ğŸ”€ Merge Requests")
              if analysis["mrs_created"]:
                  lines.append(f"**Created:** {', '.join(['!' + mr for mr in analysis['mrs_created'][:5]])}")
              if analysis["mrs_reviewed"]:
                  lines.append(f"**Reviewed:** {', '.join(['!' + mr for mr in analysis['mrs_reviewed'][:5]])}")
          lines.append("")

      # Deployments
      if analysis["deployments"]:
          if is_slack:
              lines.append(f"*Deployments:* {len(analysis['deployments'])}")
          else:
              lines.append("## ğŸš€ Deployments")
              for d in analysis["deployments"][:5]:
                  lines.append(f"- {d['date']}: {d['action']}")
          lines.append("")

      # Debug sessions
      if analysis["debug_sessions"]:
          if is_slack:
              lines.append(f"*Debug Sessions:* {len(analysis['debug_sessions'])}")
          else:
              lines.append("## ğŸ” Debug Sessions")
              for d in analysis["debug_sessions"][:5]:
                  lines.append(f"- {d['date']}: {d['action']}")
          lines.append("")

      # Patterns learned
      if analysis["patterns_learned"]:
          if is_slack:
              lines.append(f"*Patterns Learned:* {len(analysis['patterns_learned'])}")
          else:
              lines.append("## ğŸ“š Patterns Learned")
              for p in analysis["patterns_learned"]:
                  lines.append(f"- {p['date']}: {p['action']}")
          lines.append("")

      # Currently active
      if analysis["active_issues"] or analysis["open_mrs"]:
          if not is_slack:
              lines.append("## ğŸ¯ Currently Active")
              if analysis["active_issues"]:
                  lines.append("**Active Issues:**")
                  for issue in analysis["active_issues"][:5]:
                      lines.append(f"- {issue.get('key', '?')}: {issue.get('summary', 'No summary')[:50]}")
              if analysis["open_mrs"]:
                  lines.append("**Open MRs:**")
                  for mr in analysis["open_mrs"][:5]:
                      lines.append(f"- !{mr.get('id', '?')}: {mr.get('title', 'No title')[:50]}")
          lines.append("")

      result = "\n".join(lines)
    output: formatted_summary

outputs:
  - name: summary
    value: |
      {{ formatted_summary }}

      ## ğŸ“ˆ Activity Metrics

      | Source | Count |
      |--------|-------|
      | Commits ({{ inputs.repo }}) | {{ external_data.commit_count }} |
      | Jira Issues Touched | {{ external_data.jira_issues|length }} |
      | GitLab MRs | {{ external_data.gitlab_mrs|length }} |
      | Konflux Releases | {{ external_data.release_count }} |
      | Images Built | {{ external_data.image_count }} |

      {% if external_data.jira_issues %}
      ### Jira Issues
      {% for issue in external_data.jira_issues[:5] %}
      - [{{ issue }}](https://issues.redhat.com/browse/{{ issue }})
      {% endfor %}
      {% endif %}

      {% if external_data.gitlab_mrs %}
      ### GitLab MRs
      {% for mr in external_data.gitlab_mrs[:5] %}
      - !{{ mr }}
      {% endfor %}
      {% endif %}

      ---

      *Generated from {{ analysis.total_entries }} session log entries + live data.*
