# Skill: Learn Pattern
# Save a new error pattern to memory for future recognition

name: learn_pattern
description: |
  Save a new error pattern to memory.

  When you discover a new error pattern and its fix, use this skill
  to remember it for future debugging sessions.

  The pattern is saved to memory/learned/patterns.yaml and will be
  automatically matched during investigate_alert and debug_prod skills.

version: "1.0"

inputs:
  - name: pattern
    type: string
    required: true
    description: "Short name for the pattern (e.g., 'OOMKilled', 'ImagePullBackOff')"

  - name: meaning
    type: string
    required: true
    description: "What this error means (e.g., 'Container exceeded memory limit')"

  - name: fix
    type: string
    required: true
    description: "How to fix this error (e.g., 'Increase memory limits in deployment')"

  - name: commands
    type: string
    required: false
    description: "Comma-separated commands to run for diagnosis (e.g., 'kubectl describe pod X,kubectl logs X')"

  - name: category
    type: string
    required: false
    default: "general"
    description: "Category: pod_errors, log_patterns, network, general"

steps:
  - name: validate_inputs
    description: "Validate inputs"
    compute: |
      # Basic validation
      pattern = inputs.get("pattern", "").strip()
      meaning = inputs.get("meaning", "").strip()
      fix = inputs.get("fix", "").strip()

      if not pattern:
          result = {"valid": False, "error": "Pattern name is required"}
      elif not meaning:
          result = {"valid": False, "error": "Meaning is required"}
      elif not fix:
          result = {"valid": False, "error": "Fix is required"}
      else:
          result = {"valid": True, "pattern": pattern, "meaning": meaning, "fix": fix}
    output: validation

  - name: parse_commands
    description: "Parse comma-separated commands"
    condition: "validation.valid"
    compute: |
      commands_str = inputs.get("commands", "")
      if commands_str:
          result = [cmd.strip() for cmd in commands_str.split(",") if cmd.strip()]
      else:
          result = []
    output: command_list

  - name: validate_tool_existence
    description: "Check if tools in commands actually exist"
    condition: "command_list"
    compute: |
      # Known tools from all modules (partial list for basic validation)
      known_tools = [
        # Workflow
        "vpn_connect", "kube_login", "session_start", "persona_load",
        "memory_read", "memory_write", "memory_append", "memory_update",
        "check_known_issues", "learn_tool_fix", "debug_tool",
        # Git
        "git_status", "git_branch_create", "git_checkout", "git_commit",
        "git_push", "git_pull", "git_log", "git_diff",
        # GitLab
        "gitlab_mr_list", "gitlab_mr_view", "gitlab_mr_create", "gitlab_mr_update",
        "gitlab_ci_status", "gitlab_ci_view", "gitlab_ci_run",
        # Jira
        "jira_view_issue", "jira_set_status", "jira_assign", "jira_add_comment",
        "jira_my_issues", "jira_search", "jira_lint",
        # K8s
        "kubectl_get_pods", "kubectl_describe_pod", "kubectl_logs",
        "kubectl_get_events", "kubectl_get_deployments", "kubectl_rollout_restart",
        "k8s_namespace_health", "kubectl_top_pods",
        # Bonfire
        "bonfire_namespace_list", "bonfire_namespace_reserve",
        "bonfire_namespace_release", "bonfire_deploy", "bonfire_namespace_describe",
        # Prometheus
        "prometheus_query", "prometheus_alerts", "prometheus_query_range",
        # Konflux
        "konflux_list_builds", "konflux_list_snapshots", "konflux_get_build_logs",
        # Quay
        "quay_get_tag", "quay_get_vulnerabilities", "quay_list_tags",
        # Others
        "kibana_get_errors", "kibana_search_logs",
        "alertmanager_list_silences", "alertmanager_create_silence",
      ]

      invalid_tools = []
      warnings = []

      for cmd in command_list:
        # Extract tool name (before first '(' or whitespace)
        tool_name = cmd.split('(')[0].strip()

        if tool_name and tool_name not in known_tools:
          # Check if it might be a kubectl/oc command (allowed)
          if tool_name.startswith(('kubectl', 'oc', 'bonfire', 'git', 'glab')):
            warnings.append(f"'{tool_name}' appears to be a CLI command - consider using MCP tool instead")
          else:
            invalid_tools.append(tool_name)

      if invalid_tools:
        result = {
          "valid": False,
          "unknown_tools": invalid_tools,
          "suggestion": "Double-check tool names. Unknown tools: " + ", ".join(invalid_tools)
        }
      elif warnings:
        result = {
          "valid": True,
          "warnings": warnings
        }
      else:
        result = {"valid": True}
    output: tool_check

  - name: save_pattern
    description: "Save pattern to memory"
    condition: "validation.valid and tool_check.get('valid', True)"
    compute: |
      from pathlib import Path
      from datetime import datetime
      import yaml

      patterns_file = Path.home() / "src/redhat-ai-workflow/memory/learned/patterns.yaml"
      category = inputs.get("category", "general")

      try:
          if patterns_file.exists():
              with open(patterns_file) as f:
                  data = yaml.safe_load(f) or {}
          else:
              patterns_file.parent.mkdir(parents=True, exist_ok=True)
              data = {}

          # Ensure category exists
          if category not in data:
              data[category] = []

          # Build new pattern entry
          new_pattern = {
              "pattern": validation["pattern"],
              "meaning": validation["meaning"],
              "fix": validation["fix"],
          }
          if command_list:
              new_pattern["commands"] = command_list

          # Check if pattern already exists - update if so
          existing_idx = None
          for i, p in enumerate(data[category]):
              if p.get("pattern") == validation["pattern"]:
                  existing_idx = i
                  break

          if existing_idx is not None:
              data[category][existing_idx] = new_pattern
              action = "updated"
          else:
              data[category].append(new_pattern)
              action = "added"

          data["last_updated"] = datetime.now().isoformat()

          with open(patterns_file, "w") as f:
              yaml.dump(data, f, default_flow_style=False, sort_keys=False)

          result = {
              "success": True,
              "action": action,
              "category": category,
              "pattern": validation["pattern"],
          }
      except Exception as e:
          result = {"success": False, "error": str(e)}
    output: save_result

  - name: log_session
    description: "Log pattern learning to session"
    condition: "save_result.success"
    tool: memory_session_log
    args:
      action: "Learned pattern: {{ save_result.pattern }}"
      details: "Category: {{ save_result.category }}, Action: {{ save_result.action }}"
    on_error: continue

  - name: track_pattern_learning
    description: "Track pattern learning history"
    condition: "save_result.success"
    compute: |
      from datetime import datetime

      # Load patterns
      patterns = memory.read_memory("learned/patterns") or {}
      if "pattern_learning_history" not in patterns:
          patterns["pattern_learning_history"] = []

      # Record this learning
      learning_record = {
          "pattern": save_result.pattern,
          "category": save_result.category,
          "action": save_result.action,
          "timestamp": datetime.now().isoformat(),
      }

      patterns["pattern_learning_history"].append(learning_record)

      # Keep last 100 learning records
      patterns["pattern_learning_history"] = patterns["pattern_learning_history"][-100:]

      memory.write_memory("learned/patterns", patterns)
      result = "pattern learning tracked"
    output: learning_tracking_result
    on_error: continue

  # ==================== SEMANTIC SEARCH ====================

  - name: search_similar_patterns
    description: "Search for similar patterns in codebase"
    condition: "validation.valid"
    tool: code_search
    args:
      query: "{{ validation.pattern }} error {{ validation.meaning[:50] }}"
      project: "automation-analytics-backend"
      limit: 3
    output: similar_patterns_raw
    on_error: continue

  - name: parse_similar_patterns
    description: "Parse similar patterns search results"
    condition: "similar_patterns_raw"
    compute: |
      code_result = similar_patterns_raw if similar_patterns_raw else {}

      similar_code = []
      if isinstance(code_result, dict) and code_result.get('results'):
          for r in code_result.get('results', [])[:3]:
              similar_code.append({
                  'file': r.get('file_path', ''),
                  'score': r.get('score', 0),
                  'preview': r.get('code_chunk', '')[:100] if r.get('code_chunk') else '',
              })

      result = {
          'similar': similar_code,
          'count': len(similar_code),
          'has_similar': len(similar_code) > 0,
      }
    output: similar_patterns_analysis
    on_error: continue

outputs:
  - name: summary
    value: |
      {% if not validation.valid %}
      ## ❌ Validation Failed

      {{ validation.error }}

      {% elif tool_check and not tool_check.valid %}
      ## ❌ Tool Validation Failed

      {{ tool_check.suggestion }}

      **Unknown tools:**
      {% for tool in tool_check.unknown_tools %}
      - `{{ tool }}`
      {% endfor %}

      **Fix:** Verify tool names exist in the MCP tool registry. Use `tool_list()` to see available tools.

      {% elif save_result.success %}
      ## ✅ Pattern {{ save_result.action | title }}

      **Pattern:** `{{ save_result.pattern }}`
      **Category:** {{ save_result.category }}

      **Meaning:** {{ validation.meaning }}
      **Fix:** {{ validation.fix }}
      {% if command_list %}
      **Commands:**
      {% for cmd in command_list %}
      - `{{ cmd }}`
      {% endfor %}
      {% endif %}

      {% if tool_check.warnings %}
      ### ⚠️ Warnings
      {% for warning in tool_check.warnings %}
      - {{ warning }}
      {% endfor %}
      {% endif %}

      This pattern will now be matched during `investigate_alert` and `debug_prod` skills.

      {% else %}
      ## ❌ Failed to Save

      {{ save_result.error }}
      {% endif %}
