# Skill: Morning Coffee Briefing
# Your daily standup assistant - everything you need to start the day

name: coffee
description: |
  Morning briefing - everything you need to know at the start of your work day.

  This skill gathers and summarizes:
  - ğŸ“… Calendar: Today's meetings with Meet links
  - ğŸ“§ Email: Unread emails categorized (people vs newsletters)
  - ğŸ”€ PRs: Your open PRs, feedback waiting, failed pipelines
  - ğŸ‘€ Reviews: PRs assigned to you for review
  - ğŸ“‹ Jira: Sprint activity for last day/week
  - ğŸš€ Merges: Recent merged code in aa-backend
  - ğŸ§ª Ephemeral: Your active test environments with expiry
  - ğŸ“ Yesterday: Your commits (for standup prep)
  - ğŸš¨ Alerts: Any firing or recent alerts
  - ğŸ¯ Actions: Suggested next steps

  Requires: Gmail API access (same OAuth as Calendar)
version: "1.1"

inputs:
  - name: full_email_scan
    type: boolean
    required: false
    default: false
    description: "Process all unread emails (vs just summary)"

  - name: auto_archive_email
    type: boolean
    required: false
    default: false
    description: "Automatically archive processed emails"

  - name: days_back
    type: integer
    required: false
    default: 1
    description: "Days to look back for activity (default: 1)"

steps:
  # ==================== CONFIGURATION ====================

  - name: load_config
    description: "Load configuration using shared loader"
    compute: |
      from datetime import datetime
      from zoneinfo import ZoneInfo
      from scripts.common.config_loader import load_config, get_timezone

      config = load_config()
      tz = ZoneInfo(get_timezone())
      now = datetime.now(tz)

      result = {
        "config": config,
        "now": now.isoformat(),
        "today": now.strftime("%Y-%m-%d"),
        "day_name": now.strftime("%A"),
        "time": now.strftime("%H:%M"),
        "greeting": "Good morning" if now.hour < 12 else "Good afternoon" if now.hour < 18 else "Good evening",
      }
    output: ctx

  # ==================== MEMORY CONTEXT ====================

  - name: load_current_work
    description: "Load current work state from memory"
    compute: |
      from pathlib import Path
      import yaml

      memory_file = Path.home() / "src/redhat-ai-workflow/memory/state/current_work.yaml"
      current_work = {"active_issues": [], "open_mrs": [], "follow_ups": []}

      if memory_file.exists():
          try:
              with open(memory_file) as f:
                  data = yaml.safe_load(f) or {}
              current_work["active_issues"] = data.get("active_issues", [])
              current_work["open_mrs"] = data.get("open_mrs", [])
              current_work["follow_ups"] = data.get("follow_ups", [])
          except Exception:
              pass

      result = current_work
    output: memory_work

  # ==================== CALENDAR ====================

  - name: get_todays_calendar
    description: "Fetch today's calendar events"
    compute: |
      from pathlib import Path
      from datetime import datetime, timedelta
      from zoneinfo import ZoneInfo

      CONFIG_DIR = Path.home() / ".config" / "google-calendar"
      TOKEN_FILE = CONFIG_DIR / "token.json"
      TIMEZONE = "Europe/Dublin"
      tz = ZoneInfo(TIMEZONE)

      events_today = []

      if TOKEN_FILE.exists():
        try:
          from google.oauth2.credentials import Credentials
          from google.auth.transport.requests import Request
          from googleapiclient.discovery import build

          # Load token with its original scopes (don't override)
          creds = Credentials.from_authorized_user_file(str(TOKEN_FILE))

          # Refresh if expired
          if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
            # Save refreshed token
            with open(TOKEN_FILE, 'w') as f:
              f.write(creds.to_json())

          service = build('calendar', 'v3', credentials=creds)

          now = datetime.now(tz)
          day_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
          day_end = day_start + timedelta(days=1)

          events_result = service.events().list(
            calendarId='primary',
            timeMin=day_start.isoformat(),
            timeMax=day_end.isoformat(),
            singleEvents=True,
            orderBy='startTime',
            timeZone=TIMEZONE,
          ).execute()

          for event in events_result.get('items', []):
            start = event['start'].get('dateTime', event['start'].get('date'))
            try:
              if 'T' in start:
                dt = datetime.fromisoformat(start.replace('Z', '+00:00')).astimezone(tz)
                time_str = dt.strftime('%H:%M')
              else:
                time_str = "All day"
            except:
              time_str = start

            # Check for Meet link
            meet_link = ""
            if event.get('conferenceData', {}).get('entryPoints'):
              for entry in event['conferenceData']['entryPoints']:
                if entry.get('entryPointType') == 'video':
                  meet_link = entry.get('uri', '')
                  break

            events_today.append({
              "time": time_str,
              "title": event.get('summary', 'No title'),
              "meet_link": meet_link,
            })
        except Exception as e:
          events_today = [{"error": str(e)}]
      else:
        events_today = [{"error": "Calendar not configured"}]

      result = events_today
    output: calendar_events

  # ==================== EMAIL (Gmail) with Smart Triage ====================

  - name: get_email_summary
    description: "Fetch, analyze, and optionally triage unread emails"
    compute: |
      from pathlib import Path

      CONFIG_DIR = Path.home() / ".config" / "google-calendar"
      TOKEN_FILE = CONFIG_DIR / "token.json"

      # Get user info for "directed at me" detection
      user_email = ctx.get('config', {}).get('user', {}).get('email', '')
      user_name = ctx.get('config', {}).get('user', {}).get('full_name', '')
      first_name = user_name.split()[0].lower() if user_name else ''

      # Should we auto-archive?
      do_archive = inputs.get('auto_archive_email', False)

      email_summary = {
        "unread_count": 0,
        "needs_attention": [],      # Emails directed at me
        "archived": [],             # Emails we auto-archived
        "newsletters": 0,
        "notifications": 0,
        "cc_only": 0,
        "error": None,
      }

      def is_directed_at_me(headers, user_email, first_name):
        """Determine if email is specifically directed at the user."""
        to_field = headers.get('To', '').lower()
        cc_field = headers.get('Cc', '').lower()
        from_field = headers.get('From', '').lower()
        subject = headers.get('Subject', '').lower()

        # Check if I'm in TO (not just CC)
        in_to = user_email.lower() in to_field if user_email else False
        in_cc_only = not in_to and (user_email.lower() in cc_field if user_email else False)

        # Automated sender patterns
        auto_senders = ['noreply', 'no-reply', 'notifications@', 'system@',
                        'mailer-daemon', 'postmaster', 'donotreply', 'automated']
        is_automated = any(pattern in from_field for pattern in auto_senders)

        # Newsletter patterns
        newsletter_patterns = ['newsletter', 'digest', 'weekly', 'daily update',
                               'unsubscribe', 'mailing list', 'marketing']
        is_newsletter = any(pattern in from_field or pattern in subject
                           for pattern in newsletter_patterns)

        # Jira notifications - keep ones assigned to me
        is_jira = 'jira' in from_field
        jira_assigned = is_jira and ('assigned' in subject or first_name in subject)

        # GitLab notifications - keep ones mentioning me or my MRs
        is_gitlab = 'gitlab' in from_field
        gitlab_important = is_gitlab and (first_name in subject or 'mentioned' in subject
                                          or 'assigned' in subject or 'approved' in subject)

        # Decision logic
        if is_newsletter:
          return False, "newsletter"
        elif is_automated and not jira_assigned and not gitlab_important:
          return False, "notification"
        elif in_cc_only and not (first_name and first_name in subject):
          return False, "cc_only"
        else:
          return True, "direct"

      if TOKEN_FILE.exists():
        try:
          from google.oauth2.credentials import Credentials
          from google.auth.transport.requests import Request
          from googleapiclient.discovery import build

          creds = Credentials.from_authorized_user_file(str(TOKEN_FILE))

          if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
            with open(TOKEN_FILE, 'w') as f:
              f.write(creds.to_json())

          service = build('gmail', 'v1', credentials=creds)

          # Get unread messages
          results = service.users().messages().list(
            userId='me',
            q='is:unread in:inbox',
            maxResults=50
          ).execute()

          messages = results.get('messages', [])
          email_summary["unread_count"] = len(messages)

          # Process each message
          for msg in messages[:30]:  # Process up to 30
            msg_data = service.users().messages().get(
              userId='me',
              id=msg['id'],
              format='metadata',
              metadataHeaders=['Subject', 'From', 'To', 'Cc', 'List-Unsubscribe']
            ).execute()

            headers = {h['name']: h['value'] for h in msg_data.get('payload', {}).get('headers', [])}
            subject = headers.get('Subject', 'No subject')
            sender = headers.get('From', 'Unknown')
            msg_id = msg['id']

            # Check if email is directed at me
            is_important, category = is_directed_at_me(headers, user_email, first_name)

            email_info = {
              "id": msg_id,
              "subject": subject[:60],
              "from": sender.split('<')[0].strip()[:30],
              "category": category,
            }

            if is_important:
              email_summary["needs_attention"].append(email_info)
            else:
              # Track by category
              if category == "newsletter":
                email_summary["newsletters"] += 1
              elif category == "notification":
                email_summary["notifications"] += 1
              elif category == "cc_only":
                email_summary["cc_only"] += 1

              # Auto-archive if enabled
              if do_archive:
                try:
                  # Mark as read and archive (remove INBOX label)
                  service.users().messages().modify(
                    userId='me',
                    id=msg_id,
                    body={'removeLabelIds': ['UNREAD', 'INBOX']}
                  ).execute()
                  email_summary["archived"].append(email_info)
                except Exception:
                  pass  # Skip if archive fails

        except Exception as e:
          error_str = str(e)
          if "gmail" in error_str.lower() or "scope" in error_str.lower():
            email_summary["error"] = "Gmail API not enabled. Run /setup-gmail to configure."
          else:
            email_summary["error"] = error_str
      else:
        email_summary["error"] = "Google OAuth not configured"

      result = email_summary
    output: email_summary
    on_error: continue

  # ==================== OPEN PRs (using MCP tools) ====================

  - name: get_open_prs
    description: "Get all open PRs in the repo"
    tool: gitlab_mr_list
    args:
      project: "automation-analytics/automation-analytics-backend"
    output: all_open_prs_raw
    on_error: continue

  - name: get_my_prs
    description: "Get PRs authored by me"
    tool: gitlab_mr_list
    args:
      project: "automation-analytics/automation-analytics-backend"
      author: "@me"
    output: my_prs_raw
    on_error: continue

  - name: parse_my_prs
    description: "Parse MR list output"
    compute: |
      from scripts.common.parsers import parse_mr_list

      result = parse_mr_list(my_prs_raw) if my_prs_raw else []
    output: my_prs

  # Get MR IDs for comments check
  - name: get_pr_ids_for_feedback
    description: "Extract MR IDs for feedback check"
    compute: |
      # Get up to 5 MR IDs to check
      pr_ids = [pr['id'] for pr in (my_prs or [])[:5]]
      result = pr_ids
    output: pr_ids_to_check

  # Get comments for MR 1
  - name: get_pr1_comments
    description: "Get comments for first PR"
    condition: "{{ pr_ids_to_check|length > 0 }}"
    tool: gitlab_mr_comments
    args:
      project: "automation-analytics/automation-analytics-backend"
      mr_id: "{{ pr_ids_to_check[0] }}"
    output: pr1_comments_raw
    on_error: continue

  # Get comments for MR 2
  - name: get_pr2_comments
    description: "Get comments for second PR"
    condition: "{{ pr_ids_to_check|length > 1 }}"
    tool: gitlab_mr_comments
    args:
      project: "automation-analytics/automation-analytics-backend"
      mr_id: "{{ pr_ids_to_check[1] }}"
    output: pr2_comments_raw
    on_error: continue

  # Get comments for MR 3
  - name: get_pr3_comments
    description: "Get comments for third PR"
    condition: "{{ pr_ids_to_check|length > 2 }}"
    tool: gitlab_mr_comments
    args:
      project: "automation-analytics/automation-analytics-backend"
      mr_id: "{{ pr_ids_to_check[2] }}"
    output: pr3_comments_raw
    on_error: continue

  # Parse all comments for feedback
  - name: parse_pr_feedback
    description: "Parse all PR comments for feedback"
    compute: |
      # parsers is available from skill engine safe_globals
      feedback = []
      current_user = ctx.get('config', {}).get('user', {}).get('username', os.getenv('USER', 'unknown'))

      # Process each MR's comments
      comments_data = [
        (pr_ids_to_check[0] if pr_ids_to_check else None, pr1_comments_raw if 'pr1_comments_raw' in dir() else None),
        (pr_ids_to_check[1] if len(pr_ids_to_check) > 1 else None, pr2_comments_raw if 'pr2_comments_raw' in dir() else None),
        (pr_ids_to_check[2] if len(pr_ids_to_check) > 2 else None, pr3_comments_raw if 'pr3_comments_raw' in dir() else None),
      ]

      # Map MR IDs back to titles
      mr_titles = {pr['id']: pr.get('title', '')[:40] for pr in (my_prs or [])}

      for mr_id, comments_raw in comments_data:
        if not mr_id or not comments_raw:
          continue

        comments_text = str(comments_raw)

        # Find human comments
        for line in comments_text.split('\n'):
          if ' commented ' in line and current_user.lower() not in line.lower():
            if not parsers.is_bot_comment(line, ''):
              match = re.match(r'^(\w+) commented', line)
              if match:
                feedback.append({
                  "mr_id": mr_id,
                  "author": match.group(1),
                  "title": mr_titles.get(mr_id, '')
                })
                break

      result = feedback
    output: pr_feedback

  # ==================== JIRA ACTIVITY (using MCP tool) ====================

  - name: build_jira_jql
    description: "Build JQL query with proper days_back value"
    compute: |
      days = inputs.get('days_back', 1) if inputs else 1
      # Use labels instead of component (component 'Automation Analytics' doesn't exist)
      result = f"project = AAP AND updated >= -{days}d AND labels = 'automation-analytics' ORDER BY updated DESC"
    output: jira_jql

  - name: get_sprint_activity
    description: "Get Jira activity for the sprint"
    tool: jira_search
    args:
      jql: "{{ jira_jql }}"
      max_results: 20
    output: jira_activity_raw
    on_error: continue

  - name: parse_jira_activity
    description: "Parse Jira search results"
    compute: |
      from scripts.common.parsers import parse_jira_issues

      recent_issues = parse_jira_issues(jira_activity_raw) if jira_activity_raw else []

      result = {
        "count": len(recent_issues),
        "issues": recent_issues[:10]
      }
    output: jira_activity
    on_error: continue

  # ==================== MERGED CODE (using MCP tool) ====================

  - name: get_recent_merges
    description: "Get recently merged MRs"
    tool: gitlab_mr_list
    args:
      project: "automation-analytics/automation-analytics-backend"
      state: "merged"
    output: recent_merges_raw
    on_error: continue

  - name: parse_recent_merges
    description: "Parse merged MRs"
    compute: |
      from scripts.common.parsers import parse_mr_list

      merged_mrs = parse_mr_list(recent_merges_raw) if recent_merges_raw else []
      result = merged_mrs[:5]  # Last 5
    output: recent_merges
    on_error: continue

  # ==================== ALERTS (using Alertmanager MCP tools) ====================

  - name: check_alerts_stage
    description: "Check for Automation Analytics alerts in stage"
    tool: alertmanager_alerts
    args:
      environment: "stage"
      filter_name: "Automation Analytics"
      silenced: false
    output: alerts_stage_raw
    on_error: continue

  - name: check_alerts_prod
    description: "Check for Automation Analytics alerts in production"
    tool: alertmanager_alerts
    args:
      environment: "production"
      filter_name: "Automation Analytics"
      silenced: false
    output: alerts_prod_raw
    on_error: continue

  - name: parse_alerts
    description: "Parse alert results"
    compute: |
      import re

      alerts = {
        "stage": [],
        "production": [],
        "error": None
      }

      # Parse stage alerts
      stage_text = str(alerts_stage_raw) if alerts_stage_raw else ""
      if "No active alerts" in stage_text or not stage_text:
        alerts["stage"] = []
      elif "Failed to get alerts" in stage_text:
        alerts["error"] = "Could not connect to Alertmanager (stage)"
      else:
        # Extract alert names from the output
        for line in stage_text.split('\n'):
          if line.startswith('ğŸ”´') or line.startswith('ğŸŸ¡') or line.startswith('ğŸ”µ'):
            match = re.search(r'\*\*(.+?)\*\*', line)
            if match:
              alerts["stage"].append(match.group(1))

      # Parse production alerts
      prod_text = str(alerts_prod_raw) if alerts_prod_raw else ""
      if "No active alerts" in prod_text or not prod_text:
        alerts["production"] = []
      elif "Failed to get alerts" in prod_text:
        if not alerts["error"]:
          alerts["error"] = "Could not connect to Alertmanager (prod)"
      else:
        for line in prod_text.split('\n'):
          if line.startswith('ğŸ”´') or line.startswith('ğŸŸ¡') or line.startswith('ğŸ”µ'):
            match = re.search(r'\*\*(.+?)\*\*', line)
            if match:
              alerts["production"].append(match.group(1))

      result = alerts
    output: alerts
    on_error: continue

  # ==================== FAILED PIPELINES ====================

  # Get MR details for pipeline status (reusing pr_ids_to_check from earlier)
  - name: get_mr1_details
    description: "Get details for first MR"
    condition: "{{ pr_ids_to_check|length > 0 }}"
    tool: gitlab_mr_view
    args:
      project: "automation-analytics/automation-analytics-backend"
      mr_id: "{{ pr_ids_to_check[0] }}"
    output: mr1_details_raw
    on_error: continue

  - name: get_mr2_details
    description: "Get details for second MR"
    condition: "{{ pr_ids_to_check|length > 1 }}"
    tool: gitlab_mr_view
    args:
      project: "automation-analytics/automation-analytics-backend"
      mr_id: "{{ pr_ids_to_check[1] }}"
    output: mr2_details_raw
    on_error: continue

  - name: get_mr3_details
    description: "Get details for third MR"
    condition: "{{ pr_ids_to_check|length > 2 }}"
    tool: gitlab_mr_view
    args:
      project: "automation-analytics/automation-analytics-backend"
      mr_id: "{{ pr_ids_to_check[2] }}"
    output: mr3_details_raw
    on_error: continue

  - name: check_failed_pipelines
    description: "Parse MR details for failed pipelines"
    compute: |
      failed_pipelines = []

      # Map MR IDs to titles
      mr_titles = {pr['id']: pr.get('title', '')[:40] for pr in (my_prs or [])}

      # Check each MR for failed status
      mr_details_list = [
        (pr_ids_to_check[0] if pr_ids_to_check else None, mr1_details_raw if 'mr1_details_raw' in dir() else None),
        (pr_ids_to_check[1] if len(pr_ids_to_check) > 1 else None, mr2_details_raw if 'mr2_details_raw' in dir() else None),
        (pr_ids_to_check[2] if len(pr_ids_to_check) > 2 else None, mr3_details_raw if 'mr3_details_raw' in dir() else None),
      ]

      for mr_id, details_raw in mr_details_list:
        if not mr_id or not details_raw:
          continue

        output = str(details_raw).lower()
        if 'failed' in output or 'canceled' in output:
          failed_pipelines.append({
            "mr_id": mr_id,
            "title": mr_titles.get(mr_id, ''),
            "status": "failed" if 'failed' in output else "canceled"
          })

      result = failed_pipelines
    output: failed_pipelines

  # ==================== EPHEMERAL NAMESPACES (using MCP tool) ====================

  - name: check_ephemeral_namespaces
    description: "List your active ephemeral environments"
    tool: bonfire_namespace_list
    args:
      mine: true
    output: ephemeral_namespaces_raw
    on_error: continue

  - name: parse_ephemeral_namespaces
    description: "Parse namespace list"
    compute: |
      from scripts.common.parsers import parse_namespaces

      result = parse_namespaces(ephemeral_namespaces_raw) if ephemeral_namespaces_raw else []
    output: ephemeral_namespaces
    on_error: continue

  # ==================== YESTERDAY'S WORK (using MCP tool) ====================

  - name: get_yesterdays_commits_raw
    description: "Get your commits from yesterday (for standup)"
    tool: git_log
    args:
      repo: "automation-analytics-backend"
      limit: 10
      author: "{{ ctx.config.user.username }}"
      since: "yesterday"
      until: "today"
    output: yesterdays_commits_raw
    on_error: continue

  - name: parse_yesterdays_commits
    description: "Parse commit output"
    compute: |
      import re

      commits = []
      raw = str(yesterdays_commits_raw) if yesterdays_commits_raw else ""

      for line in raw.split('\n'):
        # Look for lines like "- `abc1234 commit message`"
        match = re.search(r'`([a-f0-9]{7,})\s+(.+?)`', line)
        if match:
          commits.append({
            "sha": match.group(1)[:7],
            "message": match.group(2)[:60]
          })

      result = commits
    output: yesterdays_commits
    on_error: continue

  # ==================== REVIEW REQUESTS (using MCP tool) ====================

  - name: get_review_requests
    description: "Get PRs where you're assigned as reviewer"
    tool: gitlab_mr_list
    args:
      project: "automation-analytics/automation-analytics-backend"
      reviewer: "@me"
    output: review_requests_raw
    on_error: continue

  - name: parse_review_requests
    description: "Parse review request list"
    compute: |
      from scripts.common.parsers import parse_mr_list

      review_requests = parse_mr_list(review_requests_raw) if review_requests_raw else []
      result = review_requests[:5]  # Limit to 5
    output: review_requests
    on_error: continue

  # ==================== SUMMARY ====================

  - name: format_briefing
    description: "Create the morning briefing"
    compute: |
      import re

      lines = []

      # Get user's first name from config
      full_name = ctx.get('config', {}).get('user', {}).get('full_name', 'there')
      first_name = full_name.split()[0] if full_name else 'there'

      # Base URLs for hyperlinks (inlined to avoid closure issues in sandbox)
      # GitLab: https://gitlab.cee.redhat.com/automation-analytics/automation-analytics-backend/-/merge_requests/{id}
      # Import shared linkify function
      from scripts.common.parsers import linkify_jira_keys

      # Header
      lines.append(f"# â˜• {ctx['greeting']}, {first_name}!")
      lines.append(f"")
      lines.append(f"**{ctx['day_name']}, {ctx['today']}** | {ctx['time']} Irish time")
      lines.append("")
      lines.append("---")
      lines.append("")

      # Current Work from Memory (if any)
      active_issues = memory_work.get('active_issues', []) if memory_work else []
      tracked_mrs = memory_work.get('open_mrs', []) if memory_work else []
      follow_ups = memory_work.get('follow_ups', []) if memory_work else []

      if active_issues or follow_ups:
        lines.append("## ğŸ¯ Current Work (from memory)")
        if active_issues:
          for issue in active_issues[:3]:
            key = issue.get('key', 'Unknown')
            summary = issue.get('summary', '')[:40]
            branch = issue.get('branch', '')
            lines.append(f"- **[{key}](https://issues.redhat.com/browse/{key})**: {summary}")
            if branch:
              lines.append(f"  - Branch: `{branch}`")
        if follow_ups:
          lines.append("**Follow-ups:**")
          for fu in follow_ups[:3]:
            task = fu.get('task', 'Unknown task')
            priority = fu.get('priority', 'normal')
            emoji = "ğŸ”´" if priority == "high" else "ğŸŸ¡" if priority == "medium" else "âšª"
            lines.append(f"- {emoji} {task}")
        lines.append("")

      # Calendar
      lines.append("## ğŸ“… Today's Calendar")
      if calendar_events and not any('error' in e for e in calendar_events):
        if calendar_events:
          for event in calendar_events:
            meet_icon = "ğŸ“¹" if event.get('meet_link') else ""
            lines.append(f"- **{event['time']}** - {event['title']} {meet_icon}")
        else:
          lines.append("- No meetings scheduled! ğŸ‰")
      else:
        lines.append("- âš ï¸ Calendar not accessible")
      lines.append("")

      # Email with smart triage
      lines.append("## ğŸ“§ Email")
      if email_summary and not email_summary.get('error'):
        needs_attention = email_summary.get('needs_attention', [])
        archived = email_summary.get('archived', [])
        newsletters = email_summary.get('newsletters', 0)
        notifications = email_summary.get('notifications', 0)
        cc_only = email_summary.get('cc_only', 0)

        # Show emails needing attention
        if needs_attention:
          lines.append(f"### âš ï¸ Needs Your Attention ({len(needs_attention)})")
          for email in needs_attention[:8]:
            lines.append(f"- **{email['from']}**: *{email['subject']}*")
          if len(needs_attention) > 8:
            lines.append(f"- *...and {len(needs_attention) - 8} more*")
          lines.append("")

        # Show what was archived (if auto-archive was enabled)
        if archived:
          lines.append(f"### âœ… Auto-Archived ({len(archived)})")
          # Group by category
          by_cat = {}
          for email in archived:
            cat = email.get('category', 'other')
            if cat not in by_cat:
              by_cat[cat] = []
            by_cat[cat].append(email)

          for cat, emails in by_cat.items():
            cat_name = {'newsletter': 'ğŸ“° Newsletters', 'notification': 'ğŸ”” Notifications',
                        'cc_only': 'ğŸ“‹ CC-only'}.get(cat, cat)
            lines.append(f"- {cat_name}: {len(emails)}")
          lines.append("")

        # Show what WOULD be archived (if not auto-archiving)
        if not archived and (newsletters or notifications or cc_only):
          skippable = newsletters + notifications + cc_only
          lines.append(f"### ğŸ’¡ Could Auto-Archive ({skippable})")
          if newsletters:
            lines.append(f"- ğŸ“° Newsletters: {newsletters}")
          if notifications:
            lines.append(f"- ğŸ”” Notifications: {notifications}")
          if cc_only:
            lines.append(f"- ğŸ“‹ CC-only: {cc_only}")
          lines.append("")
          lines.append("*Tip: Run with `auto_archive_email: true` to clean these up*")
          lines.append("")

        if not needs_attention and not archived and not newsletters:
          lines.append("âœ¨ Inbox is clean!")
          lines.append("")
      else:
        error = email_summary.get('error', 'Unknown') if email_summary else 'Not configured'
        lines.append(f"- âš ï¸ {error}")
        lines.append("")

      # PRs needing attention
      lines.append("## ğŸ”€ Your PRs")
      lines.append(f"")
      lines.append(f"**Open PRs:** {len(my_prs) if my_prs else 0}")
      if my_prs:
        for pr in my_prs[:5]:
          title_with_links = linkify_jira_keys(pr['title'])
          lines.append(f"- [!{pr['id']}](https://gitlab.cee.redhat.com/automation-analytics/automation-analytics-backend/-/merge_requests/{pr['id']}) - {title_with_links}")
      lines.append("")

      if pr_feedback:
        lines.append(f"**âš ï¸ Feedback Waiting ({len(pr_feedback)}):**")
        for fb in pr_feedback:
          lines.append(f"- [!{fb['mr_id']}](https://gitlab.cee.redhat.com/automation-analytics/automation-analytics-backend/-/merge_requests/{fb['mr_id']}) - Comment from **{fb['author']}**")
      else:
        lines.append("âœ… No pending feedback on your PRs")
      lines.append("")

      # Failed pipelines
      if failed_pipelines:
        lines.append(f"**ğŸ”´ Failed Pipelines ({len(failed_pipelines)}):**")
        for fp in failed_pipelines:
          lines.append(f"- [!{fp['mr_id']}](https://gitlab.cee.redhat.com/automation-analytics/automation-analytics-backend/-/merge_requests/{fp['mr_id']}) - {fp['status'].upper()}")
        lines.append("")

      # Review requests - PRs assigned to YOU for review
      lines.append("## ğŸ‘€ Review Requests")
      if review_requests:
        lines.append(f"**Assigned to you:** {len(review_requests)}")
        for rr in review_requests:
          title_with_links = linkify_jira_keys(rr['title'])
          lines.append(f"- [!{rr['id']}](https://gitlab.cee.redhat.com/automation-analytics/automation-analytics-backend/-/merge_requests/{rr['id']}) - {title_with_links}")
      else:
        lines.append("âœ… No PRs waiting for your review")
      lines.append("")

      # Jira
      lines.append("## ğŸ“‹ Jira Activity")
      if jira_activity and jira_activity.get('count', 0) > 0:
        lines.append(f"**{jira_activity.get('count', 0)}** issues updated in last {inputs.get('days_back', 1)} day(s)")
        for issue in jira_activity.get('issues', [])[:5]:
          lines.append(f"- [{issue['key']}](https://issues.redhat.com/browse/{issue['key']}) - {issue['summary']}")
      else:
        lines.append("- No Jira activity in the last day")
      lines.append("")

      # Merges
      lines.append("## ğŸš€ Recent Merges")
      if recent_merges:
        for mr in recent_merges:
          title_with_links = linkify_jira_keys(mr['title'])
          lines.append(f"- [!{mr['id']}](https://gitlab.cee.redhat.com/automation-analytics/automation-analytics-backend/-/merge_requests/{mr['id']}) - {title_with_links}")
      else:
        lines.append("- No recent merges")
      lines.append("")

      # Ephemeral Environments
      lines.append("## ğŸ§ª Ephemeral Environments")
      if ephemeral_namespaces:
        for ns in ephemeral_namespaces:
          expires = ns.get('expires', 'unknown')
          lines.append(f"- **{ns['name']}** - expires {expires}")
      else:
        lines.append("- No active ephemeral environments")
      lines.append("")

      # Yesterday's Work (for standup)
      lines.append("## ğŸ“ Yesterday's Work")
      if yesterdays_commits:
        for commit in yesterdays_commits[:5]:
          lines.append(f"- `{commit['sha']}` {commit['message']}")
      else:
        lines.append("- No commits yesterday")
      lines.append("")

      # Alerts
      lines.append("## ğŸš¨ Alerts")
      if alerts and not alerts.get('error'):
        if alerts.get('production') or alerts.get('stage'):
          for env, alert_list in alerts.items():
            if alert_list and env != 'error':
              lines.append(f"**{env.upper()}:**")
              for a in alert_list:
                lines.append(f"- {a}")
        else:
          lines.append("âœ… No active alerts")
      else:
        lines.append("- Alert check not configured")
      lines.append("")

      # Actions
      lines.append("---")
      lines.append("")
      lines.append("## ğŸ¯ Suggested Actions")
      actions = []

      if pr_feedback:
        actions.append(f"- Respond to feedback on {len(pr_feedback)} PR(s)")
      if failed_pipelines:
        actions.append(f"- Fix {len(failed_pipelines)} failed pipeline(s)")
      if review_requests:
        actions.append(f"- Review {len(review_requests)} PR(s) assigned to you")

      # Email actions
      needs_attention = email_summary.get('needs_attention', []) if email_summary else []
      if needs_attention:
        actions.append(f"- Review {len(needs_attention)} email(s) needing attention")

      # Suggest auto-archive if there's cleanup potential
      newsletters = email_summary.get('newsletters', 0) if email_summary else 0
      notifications = email_summary.get('notifications', 0) if email_summary else 0
      cc_only = email_summary.get('cc_only', 0) if email_summary else 0
      skippable = newsletters + notifications + cc_only
      if skippable >= 5 and not email_summary.get('archived'):
        actions.append(f"- ğŸ’¡ Run `/coffee` with `auto_archive_email: true` to clean up {skippable} emails")

      if ephemeral_namespaces:
        expiring = [ns for ns in ephemeral_namespaces if 'h' in str(ns.get('expires', '')) and int(re.search(r'(\d+)h', str(ns.get('expires', '0h'))).group(1) if re.search(r'(\d+)h', str(ns.get('expires', ''))) else 99) < 2]
        if expiring:
          actions.append(f"- â° {len(expiring)} ephemeral env(s) expiring soon!")

      if actions:
        for a in actions:
          lines.append(a)
      else:
        lines.append("- You're all caught up! â˜•")

      result = '\n'.join(lines)
    output: briefing

outputs:
  - name: summary
    value: "{{ briefing }}"

  - name: context
    value:
      calendar_count: "{{ calendar_events | length if calendar_events else 0 }}"
      unread_emails: "{{ email_summary.unread_count if email_summary else 0 }}"
      my_prs: "{{ my_prs | length if my_prs else 0 }}"
      feedback_waiting: "{{ pr_feedback | length if pr_feedback else 0 }}"
      failed_pipelines: "{{ failed_pipelines | length if failed_pipelines else 0 }}"
      review_requests: "{{ review_requests | length if review_requests else 0 }}"
      ephemeral_envs: "{{ ephemeral_namespaces | length if ephemeral_namespaces else 0 }}"
      yesterdays_commits: "{{ yesterdays_commits | length if yesterdays_commits else 0 }}"
      jira_updates: "{{ jira_activity.count if jira_activity else 0 }}"
      recent_merges: "{{ recent_merges | length if recent_merges else 0 }}"
