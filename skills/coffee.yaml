# Skill: Morning Coffee Briefing
# Your daily standup assistant - everything you need to start the day

name: coffee
description: |
  Morning briefing - everything you need to know at the start of your work day.
  
  This skill gathers and summarizes:
  - ğŸ“… Calendar: Today's meetings with Meet links
  - ğŸ“§ Email: Unread emails categorized (people vs newsletters)
  - ğŸ”€ PRs: Your open PRs, feedback waiting, failed pipelines
  - ğŸ‘€ Reviews: PRs assigned to you for review
  - ğŸ“‹ Jira: Sprint activity for last day/week
  - ğŸš€ Merges: Recent merged code in aa-backend
  - ğŸ§ª Ephemeral: Your active test environments with expiry
  - ğŸ“ Yesterday: Your commits (for standup prep)
  - ğŸš¨ Alerts: Any firing or recent alerts
  - ğŸ¯ Actions: Suggested next steps
  
  Requires: Gmail API access (same OAuth as Calendar)
version: "1.1"

inputs:
  - name: full_email_scan
    type: boolean
    required: false
    default: false
    description: "Process all unread emails (vs just summary)"
  
  - name: auto_archive_email
    type: boolean
    required: false
    default: false
    description: "Automatically archive processed emails"
  
  - name: days_back
    type: integer
    required: false
    default: 1
    description: "Days to look back for activity (default: 1)"

steps:
  # ==================== CONFIGURATION ====================
  
  - name: load_config
    description: "Load configuration using shared loader"
    compute: |
      from datetime import datetime
      from zoneinfo import ZoneInfo
      from scripts.common.config_loader import load_config, get_timezone
      
      config = load_config()
      tz = ZoneInfo(get_timezone())
      now = datetime.now(tz)
      
      result = {
        "config": config,
        "now": now.isoformat(),
        "today": now.strftime("%Y-%m-%d"),
        "day_name": now.strftime("%A"),
        "time": now.strftime("%H:%M"),
        "greeting": "Good morning" if now.hour < 12 else "Good afternoon" if now.hour < 18 else "Good evening",
      }
    output: ctx

  # ==================== CALENDAR ====================
  
  - name: get_todays_calendar
    description: "Fetch today's calendar events"
    compute: |
      from pathlib import Path
      from datetime import datetime, timedelta
      from zoneinfo import ZoneInfo
      
      CONFIG_DIR = Path.home() / ".config" / "google-calendar"
      TOKEN_FILE = CONFIG_DIR / "token.json"
      TIMEZONE = "Europe/Dublin"
      tz = ZoneInfo(TIMEZONE)
      
      events_today = []
      
      if TOKEN_FILE.exists():
        try:
          from google.oauth2.credentials import Credentials
          from google.auth.transport.requests import Request
          from googleapiclient.discovery import build
          
          # Load token with its original scopes (don't override)
          creds = Credentials.from_authorized_user_file(str(TOKEN_FILE))
          
          # Refresh if expired
          if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
            # Save refreshed token
            with open(TOKEN_FILE, 'w') as f:
              f.write(creds.to_json())
          
          service = build('calendar', 'v3', credentials=creds)
          
          now = datetime.now(tz)
          day_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
          day_end = day_start + timedelta(days=1)
          
          events_result = service.events().list(
            calendarId='primary',
            timeMin=day_start.isoformat(),
            timeMax=day_end.isoformat(),
            singleEvents=True,
            orderBy='startTime',
            timeZone=TIMEZONE,
          ).execute()
          
          for event in events_result.get('items', []):
            start = event['start'].get('dateTime', event['start'].get('date'))
            try:
              if 'T' in start:
                dt = datetime.fromisoformat(start.replace('Z', '+00:00')).astimezone(tz)
                time_str = dt.strftime('%H:%M')
              else:
                time_str = "All day"
            except:
              time_str = start
            
            # Check for Meet link
            meet_link = ""
            if event.get('conferenceData', {}).get('entryPoints'):
              for entry in event['conferenceData']['entryPoints']:
                if entry.get('entryPointType') == 'video':
                  meet_link = entry.get('uri', '')
                  break
            
            events_today.append({
              "time": time_str,
              "title": event.get('summary', 'No title'),
              "meet_link": meet_link,
            })
        except Exception as e:
          events_today = [{"error": str(e)}]
      else:
        events_today = [{"error": "Calendar not configured"}]
      
      result = events_today
    output: calendar_events

  # ==================== EMAIL (Gmail) ====================
  
  - name: get_email_summary
    description: "Fetch and summarize unread emails"
    compute: |
      from pathlib import Path
      
      CONFIG_DIR = Path.home() / ".config" / "google-calendar"
      TOKEN_FILE = CONFIG_DIR / "token.json"
      
      email_summary = {
        "unread_count": 0,
        "important": [],
        "newsletters": 0,
        "notifications": 0,
        "error": None,
      }
      
      if TOKEN_FILE.exists():
        try:
          from google.oauth2.credentials import Credentials
          from google.auth.transport.requests import Request
          from googleapiclient.discovery import build
          
          # Load token with its original scopes (don't override)
          creds = Credentials.from_authorized_user_file(str(TOKEN_FILE))
          
          # Refresh if expired
          if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
            # Save refreshed token
            with open(TOKEN_FILE, 'w') as f:
              f.write(creds.to_json())
          
          service = build('gmail', 'v1', credentials=creds)
          
          # Get unread messages
          results = service.users().messages().list(
            userId='me',
            q='is:unread',
            maxResults=50
          ).execute()
          
          messages = results.get('messages', [])
          email_summary["unread_count"] = len(messages)
          
          # Categorize messages
          for msg in messages[:20]:  # Process first 20
            msg_data = service.users().messages().get(
              userId='me',
              id=msg['id'],
              format='metadata',
              metadataHeaders=['Subject', 'From']
            ).execute()
            
            headers = {h['name']: h['value'] for h in msg_data.get('payload', {}).get('headers', [])}
            subject = headers.get('Subject', 'No subject')
            sender = headers.get('From', 'Unknown')
            
            # Categorize
            sender_lower = sender.lower()
            subject_lower = subject.lower()
            
            if 'newsletter' in sender_lower or 'digest' in subject_lower:
              email_summary["newsletters"] += 1
            elif 'notification' in sender_lower or 'noreply' in sender_lower:
              email_summary["notifications"] += 1
            else:
              # Important - from people
              email_summary["important"].append({
                "subject": subject[:60],
                "from": sender.split('<')[0].strip()[:30],
              })
          
        except Exception as e:
          error_str = str(e)
          if "gmail" in error_str.lower() or "scope" in error_str.lower():
            email_summary["error"] = "Gmail API not enabled. Run /setup-gmail to configure."
          else:
            email_summary["error"] = error_str
      else:
        email_summary["error"] = "Google OAuth not configured"
      
      result = email_summary
    output: email_summary
    on_error: continue

  # ==================== OPEN PRs (using MCP tools) ====================
  
  - name: get_open_prs
    description: "Get all open PRs in the repo"
    tool: gitlab_mr_list
    args:
      project: "automation-analytics/automation-analytics-backend"
    output: all_open_prs_raw
    on_error: continue

  - name: get_my_prs
    description: "Get PRs authored by me"
    tool: gitlab_mr_list
    args:
      project: "automation-analytics/automation-analytics-backend"
      author: "@me"
    output: my_prs_raw
    on_error: continue

  - name: parse_my_prs
    description: "Parse MR list output"
    compute: |
      from scripts.common.parsers import parse_mr_list
      
      result = parse_mr_list(my_prs_raw) if my_prs_raw else []
    output: my_prs

  # Get MR IDs for comments check
  - name: get_pr_ids_for_feedback
    description: "Extract MR IDs for feedback check"
    compute: |
      # Get up to 5 MR IDs to check
      pr_ids = [pr['id'] for pr in (my_prs or [])[:5]]
      result = pr_ids
    output: pr_ids_to_check

  # Get comments for MR 1
  - name: get_pr1_comments
    description: "Get comments for first PR"
    condition: "{{ pr_ids_to_check|length > 0 }}"
    tool: gitlab_mr_comments
    args:
      project: "automation-analytics/automation-analytics-backend"
      mr_id: "{{ pr_ids_to_check[0] }}"
    output: pr1_comments_raw
    on_error: continue

  # Get comments for MR 2
  - name: get_pr2_comments
    description: "Get comments for second PR"
    condition: "{{ pr_ids_to_check|length > 1 }}"
    tool: gitlab_mr_comments
    args:
      project: "automation-analytics/automation-analytics-backend"
      mr_id: "{{ pr_ids_to_check[1] }}"
    output: pr2_comments_raw
    on_error: continue

  # Get comments for MR 3
  - name: get_pr3_comments
    description: "Get comments for third PR"
    condition: "{{ pr_ids_to_check|length > 2 }}"
    tool: gitlab_mr_comments
    args:
      project: "automation-analytics/automation-analytics-backend"
      mr_id: "{{ pr_ids_to_check[2] }}"
    output: pr3_comments_raw
    on_error: continue

  # Parse all comments for feedback
  - name: parse_pr_feedback
    description: "Parse all PR comments for feedback"
    compute: |
      import re
      import sys
      from pathlib import Path
      
      sys.path.insert(0, str(Path.home() / "src/redhat-ai-workflow/scripts"))
      from common.parsers import is_bot_comment
      
      feedback = []
      current_user = ctx.get('config', {}).get('user', {}).get('username', os.getenv('USER', 'unknown'))
      
      # Process each MR's comments
      comments_data = [
        (pr_ids_to_check[0] if pr_ids_to_check else None, pr1_comments_raw if 'pr1_comments_raw' in dir() else None),
        (pr_ids_to_check[1] if len(pr_ids_to_check) > 1 else None, pr2_comments_raw if 'pr2_comments_raw' in dir() else None),
        (pr_ids_to_check[2] if len(pr_ids_to_check) > 2 else None, pr3_comments_raw if 'pr3_comments_raw' in dir() else None),
      ]
      
      # Map MR IDs back to titles
      mr_titles = {pr['id']: pr.get('title', '')[:40] for pr in (my_prs or [])}
      
      for mr_id, comments_raw in comments_data:
        if not mr_id or not comments_raw:
          continue
        
        comments_text = str(comments_raw)
        
        # Find human comments
        for line in comments_text.split('\n'):
          if ' commented ' in line and current_user.lower() not in line.lower():
            if not is_bot_comment(line, ''):
              match = re.match(r'^(\w+) commented', line)
              if match:
                feedback.append({
                  "mr_id": mr_id,
                  "author": match.group(1),
                  "title": mr_titles.get(mr_id, '')
                })
                break
      
      result = feedback
    output: pr_feedback

  # ==================== JIRA ACTIVITY (using MCP tool) ====================
  
  - name: build_jira_jql
    description: "Build JQL query with proper days_back value"
    compute: |
      days = inputs.get('days_back', 1) if inputs else 1
      # Use labels instead of component (component 'Automation Analytics' doesn't exist)
      result = f"project = AAP AND updated >= -{days}d AND labels = 'automation-analytics' ORDER BY updated DESC"
    output: jira_jql
  
  - name: get_sprint_activity
    description: "Get Jira activity for the sprint"
    tool: jira_search
    args:
      jql: "{{ jira_jql }}"
      max_results: 20
    output: jira_activity_raw
    on_error: continue

  - name: parse_jira_activity
    description: "Parse Jira search results"
    compute: |
      from scripts.common.parsers import parse_jira_issues
      
      recent_issues = parse_jira_issues(jira_activity_raw) if jira_activity_raw else []
      
      result = {
        "count": len(recent_issues),
        "issues": recent_issues[:10]
      }
    output: jira_activity
    on_error: continue

  # ==================== MERGED CODE (using MCP tool) ====================
  
  - name: get_recent_merges
    description: "Get recently merged MRs"
    tool: gitlab_mr_list
    args:
      project: "automation-analytics/automation-analytics-backend"
      state: "merged"
    output: recent_merges_raw
    on_error: continue

  - name: parse_recent_merges
    description: "Parse merged MRs"
    compute: |
      from scripts.common.parsers import parse_mr_list
      
      merged_mrs = parse_mr_list(recent_merges_raw) if recent_merges_raw else []
      result = merged_mrs[:5]  # Last 5
    output: recent_merges
    on_error: continue

  # ==================== ALERTS (using Alertmanager MCP tools) ====================
  
  - name: check_alerts_stage
    description: "Check for Automation Analytics alerts in stage"
    tool: alertmanager_alerts
    args:
      environment: "stage"
      filter_name: "Automation Analytics"
      silenced: false
    output: alerts_stage_raw
    on_error: continue

  - name: check_alerts_prod
    description: "Check for Automation Analytics alerts in production"
    tool: alertmanager_alerts
    args:
      environment: "production"
      filter_name: "Automation Analytics"
      silenced: false
    output: alerts_prod_raw
    on_error: continue

  - name: parse_alerts
    description: "Parse alert results"
    compute: |
      import re
      
      alerts = {
        "stage": [],
        "production": [],
        "error": None
      }
      
      # Parse stage alerts
      stage_text = str(alerts_stage_raw) if alerts_stage_raw else ""
      if "No active alerts" in stage_text or not stage_text:
        alerts["stage"] = []
      elif "Failed to get alerts" in stage_text:
        alerts["error"] = "Could not connect to Alertmanager (stage)"
      else:
        # Extract alert names from the output
        for line in stage_text.split('\n'):
          if line.startswith('ğŸ”´') or line.startswith('ğŸŸ¡') or line.startswith('ğŸ”µ'):
            match = re.search(r'\*\*(.+?)\*\*', line)
            if match:
              alerts["stage"].append(match.group(1))
      
      # Parse production alerts
      prod_text = str(alerts_prod_raw) if alerts_prod_raw else ""
      if "No active alerts" in prod_text or not prod_text:
        alerts["production"] = []
      elif "Failed to get alerts" in prod_text:
        if not alerts["error"]:
          alerts["error"] = "Could not connect to Alertmanager (prod)"
      else:
        for line in prod_text.split('\n'):
          if line.startswith('ğŸ”´') or line.startswith('ğŸŸ¡') or line.startswith('ğŸ”µ'):
            match = re.search(r'\*\*(.+?)\*\*', line)
            if match:
              alerts["production"].append(match.group(1))
      
      result = alerts
    output: alerts
    on_error: continue

  # ==================== FAILED PIPELINES ====================
  
  # Get MR details for pipeline status (reusing pr_ids_to_check from earlier)
  - name: get_mr1_details
    description: "Get details for first MR"
    condition: "{{ pr_ids_to_check|length > 0 }}"
    tool: gitlab_mr_view
    args:
      project: "automation-analytics/automation-analytics-backend"
      mr_id: "{{ pr_ids_to_check[0] }}"
    output: mr1_details_raw
    on_error: continue

  - name: get_mr2_details
    description: "Get details for second MR"
    condition: "{{ pr_ids_to_check|length > 1 }}"
    tool: gitlab_mr_view
    args:
      project: "automation-analytics/automation-analytics-backend"
      mr_id: "{{ pr_ids_to_check[1] }}"
    output: mr2_details_raw
    on_error: continue

  - name: get_mr3_details
    description: "Get details for third MR"
    condition: "{{ pr_ids_to_check|length > 2 }}"
    tool: gitlab_mr_view
    args:
      project: "automation-analytics/automation-analytics-backend"
      mr_id: "{{ pr_ids_to_check[2] }}"
    output: mr3_details_raw
    on_error: continue

  - name: check_failed_pipelines
    description: "Parse MR details for failed pipelines"
    compute: |
      failed_pipelines = []
      
      # Map MR IDs to titles
      mr_titles = {pr['id']: pr.get('title', '')[:40] for pr in (my_prs or [])}
      
      # Check each MR for failed status
      mr_details_list = [
        (pr_ids_to_check[0] if pr_ids_to_check else None, mr1_details_raw if 'mr1_details_raw' in dir() else None),
        (pr_ids_to_check[1] if len(pr_ids_to_check) > 1 else None, mr2_details_raw if 'mr2_details_raw' in dir() else None),
        (pr_ids_to_check[2] if len(pr_ids_to_check) > 2 else None, mr3_details_raw if 'mr3_details_raw' in dir() else None),
      ]
      
      for mr_id, details_raw in mr_details_list:
        if not mr_id or not details_raw:
          continue
        
        output = str(details_raw).lower()
        if 'failed' in output or 'canceled' in output:
          failed_pipelines.append({
            "mr_id": mr_id,
            "title": mr_titles.get(mr_id, ''),
            "status": "failed" if 'failed' in output else "canceled"
          })
      
      result = failed_pipelines
    output: failed_pipelines

  # ==================== EPHEMERAL NAMESPACES (using MCP tool) ====================
  
  - name: check_ephemeral_namespaces
    description: "List your active ephemeral environments"
    tool: bonfire_namespace_list
    args:
      mine: true
    output: ephemeral_namespaces_raw
    on_error: continue

  - name: parse_ephemeral_namespaces
    description: "Parse namespace list"
    compute: |
      from scripts.common.parsers import parse_namespaces
      
      result = parse_namespaces(ephemeral_namespaces_raw) if ephemeral_namespaces_raw else []
    output: ephemeral_namespaces
    on_error: continue

  # ==================== YESTERDAY'S WORK (using MCP tool) ====================
  
  - name: get_yesterdays_commits_raw
    description: "Get your commits from yesterday (for standup)"
    tool: git_log
    args:
      repo: "automation-analytics-backend"
      limit: 10
      author: "{{ ctx.config.user.username }}"
      since: "yesterday"
      until: "today"
    output: yesterdays_commits_raw
    on_error: continue

  - name: parse_yesterdays_commits
    description: "Parse commit output"
    compute: |
      import re
      
      commits = []
      raw = str(yesterdays_commits_raw) if yesterdays_commits_raw else ""
      
      for line in raw.split('\n'):
        # Look for lines like "- `abc1234 commit message`"
        match = re.search(r'`([a-f0-9]{7,})\s+(.+?)`', line)
        if match:
          commits.append({
            "sha": match.group(1)[:7],
            "message": match.group(2)[:60]
          })
      
      result = commits
    output: yesterdays_commits
    on_error: continue

  # ==================== REVIEW REQUESTS (using MCP tool) ====================
  
  - name: get_review_requests
    description: "Get PRs where you're assigned as reviewer"
    tool: gitlab_mr_list
    args:
      project: "automation-analytics/automation-analytics-backend"
      reviewer: "@me"
    output: review_requests_raw
    on_error: continue

  - name: parse_review_requests
    description: "Parse review request list"
    compute: |
      from scripts.common.parsers import parse_mr_list
      
      review_requests = parse_mr_list(review_requests_raw) if review_requests_raw else []
      result = review_requests[:5]  # Limit to 5
    output: review_requests
    on_error: continue

  # ==================== SUMMARY ====================
  
  - name: format_briefing
    description: "Create the morning briefing"
    compute: |
      import re
      
      lines = []
      
      # Get user's first name from config
      full_name = ctx.get('config', {}).get('user', {}).get('full_name', 'there')
      first_name = full_name.split()[0] if full_name else 'there'
      
      # GitLab base URL for MR links
      gitlab_base = "https://gitlab.cee.redhat.com/automation-analytics/automation-analytics-backend/-/merge_requests"
      
      def mr_link(mr_id, title=""):
        """Create a markdown hyperlink for an MR."""
        if title:
          return f"[!{mr_id}]({gitlab_base}/{mr_id}) - {title}"
        return f"[!{mr_id}]({gitlab_base}/{mr_id})"
      
      # Header
      lines.append(f"# â˜• {ctx['greeting']}, {first_name}!")
      lines.append(f"")
      lines.append(f"**{ctx['day_name']}, {ctx['today']}** | {ctx['time']} Irish time")
      lines.append("")
      lines.append("---")
      lines.append("")
      
      # Calendar
      lines.append("## ğŸ“… Today's Calendar")
      if calendar_events and not any('error' in e for e in calendar_events):
        if calendar_events:
          for event in calendar_events:
            meet_icon = "ğŸ“¹" if event.get('meet_link') else ""
            lines.append(f"- **{event['time']}** - {event['title']} {meet_icon}")
        else:
          lines.append("- No meetings scheduled! ğŸ‰")
      else:
        lines.append("- âš ï¸ Calendar not accessible")
      lines.append("")
      
      # Email
      lines.append("## ğŸ“§ Email Summary")
      if email_summary and not email_summary.get('error'):
        lines.append(f"- **{email_summary['unread_count']}** unread emails")
        if email_summary['important']:
          lines.append(f"- **{len(email_summary['important'])}** from people:")
          for email in email_summary['important'][:5]:
            lines.append(f"  - {email['from']}: *{email['subject']}*")
        if email_summary['newsletters']:
          lines.append(f"- {email_summary['newsletters']} newsletters")
        if email_summary['notifications']:
          lines.append(f"- {email_summary['notifications']} notifications")
      else:
        error = email_summary.get('error', 'Unknown') if email_summary else 'Not configured'
        lines.append(f"- âš ï¸ {error}")
      lines.append("")
      
      # PRs needing attention
      lines.append("## ğŸ”€ Your PRs")
      lines.append(f"")
      lines.append(f"**Open PRs:** {len(my_prs) if my_prs else 0}")
      if my_prs:
        for pr in my_prs[:5]:
          lines.append(f"- {mr_link(pr['id'], pr['title'])}")
      lines.append("")
      
      if pr_feedback:
        lines.append(f"**âš ï¸ Feedback Waiting ({len(pr_feedback)}):**")
        for fb in pr_feedback:
          lines.append(f"- {mr_link(fb['mr_id'])} - Comment from **{fb['author']}**")
      else:
        lines.append("âœ… No pending feedback on your PRs")
      lines.append("")
      
      # Failed pipelines
      if failed_pipelines:
        lines.append(f"**ğŸ”´ Failed Pipelines ({len(failed_pipelines)}):**")
        for fp in failed_pipelines:
          lines.append(f"- {mr_link(fp['mr_id'])} - {fp['status'].upper()}")
        lines.append("")
      
      # Review requests - PRs assigned to YOU for review
      lines.append("## ğŸ‘€ Review Requests")
      if review_requests:
        lines.append(f"**Assigned to you:** {len(review_requests)}")
        for rr in review_requests:
          lines.append(f"- {mr_link(rr['id'], rr['title'])}")
      else:
        lines.append("âœ… No PRs waiting for your review")
      lines.append("")
      
      # Jira
      jira_base = "https://issues.redhat.com/browse"
      
      def jira_link(key, summary=""):
        """Create a markdown hyperlink for a Jira issue."""
        if summary:
          return f"[{key}]({jira_base}/{key}) - {summary}"
        return f"[{key}]({jira_base}/{key})"
      
      lines.append("## ğŸ“‹ Jira Activity")
      if jira_activity and jira_activity.get('count', 0) > 0:
        lines.append(f"**{jira_activity.get('count', 0)}** issues updated in last {inputs.get('days_back', 1)} day(s)")
        for issue in jira_activity.get('issues', [])[:5]:
          lines.append(f"- {jira_link(issue['key'], issue['summary'])}")
      else:
        lines.append("- No Jira activity in the last day")
      lines.append("")
      
      # Merges
      lines.append("## ğŸš€ Recent Merges")
      if recent_merges:
        for mr in recent_merges:
          lines.append(f"- {mr_link(mr['id'], mr['title'])}")
      else:
        lines.append("- No recent merges")
      lines.append("")
      
      # Ephemeral Environments
      lines.append("## ğŸ§ª Ephemeral Environments")
      if ephemeral_namespaces:
        for ns in ephemeral_namespaces:
          expires = ns.get('expires', 'unknown')
          lines.append(f"- **{ns['name']}** - expires {expires}")
      else:
        lines.append("- No active ephemeral environments")
      lines.append("")
      
      # Yesterday's Work (for standup)
      lines.append("## ğŸ“ Yesterday's Work")
      if yesterdays_commits:
        for commit in yesterdays_commits[:5]:
          lines.append(f"- `{commit['sha']}` {commit['message']}")
      else:
        lines.append("- No commits yesterday")
      lines.append("")
      
      # Alerts
      lines.append("## ğŸš¨ Alerts")
      if alerts and not alerts.get('error'):
        if alerts.get('production') or alerts.get('stage'):
          for env, alert_list in alerts.items():
            if alert_list and env != 'error':
              lines.append(f"**{env.upper()}:**")
              for a in alert_list:
                lines.append(f"- {a}")
        else:
          lines.append("âœ… No active alerts")
      else:
        lines.append("- Alert check not configured")
      lines.append("")
      
      # Actions
      lines.append("---")
      lines.append("")
      lines.append("## ğŸ¯ Suggested Actions")
      actions = []
      
      if pr_feedback:
        actions.append(f"- Respond to feedback on {len(pr_feedback)} PR(s)")
      if failed_pipelines:
        actions.append(f"- Fix {len(failed_pipelines)} failed pipeline(s)")
      if review_requests:
        actions.append(f"- Review {len(review_requests)} PR(s) assigned to you")
      if email_summary and email_summary.get('important'):
        actions.append(f"- Review {len(email_summary['important'])} important emails")
      if ephemeral_namespaces:
        expiring = [ns for ns in ephemeral_namespaces if 'h' in str(ns.get('expires', '')) and int(re.search(r'(\d+)h', str(ns.get('expires', '0h'))).group(1) if re.search(r'(\d+)h', str(ns.get('expires', ''))) else 99) < 2]
        if expiring:
          actions.append(f"- â° {len(expiring)} ephemeral env(s) expiring soon!")
      
      if actions:
        for a in actions:
          lines.append(a)
      else:
        lines.append("- You're all caught up! â˜•")
      
      result = '\n'.join(lines)
    output: briefing

outputs:
  - name: summary
    value: "{{ briefing }}"
  
  - name: context
    value:
      calendar_count: "{{ calendar_events | length if calendar_events else 0 }}"
      unread_emails: "{{ email_summary.unread_count if email_summary else 0 }}"
      my_prs: "{{ my_prs | length if my_prs else 0 }}"
      feedback_waiting: "{{ pr_feedback | length if pr_feedback else 0 }}"
      failed_pipelines: "{{ failed_pipelines | length if failed_pipelines else 0 }}"
      review_requests: "{{ review_requests | length if review_requests else 0 }}"
      ephemeral_envs: "{{ ephemeral_namespaces | length if ephemeral_namespaces else 0 }}"
      yesterdays_commits: "{{ yesterdays_commits | length if yesterdays_commits else 0 }}"
      jira_updates: "{{ jira_activity.count if jira_activity else 0 }}"
      recent_merges: "{{ recent_merges | length if recent_merges else 0 }}"

