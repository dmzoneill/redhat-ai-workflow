# Skill: Silence Prometheus Alert
# Create, manage, and expire alert silences in Alertmanager

name: silence_alert
description: |
  Silence a Prometheus alert in Alertmanager.

  Use when:
  - You're working on a known issue and don't want alert noise
  - Performing maintenance and expect alerts
  - Need to temporarily suppress false positives

  The skill will:
  1. Verify the alert exists/is firing
  2. Create a silence with appropriate duration
  3. Optionally list existing silences
  4. Provide commands to extend or remove the silence

version: "1.0"

inputs:
  - name: alert_name
    type: string
    required: true
    description: "Name of the alert to silence (e.g., 'HighErrorRate', 'PodCrashLooping')"

  - name: duration
    type: string
    required: false
    default: "2h"
    description: "How long to silence (e.g., '1h', '2h', '4h', '24h')"

  - name: reason
    type: string
    required: false
    default: "Investigating issue"
    description: "Reason for silencing (for audit trail)"

  - name: environment
    type: string
    required: false
    default: "production"
    description: "Environment: 'production' or 'stage'"

  - name: namespace
    type: string
    required: false
    description: "Optionally scope silence to specific namespace"

  - name: action
    type: string
    required: false
    default: "create"
    description: "Action: 'create', 'list', or 'delete'"

  - name: silence_id
    type: string
    required: false
    description: "Silence ID (required for 'delete' action)"

steps:
  # ==================== KNOWLEDGE INTEGRATION ====================

  - name: get_alert_patterns
    description: "Get alert patterns and silence guidance from knowledge base"
    tool: knowledge_query
    args:
      project: "automation-analytics-backend"
      persona: "devops"
      query: "gotchas"
    output: alert_knowledge_raw
    on_error: continue

  - name: parse_alert_knowledge
    description: "Parse alert knowledge for silence context"
    compute: |
      knowledge_text = str(alert_knowledge_raw) if alert_knowledge_raw else ""

      gotchas = []
      runbooks = []

      # Extract gotchas related to alerts/silencing
      if knowledge_text:
          for line in knowledge_text.split("\n"):
              line_lower = line.lower()
              if any(kw in line_lower for kw in ["alert", "silence", "prometheus", "duration", "suppress"]):
                  gotchas.append(line.strip()[:150])
              if any(kw in line_lower for kw in ["runbook", "procedure", "when", "escalate"]):
                  runbooks.append(line.strip()[:150])

      result = {
          "has_knowledge": len(gotchas) > 0,
          "gotchas": gotchas[:5],
          "runbooks": runbooks[:3],
      }
    output: alert_knowledge
    on_error: continue

  # ==================== MEMORY CONTEXT ====================

  - name: check_known_issues
    description: "Check for known alertmanager issues"
    compute: |
      # Check known issues for alertmanager operations
      issues = memory.check_known_issues("alertmanager_create_silence", "")

      result = {
          "has_known_issues": len(issues.get("matches", [])) > 0 if issues else False,
          "issues": issues.get("matches", [])[:3] if issues else [],
      }
    output: known_issues
    on_error: continue

  - name: load_silence_history
    description: "Load previous silence history for this alert"
    compute: |
      # Load learned patterns
      patterns = memory.read_memory("learned/patterns") or {}
      silence_history = patterns.get("alert_silences", [])

      # Find history for this specific alert
      alert_history = [
          s for s in silence_history
          if s.get("alert_name") == inputs.alert_name
      ]

      # Check common durations for this alert
      common_durations = {}
      for h in alert_history:
          dur = h.get("duration")
          if dur:
              common_durations[dur] = common_durations.get(dur, 0) + 1

      result = {
          "previous_silences": len(alert_history),
          "recent_silences": alert_history[-5:],
          "common_durations": sorted(common_durations.keys(), key=lambda x: common_durations[x], reverse=True)[:3],
          "typical_reason": alert_history[-1].get("reason") if alert_history else None,
      }
    output: silence_history
    on_error: continue

  # ==================== CHECK CURRENT STATE ====================

  - name: check_current_alerts
    description: "Check if the alert is currently firing"
    condition: "inputs.action == 'create'"
    tool: alertmanager_alerts
    args:
      environment: "{{ inputs.environment }}"
    output: current_alerts_raw
    on_error: auto_heal  # Alertmanager - may need auth

  - name: parse_current_alerts
    description: "Check if our target alert is firing"
    condition: "inputs.action == 'create'"
    compute: |
      alerts_text = str(current_alerts_raw) if current_alerts_raw else ""

      alert_name = inputs.alert_name.lower()
      is_firing = alert_name in alerts_text.lower()

      # Count how many alerts match
      import re
      matches = re.findall(rf'{re.escape(inputs.alert_name)}', alerts_text, re.I)

      result = {
          "is_firing": is_firing,
          "match_count": len(matches),
          "alerts_preview": alerts_text[:500] if alerts_text else "No alerts data",
      }
    output: alert_status

  # ==================== LIST SILENCES ====================

  - name: list_existing_silences
    description: "List all current silences"
    tool: alertmanager_list_silences
    args:
      environment: "{{ inputs.environment }}"
    output: silences_list_raw
    on_error: continue

  - name: parse_silences
    description: "Parse existing silences"
    compute: |
      silences_text = str(silences_list_raw) if silences_list_raw else ""

      # Look for our alert in silences
      import re
      our_silence = None
      all_silences = []

      for line in silences_text.split("\n"):
          if line.strip():
              all_silences.append(line.strip()[:100])
              if inputs.alert_name.lower() in line.lower():
                  our_silence = line.strip()

      result = {
          "total_silences": len(all_silences),
          "already_silenced": our_silence is not None,
          "our_silence": our_silence,
          "all_silences": all_silences[:10],
      }
    output: silences_info

  # ==================== CREATE SILENCE ====================

  - name: create_silence
    description: "Create new silence for the alert"
    condition: "inputs.action == 'create' and not silences_info.already_silenced"
    tool: alertmanager_create_silence
    args:
      alert_name: "{{ inputs.alert_name }}"
      duration: "{{ inputs.duration }}"
      comment: "{{ inputs.reason }}"
      environment: "{{ inputs.environment }}"
    output: create_result
    on_error: continue

  - name: parse_create_result
    description: "Parse silence creation result"
    condition: "inputs.action == 'create'"
    compute: |
      result_text = str(create_result) if 'create_result' in dir() and create_result else ""

      # Extract silence ID if present
      import re
      silence_id = None
      id_match = re.search(r'([a-f0-9-]{36})', result_text)
      if id_match:
          silence_id = id_match.group(1)

      success = "success" in result_text.lower() or "created" in result_text.lower() or silence_id is not None

      result = {
          "success": success,
          "silence_id": silence_id,
          "raw": result_text[:300] if result_text else "No result",
      }
    output: create_status
    on_error: continue

  # ==================== DELETE SILENCE ====================

  - name: delete_silence
    description: "Delete an existing silence"
    condition: "inputs.action == 'delete' and inputs.silence_id"
    tool: alertmanager_delete_silence
    args:
      silence_id: "{{ inputs.silence_id }}"
      environment: "{{ inputs.environment }}"
    output: delete_result
    on_error: continue

  # ==================== MEMORY ====================

  - name: log_silence_action
    description: "Log silence action to session"
    condition: "(create_status and create_status.success) or delete_result"
    tool: memory_session_log
    args:
      action: "{{ 'Created' if inputs.action == 'create' else 'Deleted' }} alert silence"
      details: "Alert: {{ inputs.alert_name }}, Duration: {{ inputs.duration }}, Env: {{ inputs.environment }}"
    on_error: continue

  - name: learn_silence_pattern
    description: "Learn from this silence for future reference"
    condition: "create_status and create_status.success"
    compute: |
      from datetime import datetime

      # Load patterns
      patterns = memory.read_memory("learned/patterns") or {}
      if "alert_silences" not in patterns:
          patterns["alert_silences"] = []

      # Record this silence
      silence_record = {
          "alert_name": inputs.alert_name,
          "environment": inputs.environment,
          "duration": inputs.duration,
          "reason": inputs.reason,
          "namespace": inputs.namespace if inputs.get("namespace") else None,
          "silence_id": create_status.silence_id if create_status else None,
          "was_firing": alert_status.is_firing if alert_status else False,
          "timestamp": datetime.now().isoformat(),
      }

      patterns["alert_silences"].append(silence_record)

      # Keep last 100 silence records
      patterns["alert_silences"] = patterns["alert_silences"][-100:]

      memory.write_memory("learned/patterns", patterns)
      result = "silence pattern learned"
    output: pattern_learn_result
    on_error: continue

  - name: track_recurring_silences
    description: "Track alerts that are frequently silenced"
    condition: "create_status and create_status.success"
    compute: |
      from datetime import datetime

      # Load patterns
      patterns = memory.read_memory("learned/patterns") or {}
      if "recurring_silences" not in patterns:
          patterns["recurring_silences"] = []

      # Track this alert
      existing = [s for s in patterns["recurring_silences"] if s.get("alert_name") == inputs.alert_name]

      if existing:
          existing[0]["count"] = existing[0].get("count", 1) + 1
          existing[0]["last_silenced"] = datetime.now().isoformat()
          existing[0]["last_reason"] = inputs.reason
      else:
          patterns["recurring_silences"].append({
              "alert_name": inputs.alert_name,
              "environment": inputs.environment,
              "count": 1,
              "first_silenced": datetime.now().isoformat(),
              "last_silenced": datetime.now().isoformat(),
              "last_reason": inputs.reason,
          })

      # Keep top 50 recurring silences
      patterns["recurring_silences"] = sorted(
          patterns["recurring_silences"],
          key=lambda x: x.get("count", 0),
          reverse=True
      )[:50]

      memory.write_memory("learned/patterns", patterns)
      result = "recurring silence tracked"
    output: recurring_tracking_result
    on_error: continue

  - name: update_environment_state
    description: "Update environment state with active silences"
    condition: "create_status and create_status.success"
    compute: |
      from datetime import datetime

      # Update environment state
      env_data = memory.read_memory("state/environments") or {}
      if "environments" not in env_data:
          env_data["environments"] = {}

      env_key = inputs.environment
      if env_key not in env_data["environments"]:
          env_data["environments"][env_key] = {"status": "unknown", "active_silences": []}

      env = env_data["environments"][env_key]
      if "active_silences" not in env:
          env["active_silences"] = []

      # Add this silence
      env["active_silences"].append({
          "alert": inputs.alert_name,
          "silence_id": create_status.silence_id if create_status else None,
          "created": datetime.now().isoformat(),
          "duration": inputs.duration,
          "reason": inputs.reason,
      })

      # Keep last 20 silences
      env["active_silences"] = env["active_silences"][-20:]

      memory.write_memory("state/environments", env_data)
      result = "environment state updated"
    output: env_update_result
    on_error: continue

  # ==================== SEMANTIC SEARCH ====================

  - name: search_alert_code
    description: "Search for code related to this alert"
    tool: code_search
    args:
      query: "{{ inputs.alert_name }} prometheus alert monitoring"
      project: "automation-analytics-backend"
      limit: 3
    output: alert_code_raw
    on_error: continue

  - name: parse_alert_code
    description: "Parse alert code search results"
    condition: "alert_code_raw"
    compute: |
      code_result = alert_code_raw if alert_code_raw else {}

      related_code = []
      if isinstance(code_result, dict) and code_result.get('results'):
          for r in code_result.get('results', [])[:3]:
              related_code.append({
                  'file': r.get('file_path', ''),
                  'score': r.get('score', 0),
              })

      result = {
          'code': related_code,
          'count': len(related_code),
      }
    output: alert_code_analysis
    on_error: continue

  # ==================== LEARNING FROM FAILURES ====================

  - name: detect_silence_failures
    description: "Detect failure patterns from silence operations"
    compute: |
      errors_detected = []

      # Check Alertmanager failures
      alerts_text = str(current_alerts_raw) if 'current_alerts_raw' in dir() and current_alerts_raw else ""
      silences_text = str(silences_list_raw) if 'silences_list_raw' in dir() and silences_list_raw else ""
      create_text = str(create_result) if 'create_result' in dir() and create_result else ""
      combined = alerts_text + silences_text + create_text

      if "connection refused" in combined.lower() or "no route to host" in combined.lower():
          errors_detected.append({
              "tool": "alertmanager_create_silence",
              "pattern": "connection refused",
              "cause": "Cannot connect to Alertmanager - VPN or network issue",
              "fix": "Run vpn_connect() to connect to Red Hat VPN"
          })
      if "unauthorized" in combined.lower():
          errors_detected.append({
              "tool": "alertmanager_create_silence",
              "pattern": "unauthorized",
              "cause": "Alertmanager authentication failed",
              "fix": "Check Alertmanager credentials in config.json"
          })

      result = errors_detected
    output: silence_errors_detected
    on_error: continue

  - name: learn_silence_connection_failure
    description: "Learn from Alertmanager connection failures"
    condition: "silence_errors_detected and any(e.get('pattern') == 'connection refused' for e in silence_errors_detected)"
    tool: learn_tool_fix
    args:
      tool_name: "alertmanager_create_silence"
      error_pattern: "connection refused"
      root_cause: "Cannot connect to Alertmanager - VPN or network issue"
      fix_description: "Run vpn_connect() to connect to Red Hat VPN"
    output: silence_conn_fix_learned
    on_error: continue

outputs:
  - name: report
    value: |
      ## üîï Alert Silence Manager

      **Alert:** `{{ inputs.alert_name }}`
      **Environment:** {{ inputs.environment }}

      {% if inputs.action == 'list' %}
      ### üìã Current Silences

      {% if silences_info.total_silences > 0 %}
      Found **{{ silences_info.total_silences }}** active silences:

      {% for silence in silences_info.all_silences[:10] %}
      - {{ silence }}
      {% endfor %}
      {% else %}
      No active silences found.
      {% endif %}

      {% elif inputs.action == 'delete' %}
      ### üóëÔ∏è Delete Silence

      {% if delete_result %}
      {{ delete_result }}
      {% else %}
      ‚ùå Could not delete silence. Ensure the silence_id is correct.
      {% endif %}

      {% elif inputs.action == 'create' %}
      ### Create Silence

      {% if silences_info.already_silenced %}
      ‚ö†Ô∏è **Already Silenced**

      This alert already has an active silence:
      ```
      {{ silences_info.our_silence }}
      ```

      To modify, delete the existing silence first.

      {% elif create_status and create_status.success %}
      ‚úÖ **Silence Created**

      **Duration:** {{ inputs.duration }}
      **Reason:** {{ inputs.reason }}
      {% if create_status.silence_id %}
      **Silence ID:** `{{ create_status.silence_id }}`
      {% endif %}

      ### Manage This Silence

      **Extend duration:**
      ```python
      alertmanager_create_silence(alert_name='{{ inputs.alert_name }}', duration='4h', environment='{{ inputs.environment }}')
      ```

      **Remove silence:**
      ```python
      alertmanager_delete_silence(silence_id='{{ create_status.silence_id or "SILENCE_ID" }}', environment='{{ inputs.environment }}')
      ```

      {% else %}
      ‚ùå **Failed to Create Silence**

      {{ create_status.raw if create_status else "Unknown error" }}

      {% if not alert_status.is_firing %}
      ‚ö†Ô∏è Note: The alert `{{ inputs.alert_name }}` is not currently firing.
      You can still create a silence, but verify the alert name is correct.
      {% endif %}

      {% endif %}

      {% endif %}

      ---

      ### Alert Status
      {% if alert_status %}
      {% if alert_status.is_firing %}
      üî¥ **{{ inputs.alert_name }}** is firing ({{ alert_status.match_count }} instances)
      {% else %}
      üü¢ **{{ inputs.alert_name }}** is not currently firing
      {% endif %}
      {% endif %}

  - name: context
    value:
      action: "{{ inputs.action }}"
      alert_name: "{{ inputs.alert_name }}"
      is_firing: "{{ alert_status.is_firing if alert_status else false }}"
      already_silenced: "{{ silences_info.already_silenced if silences_info else false }}"
      silence_created: "{{ create_status.success if create_status else false }}"
      silence_id: "{{ create_status.silence_id if create_status else None }}"
