# Skill: App Interface Check
# Validate app-interface configuration and compare to live state

name: appinterface_check
description: |
  Comprehensive app-interface validation and release readiness check.

  This skill:
  - Validates YAML configuration, $ref paths, and SHA formats
  - Compares app-interface refs to live cluster state
  - Shows resource quotas and limits
  - Lists pending MRs that may affect release
  - Assesses overall release readiness with blockers/warnings

  Uses: appinterface_get_saas, appinterface_diff, appinterface_resources,
        kubectl_get_deployments, kubectl_get_resourcequotas, gitlab_mr_list
version: "3.1"

inputs:
  - name: saas_file
    type: string
    required: false
    default: "tower-analytics"
    description: "SaaS file name to check (service name)"

  - name: namespace_stage
    type: string
    required: false
    default: "tower-analytics-stage"
    description: "Stage namespace"

  - name: namespace_prod
    type: string
    required: false
    default: "tower-analytics-prod"
    description: "Production namespace"

  - name: deployment
    type: string
    required: false
    default: "automation-analytics-api-fastapi-v2"
    description: "Deployment to check for live SHA"

  - name: stale_days
    type: integer
    required: false
    default: 7
    description: "Alert if deployed SHA is older than this many days"

  - name: gitlab_project
    type: string
    required: false
    default: "automation-analytics/automation-analytics-backend"
    description: "GitLab project to check for pending MRs"

steps:
  # ==================== KNOWLEDGE INTEGRATION ====================

  - name: check_appinterface_known_issues
    description: "Check for known app-interface and release issues"
    compute: |
      # Check known issues for app-interface operations
      appinterface_issues = memory.check_known_issues("appinterface", "") or {}
      release_issues = memory.check_known_issues("release", "") or {}
      saas_issues = memory.check_known_issues("saas", "") or {}

      all_issues = []
      for issues in [appinterface_issues, release_issues, saas_issues]:
          if issues and issues.get("matches"):
              all_issues.extend(issues.get("matches", [])[:2])

      result = {
          "has_known_issues": len(all_issues) > 0,
          "issues": all_issues[:5],
      }
    output: appinterface_known_issues
    on_error: continue

  - name: get_release_gotchas
    description: "Get release-related gotchas from knowledge"
    tool: knowledge_query
    args:
      project: "automation-analytics-backend"
      persona: "release"
      section: "gotchas"
    output: release_gotchas_raw
    on_error: continue

  - name: parse_release_gotchas
    description: "Parse release-related gotchas"
    compute: |
      gotchas_result = release_gotchas_raw if 'release_gotchas_raw' in dir() and release_gotchas_raw else {}

      release_gotchas = []
      if isinstance(gotchas_result, dict) and gotchas_result.get('found'):
          content = gotchas_result.get('content', [])
          if isinstance(content, list):
              # Filter for release-related gotchas
              for g in content:
                  g_str = str(g).lower()
                  if any(kw in g_str for kw in ['release', 'app-interface', 'saas', 'sha', 'prod', 'stage', 'promote']):
                      release_gotchas.append(g)

      result = {
          'gotchas': release_gotchas[:5],
          'has_gotchas': len(release_gotchas) > 0,
      }
    output: release_check_gotchas
    on_error: continue

  # ==================== GET SAAS FILES ====================

  - name: get_saas_file
    description: "Get SaaS file details"
    tool: appinterface_get_saas
    args:
      service_name: "{{ inputs.saas_file }}"
    output: saas_raw
    on_error: auto_heal  # App Interface - may need auth

  - name: parse_saas_refs
    description: "Extract stage and prod refs from SaaS file"
    compute: |
      import re

      saas_text = str(saas_raw) if 'saas_raw' in dir() and saas_raw else ""

      # Find all refs (40-char hex SHAs)
      sha_pattern = r'ref:\s*([a-f0-9]{40})'
      sha_refs = re.findall(sha_pattern, saas_text)

      # Find all $ref paths
      ref_paths = re.findall(r'\$ref:\s*(\S+)', saas_text)

      # Try to identify stage vs prod refs from context
      stage_ref = None
      prod_ref = None

      lines = saas_text.split('\n')
      in_stage = False
      in_prod = False

      for i, line in enumerate(lines):
        if 'stage' in line.lower():
          in_stage = True
          in_prod = False
        elif 'prod' in line.lower():
          in_prod = True
          in_stage = False

        sha_match = re.search(r'ref:\s*([a-f0-9]{40})', line)
        if sha_match:
          if in_stage and not stage_ref:
            stage_ref = sha_match.group(1)
          elif in_prod and not prod_ref:
            prod_ref = sha_match.group(1)

      # Fallback: use first two refs found
      if not stage_ref and len(sha_refs) > 0:
        stage_ref = sha_refs[0]
      if not prod_ref and len(sha_refs) > 1:
        prod_ref = sha_refs[1]

      result = {
        "stage_ref": stage_ref or "main",
        "prod_ref": prod_ref or "unknown",
        "all_refs": sha_refs[:5],
        "ref_paths": ref_paths[:10],
        "raw_preview": saas_text[:1000],
      }
    output: saas_refs

  # ==================== VALIDATION ====================

  - name: validate_refs
    description: "Validate $ref paths and SHA formats"
    compute: |
      import re
      import os

      saas_text = str(saas_raw) if 'saas_raw' in dir() and saas_raw else ""
      issues = []
      warnings = []

      # Check SHA format (must be 40-char hex or 'main')
      sha_pattern = r'ref:\s*(\S+)'
      refs = re.findall(sha_pattern, saas_text)

      for ref in refs:
        if ref == 'main':
          continue
        if not re.match(r'^[a-f0-9]{40}$', ref):
          if re.match(r'^[a-f0-9]+$', ref) and len(ref) < 40:
            issues.append(f"Short SHA detected: {ref[:12]}... (should be 40 chars)")
          elif not ref.startswith('/') and not ref.startswith('$'):
            warnings.append(f"Non-standard ref: {ref[:30]}")

      # Check $ref paths point to reasonable locations
      ref_paths = re.findall(r'\$ref:\s*(/\S+)', saas_text)
      for path in ref_paths:
        if not path.startswith('/services/') and not path.startswith('/dependencies/'):
          warnings.append(f"Unusual $ref path: {path[:40]}")

      # Check required fields
      required_fields = ['name:', 'app:', 'resourceTemplates:']
      for field in required_fields:
        if field not in saas_text:
          issues.append(f"Missing required field: {field}")

      valid = len(issues) == 0

      result = {
        "valid": valid,
        "issues": issues,
        "warnings": warnings,
        "ref_count": len(refs),
        "path_count": len(ref_paths),
      }
    output: validation_result

  # ==================== GET LIVE STATE ====================

  - name: get_live_stage
    description: "Get live deployment from stage cluster"
    tool: kubectl_get_deployments
    args:
      namespace: "{{ inputs.namespace_stage }}"
      environment: "stage"
    output: live_stage_raw
    on_error: auto_heal  # K8s cluster - may need kube_login

  - name: parse_live_stage
    description: "Extract deployed image SHA from stage"
    compute: |
      import re

      deploy_text = str(live_stage_raw) if 'live_stage_raw' in dir() and live_stage_raw else ""
      deployment_name = str(inputs.get('deployment', 'automation-analytics-api-fastapi-v2'))

      # Look for image tags in the deployment output
      # Format: quay.io/...@sha256:xxx or :sha
      image_pattern = r'quay\.io/[^\s]+[:\@]([a-f0-9]{40,64})'
      images = re.findall(image_pattern, deploy_text)

      # Also check for IMAGE column in kubectl output
      sha_pattern = r'([a-f0-9]{40})'
      shas = re.findall(sha_pattern, deploy_text)

      live_sha = None
      if shas:
        # Prefer 40-char git SHAs over 64-char digests
        for sha in shas:
          if len(sha) == 40:
            live_sha = sha
            break
        if not live_sha:
          live_sha = shas[0][:40] if shas else None

      result = {
        "live_sha": live_sha,
        "deployment_found": deployment_name in deploy_text,
        "raw": deploy_text[:500] if deploy_text else "",
      }
    output: live_stage

  - name: get_live_prod
    description: "Get live deployment from prod cluster"
    tool: kubectl_get_deployments
    args:
      namespace: "{{ inputs.namespace_prod }}"
      environment: "prod"
    output: live_prod_raw
    on_error: auto_heal  # K8s cluster - may need kube_login

  - name: parse_live_prod
    description: "Extract deployed image SHA from prod"
    compute: |
      import re

      deploy_text = str(live_prod_raw) if 'live_prod_raw' in dir() and live_prod_raw else ""

      sha_pattern = r'([a-f0-9]{40})'
      shas = re.findall(sha_pattern, deploy_text)

      live_sha = shas[0] if shas else None

      result = {
        "live_sha": live_sha,
        "raw": deploy_text[:500] if deploy_text else "",
      }
    output: live_prod

  # ==================== COMPARE STATE ====================

  - name: compare_state
    description: "Compare app-interface refs to live state"
    compute: |
      from datetime import datetime, timedelta

      stage_ref = saas_refs.get('stage_ref', 'unknown') if isinstance(saas_refs, dict) else 'unknown'
      prod_ref = saas_refs.get('prod_ref', 'unknown') if isinstance(saas_refs, dict) else 'unknown'

      live_stage_sha = live_stage.get('live_sha') if isinstance(live_stage, dict) else None
      live_prod_sha = live_prod.get('live_sha') if isinstance(live_prod, dict) else None

      # Compare stage
      stage_match = False
      if stage_ref and live_stage_sha:
        stage_match = stage_ref[:12] == live_stage_sha[:12] if live_stage_sha else False

      # Compare prod
      prod_match = False
      if prod_ref and live_prod_sha:
        prod_match = prod_ref[:12] == live_prod_sha[:12] if live_prod_sha else False

      # Check if stage is ahead of prod (ready to promote)
      stage_ahead = stage_ref != prod_ref and stage_ref != 'main'

      # Build status
      issues = []
      if not stage_match and live_stage_sha:
        issues.append(f"Stage drift: app-interface has {stage_ref[:8]}... but cluster has {live_stage_sha[:8]}...")
      if not prod_match and live_prod_sha:
        issues.append(f"Prod drift: app-interface has {prod_ref[:8]}... but cluster has {live_prod_sha[:8]}...")

      result = {
        "stage_ref": stage_ref,
        "prod_ref": prod_ref,
        "live_stage_sha": live_stage_sha,
        "live_prod_sha": live_prod_sha,
        "stage_in_sync": stage_match,
        "prod_in_sync": prod_match,
        "stage_ahead_of_prod": stage_ahead,
        "issues": issues,
        "ready_to_promote": stage_ahead and stage_match,
      }
    output: state_comparison

  # ==================== CHECK FOR CHANGES ====================

  - name: get_diff
    description: "Get diff from main branch"
    tool: appinterface_diff
    args: {}
    output: diff_raw
    on_error: auto_heal  # App Interface - may need auth

  - name: parse_diff
    description: "Parse diff for tower-analytics changes"
    compute: |
      import re

      diff_text = str(diff_raw) if 'diff_raw' in dir() and diff_raw else ""
      service_name = str(inputs.get('saas_file', 'tower-analytics'))

      has_changes = len(diff_text.strip()) > 0 and "no changes" not in diff_text.lower()

      # Filter for service-specific changes
      file_changes = re.findall(r'^\+\+\+ b/(.+)$', diff_text, re.M)
      service_changes = [f for f in file_changes if service_name in f.lower()]

      result = {
        "has_changes": has_changes,
        "all_changed_files": len(file_changes),
        "service_changes": service_changes[:10],
        "service_change_count": len(service_changes),
        "preview": diff_text[:600] if diff_text else "",
      }
    output: diff_info

  # ==================== GET RESOURCES ====================

  - name: list_resources
    description: "List app-interface resources"
    tool: appinterface_resources
    args:
      namespace: "{{ inputs.namespace_stage }}"
    output: resources_raw
    on_error: auto_heal  # App Interface - may need auth

  - name: parse_resources
    description: "Parse resources"
    compute: |
      resources_text = str(resources_raw) if 'resources_raw' in dir() and resources_raw else ""

      resources = []
      for line in resources_text.split("\n"):
        line = line.strip()
        if line and not line.startswith("#") and not line.startswith("##"):
          resources.append(line[:80])

      result = {
        "resources": resources[:20],
        "count": len(resources),
      }
    output: resources_info

  # ==================== GET QUOTAS ====================

  - name: get_quota_stage
    description: "Get resource quotas from stage namespace"
    tool: kubectl_get
    args:
      resource: "resourcequota"
      namespace: "{{ inputs.namespace_stage }}"
      environment: "stage"
    output: quota_stage_raw
    on_error: auto_heal  # K8s cluster - may need kube_login

  - name: get_limits_stage
    description: "Get limit ranges from stage namespace"
    tool: kubectl_get
    args:
      resource: "limitrange"
      namespace: "{{ inputs.namespace_stage }}"
      environment: "stage"
    output: limits_stage_raw
    on_error: auto_heal  # K8s cluster - may need kube_login

  - name: parse_quotas
    description: "Parse quota and limit information"
    compute: |
      import re

      quota_text = str(quota_stage_raw) if 'quota_stage_raw' in dir() and quota_stage_raw else ""
      limits_text = str(limits_stage_raw) if 'limits_stage_raw' in dir() and limits_stage_raw else ""

      quotas = {}
      limits = {}

      # Parse CPU quota
      cpu_match = re.search(r'cpu[:\s]+(\d+[mM]?)', quota_text)
      if cpu_match:
        quotas['cpu'] = cpu_match.group(1)

      # Parse memory quota
      mem_match = re.search(r'memory[:\s]+(\d+[GgMmKk]i?)', quota_text)
      if mem_match:
        quotas['memory'] = mem_match.group(1)

      # Parse pod count
      pod_match = re.search(r'pods[:\s]+(\d+)', quota_text)
      if pod_match:
        quotas['pods'] = pod_match.group(1)

      # Parse limits
      limit_cpu = re.search(r'default.*cpu[:\s]+(\d+[mM]?)', limits_text, re.I)
      if limit_cpu:
        limits['default_cpu'] = limit_cpu.group(1)

      limit_mem = re.search(r'default.*memory[:\s]+(\d+[GgMmKk]i?)', limits_text, re.I)
      if limit_mem:
        limits['default_memory'] = limit_mem.group(1)

      result = {
        "quotas": quotas,
        "limits": limits,
        "quota_raw": quota_text[:300] if quota_text else "No quotas found",
        "limits_raw": limits_text[:300] if limits_text else "No limits found",
        "has_quotas": len(quotas) > 0,
        "has_limits": len(limits) > 0,
      }
    output: quota_info

  # ==================== GET PENDING MRs ====================

  - name: get_pending_mrs
    description: "Get open MRs that might affect this service"
    tool: gitlab_mr_list
    args:
      project: "{{ inputs.gitlab_project }}"
      state: "opened"
      per_page: 10
    output: mrs_raw
    on_error: auto_heal  # GitLab API - may need auth refresh

  # ==================== SEMANTIC SEARCH ====================

  - name: search_release_code
    description: "Search for release-related code and configuration"
    tool: code_search
    args:
      query: "{{ inputs.saas_file }} release deployment configuration"
      project: "automation-analytics-backend"
      limit: 5
    output: release_code_raw
    on_error: continue

  - name: parse_release_code
    description: "Parse release code search results"
    condition: "release_code_raw"
    compute: |
      code_result = release_code_raw if release_code_raw else {}

      related_code = []
      if isinstance(code_result, dict) and code_result.get('results'):
          for r in code_result.get('results', [])[:5]:
              related_code.append({
                  'file': r.get('file_path', ''),
                  'score': r.get('score', 0),
                  'preview': r.get('code_chunk', '')[:100] if r.get('code_chunk') else '',
              })

      result = {
          'code': related_code,
          'count': len(related_code),
          'has_related_code': len(related_code) > 0,
      }
    output: release_code_analysis
    on_error: continue

  - name: parse_pending_mrs
    description: "Parse pending MRs for release-relevant changes"
    compute: |
      import re

      mrs_text = str(mrs_raw) if 'mrs_raw' in dir() and mrs_raw else ""

      # Extract MR info from the listing
      mr_pattern = r'!(\d+)\s+\S+!(\d+)\s+(.+?)\s+\(main\)'
      mrs = re.findall(mr_pattern, mrs_text)

      pending_mrs = []
      for mr in mrs[:5]:
        mr_id = mr[0]
        title = mr[2].strip()[:60]
        pending_mrs.append({
          "id": mr_id,
          "title": title,
        })

      # Also extract from simpler format
      if not pending_mrs:
        simple_pattern = r'!(\d+)[^\n]+\n[^\n]*([A-Z]+-\d+[^\n]+)'
        simple_mrs = re.findall(simple_pattern, mrs_text)
        for mr in simple_mrs[:5]:
          pending_mrs.append({
            "id": mr[0],
            "title": mr[1].strip()[:60],
          })

      result = {
        "pending_mrs": pending_mrs,
        "count": len(pending_mrs),
        "raw": mrs_text[:500] if mrs_text else "",
      }
    output: pending_mrs_info

  # ==================== RELEASE READINESS ====================

  - name: assess_release_readiness
    description: "Assess overall release readiness"
    compute: |
      # Gather all signals
      validation_ok = validation_result.get('valid', False) if isinstance(validation_result, dict) else False
      stage_in_sync = state_comparison.get('stage_in_sync', False) if isinstance(state_comparison, dict) else False
      stage_ahead = state_comparison.get('stage_ahead_of_prod', False) if isinstance(state_comparison, dict) else False
      no_pending_changes = not diff_info.get('service_change_count', 0) if isinstance(diff_info, dict) else True
      pending_mr_count = pending_mrs_info.get('count', 0) if isinstance(pending_mrs_info, dict) else 0

      # Determine readiness
      ready = validation_ok and stage_ahead and no_pending_changes
      blockers = []

      if not validation_ok:
        blockers.append("Validation issues found")
      if not stage_ahead:
        blockers.append("Stage is not ahead of prod (nothing to promote)")
      if not no_pending_changes:
        blockers.append("Uncommitted changes in app-interface")

      warnings = []
      if pending_mr_count > 0:
        warnings.append(f"{pending_mr_count} open MRs - consider waiting for merge")
      if not stage_in_sync:
        warnings.append("Stage cluster may not reflect app-interface yet")

      stage_ref = state_comparison.get('stage_ref', '') if isinstance(state_comparison, dict) else ''
      prod_ref = state_comparison.get('prod_ref', '') if isinstance(state_comparison, dict) else ''

      result = {
        "ready": ready,
        "blockers": blockers,
        "warnings": warnings,
        "stage_ref": stage_ref,
        "prod_ref": prod_ref,
        "commits_ahead": 1 if stage_ahead else 0,  # Simplified
      }
    output: release_readiness

outputs:
  - name: report
    value: |
      ## üìã App-Interface Check: {{ inputs.saas_file }}

      ---

      ### ‚úÖ Validation

      {% if validation_result.valid %}
      ‚úÖ Configuration valid ({{ validation_result.ref_count }} refs, {{ validation_result.path_count }} paths)
      {% else %}
      ‚ùå **Issues found:**
      {% for issue in validation_result.issues %}
      - {{ issue }}
      {% endfor %}
      {% endif %}

      {% if validation_result.warnings %}
      ‚ö†Ô∏è **Warnings:**
      {% for warn in validation_result.warnings %}
      - {{ warn }}
      {% endfor %}
      {% endif %}

      ---

      ### üîÑ Live State Comparison

      **Stage:**
      - App-Interface: `{{ state_comparison.stage_ref[:12] }}...`
      - Live Cluster: `{{ state_comparison.live_stage_sha[:12] if state_comparison.live_stage_sha else 'N/A' }}`
      - Status: {% if state_comparison.stage_in_sync %}‚úÖ In Sync{% else %}‚ö†Ô∏è Drift{% endif %}

      **Prod:**
      - App-Interface: `{{ state_comparison.prod_ref[:12] }}...`
      - Live Cluster: `{{ state_comparison.live_prod_sha[:12] if state_comparison.live_prod_sha else 'N/A' }}`
      - Status: {% if state_comparison.prod_in_sync %}‚úÖ In Sync{% else %}‚ö†Ô∏è Drift{% endif %}

      {% if state_comparison.ready_to_promote %}
      üöÄ **Ready to promote!** Stage is ahead of prod and in sync with cluster.
      {% endif %}

      {% if state_comparison.stage_ahead_of_prod and not state_comparison.ready_to_promote %}
      ‚ÑπÔ∏è Stage has newer ref than prod ({{ state_comparison.stage_ref[:8] }}... vs {{ state_comparison.prod_ref[:8] }}...)
      {% endif %}

      {% if state_comparison.issues %}
      ‚ö†Ô∏è **Drift detected:**
      {% for issue in state_comparison.issues %}
      - {{ issue }}
      {% endfor %}
      {% endif %}

      ---

      ### üìù Pending Changes

      {% if diff_info.service_change_count > 0 %}
      **{{ diff_info.service_change_count }} uncommitted changes for {{ inputs.saas_file }}:**
      {% for file in diff_info.service_changes %}
      - `{{ file }}`
      {% endfor %}
      {% elif diff_info.has_changes %}
      ‚úÖ No changes to {{ inputs.saas_file }} ({{ diff_info.all_changed_files }} other files changed)
      {% else %}
      ‚úÖ No uncommitted changes
      {% endif %}

      ---

      ### üì¶ Namespace Resources

      {{ resources_info.count }} config files for `{{ inputs.namespace_stage }}`

      {% if quota_info.has_quotas or quota_info.has_limits %}
      **Resource Quotas:**
      {% for key, val in quota_info.quotas.items() %}
      - {{ key }}: {{ val }}
      {% endfor %}

      **Default Limits:**
      {% for key, val in quota_info.limits.items() %}
      - {{ key }}: {{ val }}
      {% endfor %}
      {% endif %}

      ---

      ### üîÄ Pending Merge Requests

      {% if pending_mrs_info.count > 0 %}
      **{{ pending_mrs_info.count }} open MRs:**
      {% for mr in pending_mrs_info.pending_mrs %}
      - !{{ mr.id }} - {{ mr.title }}
      {% endfor %}
      {% else %}
      ‚úÖ No pending MRs
      {% endif %}

      ---

      ### üöÄ Release Readiness

      {% if release_readiness.ready %}
      ‚úÖ **Ready to release!**
      - Stage ref: `{{ release_readiness.stage_ref[:12] }}...`
      - Prod ref: `{{ release_readiness.prod_ref[:12] }}...`
      {% else %}
      ‚ùå **Not ready to release**
      {% for blocker in release_readiness.blockers %}
      - ‚ùå {{ blocker }}
      {% endfor %}
      {% endif %}

      {% if release_readiness.warnings %}
      ‚ö†Ô∏è **Warnings:**
      {% for warn in release_readiness.warnings %}
      - {{ warn }}
      {% endfor %}
      {% endif %}

      ---

      ### üõ†Ô∏è Actions

      {% if release_readiness.ready %}
      ```python
      # Promote stage to prod
      skill_run("release_to_prod", '{"commit_sha": "{{ release_readiness.stage_ref }}"}')
      ```
      {% endif %}

      ```python
      # Check prod namespace
      skill_run("appinterface_check", '{"namespace_stage": "{{ inputs.namespace_prod }}"}')
      ```

      {% if release_check_gotchas and release_check_gotchas.has_gotchas %}
      ---

      ### ‚ö†Ô∏è Release Gotchas

      {% for gotcha in release_check_gotchas.gotchas[:3] %}
      - {{ gotcha }}
      {% endfor %}
      {% endif %}

      {% if appinterface_known_issues and appinterface_known_issues.has_known_issues %}
      ---

      ### üí° Known Issues

      {% for issue in appinterface_known_issues.issues[:3] %}
      - {{ issue.pattern if issue.pattern else issue }}
      {% endfor %}
      {% endif %}

  # ==================== LEARNING FROM FAILURES ====================

  - name: detect_appinterface_failures
    description: "Detect failure patterns from app-interface checks"
    compute: |
      errors_detected = []

      # Check app-interface failures
      saas_text = str(saas_config_raw) if 'saas_config_raw' in dir() and saas_config_raw else ""
      if "not found" in saas_text.lower():
          errors_detected.append({
              "tool": "appinterface_get_saas",
              "pattern": "not found",
              "cause": "SaaS file not found in app-interface",
              "fix": "Check saas_file input parameter"
          })

      # Check Kubernetes failures
      stage_text = str(stage_deploy_raw) if 'stage_deploy_raw' in dir() and stage_deploy_raw else ""
      prod_text = str(prod_deploy_raw) if 'prod_deploy_raw' in dir() and prod_deploy_raw else ""
      combined_k8s = stage_text + prod_text

      if "forbidden" in combined_k8s.lower() or "unauthorized" in combined_k8s.lower():
          errors_detected.append({
              "tool": "kubectl_get_deployments",
              "pattern": "forbidden",
              "cause": "Kubernetes auth expired or insufficient permissions",
              "fix": "Run kube_login('stage') and kube_login('prod')"
          })
      if "no route to host" in combined_k8s.lower():
          errors_detected.append({
              "tool": "kubectl_get_deployments",
              "pattern": "no route to host",
              "cause": "VPN not connected - cluster not reachable",
              "fix": "Run vpn_connect()"
          })

      # Check GitLab failures
      gitlab_text = str(pending_mrs_raw) if 'pending_mrs_raw' in dir() and pending_mrs_raw else ""
      if "no such host" in gitlab_text.lower():
          errors_detected.append({
              "tool": "gitlab_mr_list",
              "pattern": "no such host",
              "cause": "VPN not connected - internal GitLab not reachable",
              "fix": "Run vpn_connect() to connect to Red Hat VPN"
          })

      result = errors_detected
    output: appinterface_errors_detected
    on_error: continue

  - name: learn_appinterface_k8s_failure
    description: "Learn from Kubernetes auth failures"
    condition: "appinterface_errors_detected and any(e.get('pattern') == 'forbidden' for e in appinterface_errors_detected)"
    tool: learn_tool_fix
    args:
      tool_name: "kubectl_get_deployments"
      error_pattern: "forbidden"
      root_cause: "Kubernetes auth expired or insufficient permissions"
      fix_description: "Run kube_login('stage') and kube_login('prod')"
    output: appinterface_k8s_fix_learned
    on_error: continue

  - name: learn_appinterface_vpn_failure
    description: "Learn from VPN failures"
    condition: "appinterface_errors_detected and any(e.get('pattern') == 'no route to host' for e in appinterface_errors_detected)"
    tool: learn_tool_fix
    args:
      tool_name: "kubectl_get_deployments"
      error_pattern: "no route to host"
      root_cause: "VPN not connected - cluster not reachable"
      fix_description: "Run vpn_connect()"
    output: appinterface_vpn_fix_learned
    on_error: continue

  - name: log_appinterface_session
    description: "Log app-interface check to session"
    tool: memory_session_log
    args:
      action: "Checked app-interface for {{ inputs.saas_file }}"
      details: "Ready: {{ release_readiness.ready if release_readiness else 'unknown' }}, Blockers: {{ release_readiness.blockers | length if release_readiness and release_readiness.blockers else 0 }}"
    on_error: continue

  - name: track_appinterface_checks
    description: "Track app-interface checks for patterns"
    compute: |
      from datetime import datetime

      # Load patterns
      patterns = memory.read_memory("learned/patterns") or {}
      if "appinterface_checks" not in patterns:
          patterns["appinterface_checks"] = []

      # Record this check
      check_record = {
          "saas_file": inputs.saas_file,
          "ready": release_readiness.ready if release_readiness else False,
          "blockers": len(release_readiness.blockers) if release_readiness and release_readiness.blockers else 0,
          "warnings": len(release_readiness.warnings) if release_readiness and release_readiness.warnings else 0,
          "stage_in_sync": state_comparison.stage_in_sync if state_comparison else False,
          "prod_in_sync": state_comparison.prod_in_sync if state_comparison else False,
          "timestamp": datetime.now().isoformat(),
      }

      patterns["appinterface_checks"].append(check_record)

      # Keep last 100 checks
      patterns["appinterface_checks"] = patterns["appinterface_checks"][-100:]

      memory.write_memory("learned/patterns", patterns)
      result = "appinterface check tracked"
    output: appinterface_tracking_result
    on_error: continue

  - name: update_release_state
    description: "Update release readiness state"
    condition: "release_readiness"
    compute: |
      from datetime import datetime

      # Update release state
      state = memory.read_memory("state/release") or {}

      state["last_check"] = {
          "saas_file": inputs.saas_file,
          "ready": release_readiness.ready if release_readiness else False,
          "stage_ref": release_readiness.stage_ref if release_readiness else None,
          "prod_ref": release_readiness.prod_ref if release_readiness else None,
          "timestamp": datetime.now().isoformat(),
      }

      memory.write_memory("state/release", state)
      result = "release state updated"
    output: release_state_result
    on_error: continue
