# Skill: Debug Production Issues
# Systematic investigation of production problems

name: debug_prod
description: |
  Investigate production issues in Automation Analytics.
  Gathers pod status, logs, metrics, alerts, and recent deployments.
  Suggests likely causes based on patterns and learned knowledge.

  Resolves namespace and paths from config.json.
version: "1.1"

inputs:
  - name: namespace
    type: string
    required: false
    description: "Namespace to investigate: 'main' or 'billing' (will ask if not provided)"

  - name: alert_name
    type: string
    required: false
    description: "Prometheus alert name if triggered by an alert"

  - name: pod_filter
    type: string
    required: false
    description: "Filter pods by name (e.g., 'fastapi', 'processor')"

  - name: time_range
    type: string
    required: false
    default: "1h"
    description: "How far back to search (15m, 1h, 6h, 24h)"

# No hardcoded constants - resolved dynamically from config.json

steps:
  # ==================== LOAD CONFIG ====================

  - name: load_config
    description: "Load namespace and path configuration"
    compute: |
      import os
      from scripts.common.config_loader import load_config

      config = load_config()

      # Get namespace config
      ns_config = config.get("namespaces", {}).get("production", {})
      ai_config = config.get("app_interface", {})
      repos = config.get("repositories", {})
      paths_cfg = config.get("paths", {})

      # Get app-interface repo path
      ai_repo_name = ai_config.get("repo", "app-interface")
      ai_repo_path = ai_config.get("path") or repos.get(ai_repo_name, {}).get("path", "")
      if not ai_repo_path:
          # Try workspace_roots
          workspace_roots = paths_cfg.get("workspace_roots", [])
          for root in workspace_roots:
              candidate = os.path.join(os.path.expanduser(root), "app-interface")
              if os.path.exists(candidate):
                  ai_repo_path = candidate
                  break

      # Get namespace file names from config
      ns_files = ai_config.get("namespace_files", {})

      result = {
          "namespace_main": ns_config.get("main", "tower-analytics-prod"),
          "namespace_billing": ns_config.get("billing", "tower-analytics-prod-billing"),
          "kubeconfig": ns_config.get("kubeconfig", "~/.kube/config.p"),
          "alerts_main": ai_config.get("alerts", {}).get("prod_main", "resources/insights-prod/tower-analytics-prod"),
          "alerts_billing": ai_config.get("alerts", {}).get("prod_billing", "resources/insights-prod/tower-analytics-prod-billing"),
          "saas_namespaces": ai_config.get("saas_namespaces", "data/services/insights/tower-analytics/namespaces"),
          "saas_cicd": ai_config.get("deploy_file", "data/services/insights/tower-analytics/cicd/deploy-clowder.yml").rsplit("/", 1)[0],
          "appinterface_path": ai_repo_path,
          "jira_url": config.get("jira", {}).get("url", "https://issues.redhat.com"),
          "ns_file_main": ns_files.get("prod_main", "tower-analytics-prod.yml"),
          "ns_file_billing": ns_files.get("prod_billing", "tower-analytics-prod-billing.yml"),
      }
    output: cfg

  # ==================== RESOLVE NAMESPACE ====================

  # Step 1: Determine namespace
  - name: resolve_namespace
    description: "Resolve which namespace to investigate"
    compute: |
      if inputs.namespace:
        ns_input = inputs.namespace.lower()
        if 'billing' in ns_input:
          ns = cfg["namespace_billing"]
          ns_short = "billing"
        else:
          ns = cfg["namespace_main"]
          ns_short = "main"
      else:
        # Default to main, but note we should ask
        ns = None
        ns_short = None

      result = {"namespace": ns, "short": ns_short}
    output: ns_info

  # Step 2: If no namespace, return early asking for it
  - name: check_namespace
    condition: "{{ not ns_info.namespace }}"
    compute: |
      result = {
        "ask_namespace": True,
        "message": f"Which namespace to investigate?\n\n1. **main** - {cfg['namespace_main']}\n2. **billing** - {cfg['namespace_billing']}\n\nRun again with: `skill_run(\"debug_prod\", '{{\"namespace\": \"main\"}}')`"
      }
    output: namespace_prompt

  # ==================== LOAD LEARNED PATTERNS ====================

  # Step 3: Load known patterns from memory
  - name: load_patterns
    description: "Load known error patterns from memory"
    condition: "{{ ns_info.namespace }}"
    compute: |
      import yaml
      from pathlib import Path
      from scripts.common.config_loader import load_config

      patterns = {}
      memory_file = Path.home() / "src/redhat-ai-workflow/memory/learned/patterns.yaml"

      if memory_file.exists():
        try:
          with open(memory_file) as f:
            data = yaml.safe_load(f)
          patterns = data.get('error_patterns', [])
        except:
          patterns = []

      result = patterns
    output: known_patterns
    on_error: continue

  # ==================== CHECK PODS ====================

  # Step 4: Get pod status
  - name: get_pods
    description: "Check pod status in namespace"
    condition: "{{ ns_info.namespace }}"
    tool: kubectl_get_pods
    args:
      namespace: "{{ ns_info.namespace }}"
      environment: "production"
    output: pod_status

  # Step 5: Analyze pod issues
  - name: analyze_pods
    description: "Identify unhealthy pods"
    condition: "{{ ns_info.namespace }}"
    compute: |
      import sys
      from pathlib import Path

      # Add scripts path for shared parsers
      scripts_path = str(Path(__file__).parent.parent / "scripts") if hasattr(Path(__file__), 'parent') else str(Path.cwd() / "scripts")
      if scripts_path not in sys.path:
          sys.path.insert(0, scripts_path)
      from common.parsers import parse_kubectl_pods

      # Use shared parser for kubectl pods
      pods = parse_kubectl_pods(str(pod_status))

      # Analyze for issues
      issues = []
      healthy = []

      for pod in pods:
        name = pod.get("name", "")
        status = pod.get("status", "")
        restarts = pod.get("restarts", "0")

        if 'CrashLoopBackOff' in status:
          issues.append({"pod": name, "issue": "CrashLoopBackOff", "severity": "critical"})
        elif 'OOMKilled' in status:
          issues.append({"pod": name, "issue": "OOMKilled", "severity": "critical"})
        elif 'Error' in status:
          issues.append({"pod": name, "issue": status, "severity": "high"})
        elif 'Pending' in status:
          issues.append({"pod": name, "issue": "Pending", "severity": "medium"})
        elif 'ImagePullBackOff' in status:
          issues.append({"pod": name, "issue": "ImagePullBackOff", "severity": "high"})
        elif int(str(restarts).split()[0] if restarts else 0) > 5:
          issues.append({"pod": name, "issue": f"High restarts: {restarts}", "severity": "medium"})
        elif pod.get("healthy", False):
          healthy.append(name)

      result = {
        "issues": issues,
        "healthy_count": len(healthy),
        "unhealthy_count": len(issues)
      }
    output: pod_analysis

  # ==================== GET EVENTS ====================

  # Step 6: Get recent events
  - name: get_events
    description: "Get recent Kubernetes events"
    condition: "{{ ns_info.namespace }}"
    tool: kubectl_get_events
    args:
      namespace: "{{ ns_info.namespace }}"
      environment: "production"
    output: k8s_events
    on_error: continue

  # Step 7: Filter important events
  - name: filter_events
    condition: "{{ ns_info.namespace and k8s_events }}"
    compute: |
      events_str = str(k8s_events)
      important = []

      # Look for warning/error events
      for line in events_str.split('\n')[-30:]:  # Last 30 events
        line_lower = line.lower()
        if any(kw in line_lower for kw in ['warning', 'error', 'failed', 'killed', 'backoff', 'unhealthy']):
          important.append(line.strip()[:150])  # Truncate long lines

      result = important[:10]  # Top 10 important events
    output: important_events
    on_error: continue

  # ==================== CHECK LOGS ====================

  # Step 8: Get logs from unhealthy pods (or filtered pods)
  - name: get_pod_logs
    description: "Get recent error logs from pods"
    condition: "{{ ns_info.namespace }}"
    compute: |
      # Determine which pods to check (use pod_analysis from previous step)
      pods_to_check = []
      if pod_analysis.get('issues'):
        pods_to_check = [p['pod'] for p in pod_analysis['issues'][:3]]  # Max 3 problem pods

      result = {"pods_to_check": pods_to_check, "time_range": inputs.time_range}
    output: pods_selection

  # Step 8b: Get logs from first problem pod
  - name: get_pod_logs_1
    description: "Get logs from first problem pod"
    condition: "{{ pods_selection.pods_to_check|length > 0 }}"
    tool: kubectl_logs
    args:
      pod_name: "{{ pods_selection.pods_to_check[0] }}"
      namespace: "{{ ns_info.namespace }}"
      environment: "production"
      tail: 500
      since: "{{ pods_selection.time_range }}"
    output: pod_logs_1_raw
    on_error: continue

  # Step 8c: Get logs from second problem pod
  - name: get_pod_logs_2
    description: "Get logs from second problem pod"
    condition: "{{ pods_selection.pods_to_check|length > 1 }}"
    tool: kubectl_logs
    args:
      pod_name: "{{ pods_selection.pods_to_check[1] }}"
      namespace: "{{ ns_info.namespace }}"
      environment: "production"
      tail: 500
      since: "{{ pods_selection.time_range }}"
    output: pod_logs_2_raw
    on_error: continue

  # Step 8d: Get logs from third problem pod
  - name: get_pod_logs_3
    description: "Get logs from third problem pod"
    condition: "{{ pods_selection.pods_to_check|length > 2 }}"
    tool: kubectl_logs
    args:
      pod_name: "{{ pods_selection.pods_to_check[2] }}"
      namespace: "{{ ns_info.namespace }}"
      environment: "production"
      tail: 500
      since: "{{ pods_selection.time_range }}"
    output: pod_logs_3_raw
    on_error: continue

  # Step 8e: Parse logs for errors
  - name: parse_pod_logs
    description: "Extract error lines from logs"
    compute: |
      logs = []

      for i, (pod_name, raw_logs) in enumerate([
        (pods_selection.get('pods_to_check', [None])[0] if pods_selection.get('pods_to_check') else None, pod_logs_1_raw if 'pod_logs_1_raw' in dir() else None),
        (pods_selection.get('pods_to_check', [None, None])[1] if len(pods_selection.get('pods_to_check', [])) > 1 else None, pod_logs_2_raw if 'pod_logs_2_raw' in dir() else None),
        (pods_selection.get('pods_to_check', [None, None, None])[2] if len(pods_selection.get('pods_to_check', [])) > 2 else None, pod_logs_3_raw if 'pod_logs_3_raw' in dir() else None),
      ]):
        if not pod_name or not raw_logs:
          continue

        log_text = str(raw_logs)
        error_lines = []
        for line in log_text.split('\n'):
          line_lower = line.lower()
          if any(kw in line_lower for kw in ['error', 'exception', 'traceback', 'warning', 'critical', 'fatal']):
            error_lines.append(line[:200])

        if error_lines:
          logs.append({
            "pod": pod_name,
            "errors": error_lines[-20:]
          })

      result = logs
    output: pod_logs

  # ==================== CHECK ALERTS ====================

  # Step 9: Get firing alerts
  - name: get_alerts
    description: "Get currently firing alerts"
    condition: "{{ ns_info.namespace }}"
    tool: alertmanager_alerts
    args:
      environment: "production"
    output: firing_alerts
    on_error: continue

  # Step 10: Get alert definition if alert_name provided
  - name: get_alert_definition
    description: "Look up alert definition"
    condition: "{{ inputs.alert_name }}"
    compute: |
      import os
      from pathlib import Path
      from scripts.common.config_loader import load_config

      alert_name = inputs.alert_name
      alert_def = None

      # Determine which path based on namespace
      ai_path = Path(cfg["appinterface_path"])
      if 'billing' in ns_info.get('short', ''):
        alert_path = ai_path / cfg["alerts_billing"]
      else:
        alert_path = ai_path / cfg["alerts_main"]

      # Search for alert in yaml files
      if alert_path.exists():
        for f in alert_path.glob('*.yaml'):
          try:
            content = f.read_text()
            if alert_name in content:
              # Extract the alert block
              lines = content.split('\n')
              in_alert = False
              alert_lines = []
              for line in lines:
                if alert_name in line:
                  in_alert = True
                if in_alert:
                  alert_lines.append(line)
                  if line.strip() and not line.startswith(' ') and len(alert_lines) > 1:
                    break
              alert_def = '\n'.join(alert_lines[:20])
              break
          except:
            pass

      result = alert_def
    output: alert_definition
    on_error: continue

  # ==================== CHECK METRICS ====================

  # Step 11: Check key metrics
  - name: check_metrics
    description: "Query key Prometheus metrics"
    condition: "{{ ns_info.namespace }}"
    compute: |
      # Prepare Prometheus queries
      ns = ns_info['namespace']

      queries = [
        f'sum(rate(http_requests_total{{namespace="{ns}",code=~"5.."}}[5m]))',
        f'sum(container_memory_working_set_bytes{{namespace="{ns}"}}) by (pod)',
        f'sum(rate(container_cpu_usage_seconds_total{{namespace="{ns}"}}[5m])) by (pod)',
      ]

      result = {"queries_to_run": queries, "namespace": ns}
    output: metric_queries
    on_error: continue

  # ==================== CHECK RECENT DEPLOYMENTS ====================

  # Step 12a: Get deployments
  - name: get_deployments
    description: "Get deployment info"
    condition: "{{ ns_info.namespace }}"
    tool: kubectl_get_deployments
    args:
      namespace: "{{ ns_info.namespace }}"
      environment: "production"
    output: deployments_raw
    on_error: continue

  # Step 12b: Get replicasets
  - name: get_replicasets
    description: "Get replicasets for recent rollouts"
    condition: "{{ ns_info.namespace }}"
    tool: kubectl_get
    args:
      resource: "replicasets"
      namespace: "{{ ns_info.namespace }}"
      environment: "production"
      output_format: "wide"
    output: replicasets_raw
    on_error: continue

  # Step 12c: Parse deployment info
  - name: parse_deployment_info
    description: "Combine deployment and replicaset info"
    compute: |
      deployments = str(deployments_raw)[:1000] if 'deployments_raw' in dir() and deployments_raw else "Could not fetch deployments"

      # Parse replicasets
      rs_text = str(replicasets_raw) if 'replicasets_raw' in dir() and replicasets_raw else ""
      rs_lines = rs_text.split('\n')
      # Get last 5 replicasets (plus header)
      recent_rs = rs_lines[:1] + rs_lines[-5:] if len(rs_lines) > 5 else rs_lines

      result = {
        "deployments": deployments,
        "recent_rollouts": '\n'.join(recent_rs)[:500]
      }
    output: deployment_info

  # Step 13: Check deployed SHA from app-interface CICD config
  - name: check_deployed_sha
    description: "Get currently deployed SHA from app-interface config"
    condition: "{{ ns_info.namespace }}"
    compute: |
      import yaml
      from pathlib import Path
      from scripts.common.config_loader import load_config

      cicd_file = Path(cfg["appinterface_path"]) / cfg["saas_cicd"] / "deploy-clowder.yml"
      deployed_info = {"sha": None, "namespace_config": None}

      if cicd_file.exists():
        try:
          with open(cicd_file) as f:
            content = f.read()

          # Parse to find the ref for this namespace
          data = yaml.safe_load(content)

          # Target namespace file based on which we're debugging (from config)
          if 'billing' in ns_info.get('short', ''):
            target_ns = cfg.get("ns_file_billing", "tower-analytics-prod-billing.yml")
          else:
            target_ns = cfg.get("ns_file_main", "tower-analytics-prod.yml")

          # Find the ref for this namespace in resourceTemplates
          for template in data.get('resourceTemplates', []):
            for target in template.get('targets', []):
              ns_ref = target.get('namespace', {}).get('$ref', '')
              if target_ns in ns_ref:
                deployed_info['sha'] = target.get('ref', 'unknown')
                deployed_info['namespace_config'] = ns_ref
                break
        except Exception as e:
          deployed_info['error'] = str(e)

      result = deployed_info
    output: deployed_sha
    on_error: continue

  # Step 14: Check namespace config
  - name: check_namespace_config
    description: "Get namespace configuration from app-interface"
    condition: "{{ ns_info.namespace }}"
    compute: |
      import yaml
      from pathlib import Path
      from scripts.common.config_loader import load_config

      ns_path = Path(cfg["appinterface_path"]) / cfg["saas_namespaces"]
      config_info = {}

      # Use namespace file from config
      if 'billing' in ns_info.get('short', ''):
        ns_file = ns_path / cfg.get("ns_file_billing", "tower-analytics-prod-billing.yml")
      else:
        ns_file = ns_path / cfg.get("ns_file_main", "tower-analytics-prod.yml")

      if ns_file.exists():
        try:
          with open(ns_file) as f:
            data = yaml.safe_load(f)

          # Extract key config info
          config_info = {
            "name": data.get('name', ''),
            "cluster": data.get('cluster', {}).get('$ref', '').split('/')[-1] if data.get('cluster') else '',
            "description": data.get('description', '')[:100] if data.get('description') else ''
          }
        except Exception as e:
          config_info['error'] = str(e)

      result = config_info
    output: namespace_config
    on_error: continue

  # ==================== ANALYZE & SUGGEST ====================

  # Step 13: Match against known patterns
  - name: match_patterns
    description: "Match issues against known patterns"
    condition: "{{ ns_info.namespace }}"
    compute: |
      matches = []

      # Check pod issues against known patterns
      for pod_issue in pod_analysis.get('issues', []):
        issue_type = pod_issue.get('issue', '')

        for pattern in (known_patterns or []):
          if isinstance(pattern, dict):
            pattern_text = pattern.get('pattern', '')
            if pattern_text.lower() in issue_type.lower():
              matches.append({
                "issue": issue_type,
                "pattern": pattern_text,
                "meaning": pattern.get('meaning', ''),
                "fix": pattern.get('fix', ''),
                "commands": pattern.get('commands', [])
              })

      # Add generic suggestions for unmatched issues
      for pod_issue in pod_analysis.get('issues', []):
        issue_type = pod_issue.get('issue', '')
        matched = any(m['issue'] == issue_type for m in matches)

        if not matched:
          if 'OOMKilled' in issue_type:
            matches.append({
              "issue": issue_type,
              "pattern": "OOMKilled",
              "meaning": "Container exceeded memory limits",
              "fix": "Increase memory limits or investigate memory leak",
              "commands": ["kubectl describe pod <pod>", "kubectl top pod -n <ns>"]
            })
          elif 'CrashLoopBackOff' in issue_type:
            matches.append({
              "issue": issue_type,
              "pattern": "CrashLoopBackOff",
              "meaning": "Container crashes repeatedly on startup",
              "fix": "Check logs for startup errors, config issues, or missing deps",
              "commands": ["kubectl logs <pod> --previous", "kubectl describe pod <pod>"]
            })
          elif 'ImagePullBackOff' in issue_type:
            matches.append({
              "issue": issue_type,
              "pattern": "ImagePullBackOff",
              "meaning": "Cannot pull container image",
              "fix": "Check image name, tag exists in Quay, registry credentials",
              "commands": ["kubectl describe pod <pod>"]
            })

      result = matches
    output: pattern_matches

  # ==================== BUILD REPORT ====================

  # Step 16: Compile investigation report
  - name: build_report
    condition: "{{ ns_info.namespace }}"
    compute: |
      lines = []

      # Header
      lines.append(f"## üîç Production Debug: {ns_info['namespace']}")
      lines.append(f"**Time range:** {inputs.time_range}")
      if inputs.alert_name:
        lines.append(f"**Alert:** {inputs.alert_name}")

      # Deployed SHA
      if deployed_sha and deployed_sha.get('sha'):
        lines.append(f"**Deployed SHA:** `{deployed_sha['sha'][:12]}`")
      lines.append("")

      # === POD STATUS ===
      lines.append("### üì¶ Pod Status")
      if pod_analysis['unhealthy_count'] > 0:
        lines.append(f"**‚ö†Ô∏è {pod_analysis['unhealthy_count']} unhealthy pods**")
        for issue in pod_analysis['issues'][:5]:
          severity_icon = "üî¥" if issue['severity'] == 'critical' else "üü†" if issue['severity'] == 'high' else "üü°"
          lines.append(f"- {severity_icon} `{issue['pod']}`: {issue['issue']}")
      else:
        lines.append(f"‚úÖ All {pod_analysis['healthy_count']} pods healthy")
      lines.append("")

      # === EVENTS ===
      if important_events:
        lines.append("### ‚ö° Recent Events")
        for event in important_events[:5]:
          lines.append(f"- {event[:120]}")
        lines.append("")

      # === LOGS ===
      if pod_logs:
        lines.append("### üìã Error Logs")
        for log in pod_logs[:2]:  # Max 2 pods to avoid context overflow
          lines.append(f"**{log['pod']}:**")
          lines.append("```")
          for err in log['errors'][-5:]:  # Last 5 errors per pod
            lines.append(err[:150])
          lines.append("```")
        lines.append("")

      # === ALERTS ===
      if firing_alerts and 'No alerts' not in str(firing_alerts):
        lines.append("### üö® Firing Alerts")
        alerts_str = str(firing_alerts)[:500]
        lines.append(f"```\n{alerts_str}\n```")
        lines.append("")

      # === ALERT DEFINITION ===
      if alert_definition:
        lines.append("### üìñ Alert Definition")
        lines.append(f"```yaml\n{alert_definition[:300]}\n```")
        lines.append("")

      # === DEPLOYMENTS ===
      if deployment_info:
        lines.append("### üöÄ Recent Deployments")
        lines.append(f"```\n{deployment_info.get('recent_rollouts', 'N/A')[:400]}\n```")
        lines.append("")

      # === PATTERN MATCHES ===
      if pattern_matches:
        lines.append("### üí° Likely Causes")
        for match in pattern_matches[:3]:
          lines.append(f"**{match['pattern']}**")
          lines.append(f"- *Meaning:* {match['meaning']}")
          lines.append(f"- *Fix:* {match['fix']}")
          if match.get('commands'):
            lines.append(f"- *Commands:* `{match['commands'][0]}`")
        lines.append("")

      # === SUGGESTED QUERIES ===
      lines.append("### üìä Prometheus Queries")
      lines.append("Run these for more details:")
      for q in metric_queries.get('queries_to_run', [])[:3]:
        lines.append(f"```\n{q}\n```")

      result = '\n'.join(lines)
    output: report

  # ==================== MEMORY INTEGRATION ====================

  - name: build_memory_context
    description: "Build context for memory updates"
    condition: "not namespace_prompt"
    compute: |
      from datetime import datetime

      # Summarize findings
      issues_found = []
      if pod_issues and pod_issues.get("unhealthy_pods"):
          issues_found.append(f"{len(pod_issues['unhealthy_pods'])} unhealthy pods")
      if log_analysis and log_analysis.get("error_count", 0) > 0:
          issues_found.append(f"{log_analysis['error_count']} errors in logs")
      if pattern_matches:
          issues_found.append(f"{len(pattern_matches)} pattern matches")

      result = {
          "timestamp": datetime.now().isoformat(),
          "namespace": ns_info.get("namespace", "unknown") if ns_info else "unknown",
          "environment": ns_info.get("environment", "production") if ns_info else "production",
          "issues_summary": ", ".join(issues_found) if issues_found else "No major issues",
      }
    output: memory_context

  - name: log_session_debug
    description: "Log debug session"
    condition: "not namespace_prompt"
    tool: memory_session_log
    args:
      action: "Debugged {{ memory_context.environment }}/{{ memory_context.namespace }}"
      details: "{{ memory_context.issues_summary }}"
    on_error: continue

  - name: update_environment_after_debug
    description: "Update environment status after debugging"
    condition: "not namespace_prompt"
    compute: |
      from pathlib import Path
      import yaml

      memory_file = Path.home() / "src/redhat-ai-workflow/memory/state/environments.yaml"

      if memory_file.exists():
          try:
              with open(memory_file) as f:
                  data = yaml.safe_load(f) or {}

              env_key = "stage" if memory_context.get("environment") == "stage" else "production"
              if env_key in data.get("environments", {}):
                  env_data = data["environments"][env_key]
                  env_data["last_check"] = memory_context["timestamp"]
                  env_data["notes"] = f"Debug: {memory_context['issues_summary']}"

                  # Mark as issues if we found problems
                  if pod_issues and pod_issues.get("unhealthy_pods"):
                      env_data["status"] = "issues"
                  elif log_analysis and log_analysis.get("error_count", 0) > 10:
                      env_data["status"] = "issues"

                  data["last_checked"] = memory_context["timestamp"]

                  with open(memory_file, "w") as f:
                      yaml.dump(data, f, default_flow_style=False)

              result = "environment updated"
          except Exception as e:
              result = f"failed: {e}"
      else:
          result = "no memory file"
    output: env_update_result
    on_error: continue

outputs:
  - name: summary
    value: |
      {% if namespace_prompt %}
      {{ namespace_prompt.message }}
      {% else %}
      {{ report }}

      ---

      ### What's Next?

      1. **Get more logs:** `kubectl_logs(pod_name='<pod>', namespace='{{ ns_info.namespace }}', environment='production')`
      2. **Describe pod:** `kubectl_describe_pod(pod_name='<pod>', namespace='{{ ns_info.namespace }}', environment='production')`
      3. **Query metrics:** `prometheus_query(query='...', environment='production')`
      4. **Check Kibana:** `kibana_search_logs(namespace='{{ ns_info.namespace }}', query='error')`
      5. **View git history since deployment:** `git_log(repo='automation-analytics-backend', since='<deployed_sha>')`

      {% if pattern_matches %}
      ### üìù Remember This?

      If the suggested fix worked (or didn't), let me know and I'll update the learned patterns.
      {% endif %}
      {% endif %}

  - name: context
    value:
      namespace: "{{ ns_info.namespace }}"
      deployed_sha: "{{ deployed_sha.sha if deployed_sha else None }}"
      unhealthy_pods: "{{ pod_analysis.unhealthy_count if pod_analysis else 0 }}"
      has_alerts: "{{ firing_alerts is not none }}"
      pattern_matches: "{{ pattern_matches | length if pattern_matches else 0 }}"
